{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "[CLIMATE CHANGE] Model Submission Guide - sklearn.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<p align=\"center\"><img width=\"50%\" src=\"https://aimodelsharecontent.s3.amazonaws.com/aimodshare_banner.jpg\" /></p>\n",
        "\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "m_DMeZsXxpEZ"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JXxGTgJz152A"
      },
      "source": [
        "# Climate Change Satellite Image Classification Competition Model Submission Guide - sklearn\n",
        "\n",
        "---\n",
        "**About the Original Data:**<br>\n",
        "*Data and Description accessed from [Tensorflow](https://www.tensorflow.org/datasets/catalog/bigearthnet)* <br>\n",
        "The BigEarthNet is a new large-scale Sentinel-2 benchmark archive, consisting of 590,326 Sentinel-2 image patches. The image patch size on the ground is 1.2 x 1.2 km with variable image size depending on the channel resolution. This is a multi-label dataset with 43 imbalanced labels, which has been simplified to single labels with 3 categories for the purposes of this competition.\n",
        "\n",
        "To construct the BigEarthNet, 125 Sentinel-2 tiles acquired between June 2017 and May 2018 over the 10 countries (Austria, Belgium, Finland, Ireland, Kosovo, Lithuania, Luxembourg, Portugal, Serbia, Switzerland) of Europe were initially selected. All the tiles were atmospherically corrected by the Sentinel-2 Level 2A product generation and formatting tool (sen2cor). Then, they were divided into 590,326 non-overlapping image patches. Each image patch was annotated by the multiple land-cover classes (i.e., multi-labels) that were provided from the CORINE Land Cover database of the year 2018 (CLC 2018).\n",
        "\n",
        "Bands and pixel resolution in meters:\n",
        "\n",
        "    B01: Coastal aerosol; 60m\n",
        "    B02: Blue; 10m\n",
        "    B03: Green; 10m\n",
        "    B04: Red; 10m\n",
        "    B05: Vegetation red edge; 20m\n",
        "    B06: Vegetation red edge; 20m\n",
        "    B07: Vegetation red edge; 20m\n",
        "    B08: NIR; 10m\n",
        "    B09: Water vapor; 60m\n",
        "    B11: SWIR; 20m\n",
        "    B12: SWIR; 20m\n",
        "    B8A: Narrow NIR; 20m\n",
        "\n",
        "License: Community Data License Agreement - Permissive, Version 1.0.\"\n",
        "\n",
        "**Competition Data Specifics:**<br>\n",
        "For the purpose of this competition, the original BigEarthNet dataset has been simplified to 20,000 images (15,000 training images and 5,000 test images) with 3 categories: \"forest\", \"nonforest\", and \"snow_shadow_cloud\", which contains images of snow and clouds. <br>\n",
        "Each \"image\" is a folder with 12 satellite image layers, each of which pics up on different features. The example preprocessor uses just three layers: B02, B03, and B04, which contain the standard RGB layers used in ML models. However, you are free to use any combination of the satellite image layers. \n",
        "\n",
        "**Data Source:**<br>\n",
        "Sumbul, G, Charfuelan, M, Demir, B and Markl, V. (2019). BigEarthNet: A Large-Scale Benchmark Archive For Remote Sensing Image Understanding. *Computing Research Repository (CoRR), abs/1902.06148.* https://www.tensorflow.org/datasets/catalog/bigearthnet"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Overview\n",
        "---\n",
        "\n",
        "Let's share our models to a centralized leaderboard, so that we can collaborate and learn from the model experimentation process...\n",
        "\n",
        "**Instructions:**\n",
        "1.   Get data in and set up X_train / X_test / y_train\n",
        "2.   Preprocess data / Write and Save Preprocessor function\n",
        "3. Fit model on preprocessed data and save preprocessor function and model \n",
        "4. Generate predictions from X_test data and submit model to competition\n",
        "5. Repeat submission process to improve place on leaderboard\n",
        "\n"
      ],
      "metadata": {
        "id": "jt9GxUrX9dMC"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5gSrVJwp3E9H"
      },
      "source": [
        "## 1. Load Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PLTIaMB3ChSW"
      },
      "source": [
        "#install aimodelshare library\n",
        "! pip install aimodelshare-nightly"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d3PiJXBhC5y-",
        "outputId": "6908c734-1ef5-4a22-9e76-a065ef5984bf"
      },
      "source": [
        "# Get competition data - May take a couple minutes due to size of data set\n",
        "from aimodelshare import download_data\n",
        "download_data('public.ecr.aws/y2e2a1d6/climate_competition_data-repository:latest') "
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading [================================================>]\n",
            "\n",
            "Data downloaded successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Unzip Data - May take a couple minutes due to size of data set\n",
        "import zipfile\n",
        "with zipfile.ZipFile('climate_competition_data/climate_competition_data.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall('competition_data')"
      ],
      "metadata": {
        "id": "oZIHmTo59tN5"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gEzPoXPj3V7u"
      },
      "source": [
        "##2.   Preprocess data / Write and Save Preprocessor function\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up for data preprocessing\n",
        "import numpy as np\n",
        "import os\n",
        "import PIL\n",
        "import PIL.Image\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds"
      ],
      "metadata": {
        "id": "DC3T1mH89xTl"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Here is a pre-designed preprocessor, but you could also build your own to prepare the data differently\n",
        "\n",
        "def preprocessor(imageband_directory):\n",
        "        \"\"\"\n",
        "        This function preprocesses reads in images, resizes them to a fixed shape and\n",
        "        min/max transforms them before converting feature values to float32 numeric values\n",
        "        required by onnx files.\n",
        "        \n",
        "        params:\n",
        "            imageband_directory\n",
        "                path to folder with 13 satellite image bands\n",
        "                      \n",
        "        returns:\n",
        "            X\n",
        "                numpy array of preprocessed image data\n",
        "                  \n",
        "        \"\"\"\n",
        "           \n",
        "        import PIL\n",
        "        import os\n",
        "        import numpy as np\n",
        "        import tensorflow_datasets as tfds\n",
        "\n",
        "        def _load_tif(data):\n",
        "            \"\"\"Loads TIF file and returns as float32 numpy array.\"\"\"\n",
        "            img=tfds.core.lazy_imports.PIL_Image.open(data)\n",
        "            img = np.array(img.getdata()).reshape(img.size).astype(np.float32)\n",
        "            return img\n",
        "\n",
        "        image_list = []\n",
        "        filelist1=os.listdir(imageband_directory)\n",
        "        for fpath in filelist1:\n",
        "          fullpath=imageband_directory+\"/\"+fpath\n",
        "          if fullpath.endswith(('B02.tif','B03.tif','B04.tif')):\n",
        "              imgarray=_load_tif(imageband_directory+\"/\"+fpath)\n",
        "              image_list.append(imgarray)\n",
        "\n",
        "        X = np.stack(image_list,axis=2)   # to get (height,width,3)\n",
        "\n",
        "        X = np.expand_dims(X, axis=0) # Expand dims to add \"1\" to object shape [1, h, w, channels] for keras model.\n",
        "        X = np.array(X, dtype=np.float32) # Final shape for onnx runtime.\n",
        "        X=X/18581 # min max transform to max value\n",
        "        X = X.flatten()\n",
        "        return X"
      ],
      "metadata": {
        "id": "EyObJvH_9zO3"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create complete list of file names\n",
        "forestfilenames=[\"competition_data/trainingdata/forest/\"+x for x in os.listdir(\"competition_data/trainingdata/forest\")]\n",
        "nonforestfilenames=[\"competition_data/trainingdata/nonforest/\"+x for x in os.listdir(\"competition_data/trainingdata/nonforest\")]\n",
        "otherfilenames=[\"competition_data/trainingdata/other/\"+x for x in os.listdir(\"competition_data/trainingdata/other\")]\n",
        "\n",
        "filenames=forestfilenames+nonforestfilenames+otherfilenames\n",
        "\n",
        "#preprocess rbg images into 120,120,3 numpy ndarray, then flatten into a single 1 x 43200 row for each set of rbg images\n",
        "preprocessed_image_data=[]\n",
        "for i in filenames:\n",
        "  try:\n",
        "    preprocessed_image_data.append(preprocessor(i))\n",
        "  except:\n",
        "    pass  \n",
        "  "
      ],
      "metadata": {
        "id": "pT6B4SWs9038"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up y data\n",
        "from itertools import repeat\n",
        "forest=repeat(\"forest\",5000)\n",
        "nonforest=repeat(\"nonforest\",5000)\n",
        "other=repeat(\"snow_shadow_cloud\",5000)\n",
        "ylist=list(forest)+list(nonforest)+list(other)"
      ],
      "metadata": {
        "id": "9ASbrj_d92dG"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Shuffle X and y data\n",
        "from sklearn.utils import shuffle\n",
        "X_train, y_train = shuffle(preprocessed_image_data, ylist, random_state=0)"
      ],
      "metadata": {
        "id": "BWiaEYkZ93-o"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train=np.vstack(X_train) # convert X from list to array"
      ],
      "metadata": {
        "id": "ri0zZQq-95aW"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Ps2SWlK96xX",
        "outputId": "463922bf-d9a6-4b96-badf-d16a3a3903bd"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(15000, 43200)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocess X_test Data: \n",
        "\n",
        "# import and preprocess X_test images in correct order...\n",
        "# ...for leaderboard prediction submissions\n",
        "filenumbers=[str(x) for x in range(1, 5001)]\n",
        "filenames=[\"competition_data/testdata/test/test\"+x for x in filenumbers]\n",
        "\n",
        "#preprocess rbg images into 120,120,3 numpy ndarray, then flatten into a single 1 x 43200 row for each set of rbg images\n",
        "preprocessed_image_data=[]\n",
        "for i in filenames:\n",
        "  try:\n",
        "    preprocessed_image_data.append(preprocessor(i))\n",
        "  except:\n",
        "    pass  "
      ],
      "metadata": {
        "id": "KQmHv_DEJppg"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test=np.vstack(preprocessed_image_data) # convert X from list to array"
      ],
      "metadata": {
        "id": "7H5flnryJtG9"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X52kECL43b-O"
      },
      "source": [
        "##3. Fit model on preprocessed data and save preprocessor function and model \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NCbBf8j9ClYl",
        "outputId": "d2a5ea30-fffc-40e7-b150-71e33877ba73"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "model = RandomForestClassifier(n_estimators = 100, max_depth = 3, random_state=0)\n",
        "model.fit(X_train, y_train) # Fitting to the training set.\n",
        "prediction_labels = model.predict(X_train)\n",
        "\n",
        "f1_score(y_train, prediction_labels, average='macro')"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5649475514285425"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zmJAnmO-5AcU"
      },
      "source": [
        "#### Save preprocessor function to local \"preprocessor.zip\" file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4VGacc0LDaMA",
        "outputId": "150e0f17-6c7e-450c-f466-6a27ebef20e9"
      },
      "source": [
        "import aimodelshare as ai\n",
        "ai.export_preprocessor(preprocessor,\"\") "
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "can't pickle module objects\n",
            "Your preprocessor is now saved to 'preprocessor.zip'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oOWBa8Cv5LdL"
      },
      "source": [
        "#### Save model to local \".onnx\" file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pEhvnRiQDlY5"
      },
      "source": [
        "# Save sklearn model to local ONNX file\n",
        "from aimodelshare.aimsonnx import model_to_onnx\n",
        "\n",
        "# Check how many preprocessed input features are there?\n",
        "from skl2onnx.common.data_types import FloatTensorType\n",
        "\n",
        "feature_count=X_train.shape[1] #Get count of preprocessed features\n",
        "initial_type = [('float_input', FloatTensorType([None, feature_count]))]  #Insert correct number of preprocessed features\n",
        "\n",
        "onnx_model = model_to_onnx(model, framework='sklearn',\n",
        "                          initial_types=initial_type,\n",
        "                          transfer_learning=False,\n",
        "                          deep_learning=False)\n",
        "\n",
        "with open(\"model.onnx\", \"wb\") as f:\n",
        "    f.write(onnx_model.SerializeToString())"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gHWkAzvX3m8O"
      },
      "source": [
        "## 4. Generate predictions from X_test data and submit model to competition\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RtgkM02MDpkO",
        "outputId": "60baf57d-f434-42c3-a3fc-b7271720c0df"
      },
      "source": [
        "#Set credentials using modelshare.org username/password\n",
        "\n",
        "from aimodelshare.aws import set_credentials\n",
        "    \n",
        "apiurl=\"https://srdmat3yhf.execute-api.us-east-1.amazonaws.com/prod/m\"\n",
        " #This is the unique rest api that powers this Climate Change Satellite Image Classification Playground\n",
        "\n",
        "set_credentials(apiurl=apiurl)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AI Modelshare Username:··········\n",
            "AI Modelshare Password:··········\n",
            "AI Model Share login credentials set successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fKNGSww8EGgi"
      },
      "source": [
        "#Instantiate Competition\n",
        "import aimodelshare as ai\n",
        "mycompetition= ai.Competition(apiurl)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Ql4wksyEUnP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a45acdf7-4990-4c27-8d78-3b081a577bbe"
      },
      "source": [
        "#Submit Model: \n",
        "\n",
        "#-- Generate predicted values (a list of predicted image categories) \n",
        "predicted_values = model.predict(X_test)\n",
        "\n",
        "# Submit model to Competition Leaderboard\n",
        "mycompetition.submit_model(model_filepath = \"model.onnx\",\n",
        "                                 preprocessor_filepath=\"preprocessor.zip\",\n",
        "                                 prediction_submission=predicted_values)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Insert search tags to help users find your model (optional): \n",
            "Provide any useful notes about your model (optional): \n",
            "\n",
            "Your model has been submitted as model version 2\n",
            "\n",
            "To submit code used to create this model or to view current leaderboard navigate to Model Playground: \n",
            "\n",
            " https://www.modelshare.org/detail/model:1535\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 169
        },
        "id": "GN1zvAmNEq17",
        "outputId": "f67ffb73-7aa1-49c8-9f72-ea1bf97219ef"
      },
      "source": [
        "# Get leaderboard to explore current best model architectures\n",
        "\n",
        "# Get raw data in pandas data frame\n",
        "data = mycompetition.get_leaderboard()\n",
        "\n",
        "# Stylize leaderboard data\n",
        "mycompetition.stylize_leaderboard(data)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<style type=\"text/css\">\n",
              "#T_6cfa4_row0_col0 {\n",
              "  text-align: center;\n",
              "  width: 10em;\n",
              "  height: 80%;\n",
              "  background: linear-gradient(90deg,#f5f8d6 54.3%, transparent 54.3%);\n",
              "  color: #251e1b;\n",
              "  font-size: 12px;\n",
              "}\n",
              "#T_6cfa4_row0_col1 {\n",
              "  text-align: center;\n",
              "  width: 10em;\n",
              "  height: 80%;\n",
              "  background: linear-gradient(90deg,#c778c8 46.1%, transparent 46.1%);\n",
              "  color: #251e1b;\n",
              "  font-size: 12px;\n",
              "}\n",
              "#T_6cfa4_row0_col2 {\n",
              "  text-align: center;\n",
              "  width: 10em;\n",
              "  height: 80%;\n",
              "  background: linear-gradient(90deg,#ff4971 44.4%, transparent 44.4%);\n",
              "  color: #251e1b;\n",
              "  font-size: 12px;\n",
              "}\n",
              "#T_6cfa4_row0_col3 {\n",
              "  text-align: center;\n",
              "  width: 10em;\n",
              "  height: 80%;\n",
              "  background: linear-gradient(90deg,#aadbaa 48.1%, transparent 48.1%);\n",
              "  color: #251e1b;\n",
              "  font-size: 12px;\n",
              "}\n",
              "#T_6cfa4_row0_col4, #T_6cfa4_row0_col5, #T_6cfa4_row0_col6, #T_6cfa4_row0_col7, #T_6cfa4_row0_col8, #T_6cfa4_row0_col9, #T_6cfa4_row0_col10, #T_6cfa4_row0_col11, #T_6cfa4_row0_col12, #T_6cfa4_row0_col13, #T_6cfa4_row0_col14, #T_6cfa4_row0_col15, #T_6cfa4_row0_col16, #T_6cfa4_row0_col17, #T_6cfa4_row0_col18, #T_6cfa4_row0_col19, #T_6cfa4_row0_col20, #T_6cfa4_row0_col21, #T_6cfa4_row0_col22, #T_6cfa4_row1_col4, #T_6cfa4_row1_col5, #T_6cfa4_row1_col6, #T_6cfa4_row1_col7, #T_6cfa4_row1_col8, #T_6cfa4_row1_col9, #T_6cfa4_row1_col10, #T_6cfa4_row1_col11, #T_6cfa4_row1_col12, #T_6cfa4_row1_col13, #T_6cfa4_row1_col14, #T_6cfa4_row1_col15, #T_6cfa4_row1_col16, #T_6cfa4_row1_col17, #T_6cfa4_row1_col18, #T_6cfa4_row1_col19, #T_6cfa4_row1_col20, #T_6cfa4_row1_col21, #T_6cfa4_row1_col22 {\n",
              "  text-align: center;\n",
              "}\n",
              "#T_6cfa4_row1_col0 {\n",
              "  text-align: center;\n",
              "  width: 10em;\n",
              "  height: 80%;\n",
              "  background: linear-gradient(90deg,#f5f8d6 40.1%, transparent 40.1%);\n",
              "  color: #251e1b;\n",
              "  font-size: 12px;\n",
              "}\n",
              "#T_6cfa4_row1_col1 {\n",
              "  text-align: center;\n",
              "  width: 10em;\n",
              "  height: 80%;\n",
              "  background: linear-gradient(90deg,#c778c8 43.4%, transparent 43.4%);\n",
              "  color: #251e1b;\n",
              "  font-size: 12px;\n",
              "}\n",
              "#T_6cfa4_row1_col2 {\n",
              "  text-align: center;\n",
              "  width: 10em;\n",
              "  height: 80%;\n",
              "  background: linear-gradient(90deg,#ff4971 44.8%, transparent 44.8%);\n",
              "  color: #251e1b;\n",
              "  font-size: 12px;\n",
              "}\n",
              "#T_6cfa4_row1_col3 {\n",
              "  text-align: center;\n",
              "  width: 10em;\n",
              "  height: 80%;\n",
              "  background: linear-gradient(90deg,#aadbaa 47.8%, transparent 47.8%);\n",
              "  color: #251e1b;\n",
              "  font-size: 12px;\n",
              "}\n",
              "</style>\n",
              "<table id=\"T_6cfa4_\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th class=\"blank level0\" >&nbsp;</th>\n",
              "      <th class=\"col_heading level0 col0\" >accuracy</th>\n",
              "      <th class=\"col_heading level0 col1\" >f1_score</th>\n",
              "      <th class=\"col_heading level0 col2\" >precision</th>\n",
              "      <th class=\"col_heading level0 col3\" >recall</th>\n",
              "      <th class=\"col_heading level0 col4\" >ml_framework</th>\n",
              "      <th class=\"col_heading level0 col5\" >transfer_learning</th>\n",
              "      <th class=\"col_heading level0 col6\" >deep_learning</th>\n",
              "      <th class=\"col_heading level0 col7\" >model_type</th>\n",
              "      <th class=\"col_heading level0 col8\" >depth</th>\n",
              "      <th class=\"col_heading level0 col9\" >num_params</th>\n",
              "      <th class=\"col_heading level0 col10\" >dropout_layers</th>\n",
              "      <th class=\"col_heading level0 col11\" >dense_layers</th>\n",
              "      <th class=\"col_heading level0 col12\" >flatten_layers</th>\n",
              "      <th class=\"col_heading level0 col13\" >conv2d_layers</th>\n",
              "      <th class=\"col_heading level0 col14\" >maxpooling2d_layers</th>\n",
              "      <th class=\"col_heading level0 col15\" >softmax_act</th>\n",
              "      <th class=\"col_heading level0 col16\" >relu_act</th>\n",
              "      <th class=\"col_heading level0 col17\" >loss</th>\n",
              "      <th class=\"col_heading level0 col18\" >optimizer</th>\n",
              "      <th class=\"col_heading level0 col19\" >model_config</th>\n",
              "      <th class=\"col_heading level0 col20\" >memory_size</th>\n",
              "      <th class=\"col_heading level0 col21\" >username</th>\n",
              "      <th class=\"col_heading level0 col22\" >version</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th id=\"T_6cfa4_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
              "      <td id=\"T_6cfa4_row0_col0\" class=\"data row0 col0\" >54.28%</td>\n",
              "      <td id=\"T_6cfa4_row0_col1\" class=\"data row0 col1\" >46.12%</td>\n",
              "      <td id=\"T_6cfa4_row0_col2\" class=\"data row0 col2\" >44.40%</td>\n",
              "      <td id=\"T_6cfa4_row0_col3\" class=\"data row0 col3\" >48.11%</td>\n",
              "      <td id=\"T_6cfa4_row0_col4\" class=\"data row0 col4\" >sklearn</td>\n",
              "      <td id=\"T_6cfa4_row0_col5\" class=\"data row0 col5\" >False</td>\n",
              "      <td id=\"T_6cfa4_row0_col6\" class=\"data row0 col6\" >False</td>\n",
              "      <td id=\"T_6cfa4_row0_col7\" class=\"data row0 col7\" >RandomForestClassifier</td>\n",
              "      <td id=\"T_6cfa4_row0_col8\" class=\"data row0 col8\" >nan</td>\n",
              "      <td id=\"T_6cfa4_row0_col9\" class=\"data row0 col9\" >nan</td>\n",
              "      <td id=\"T_6cfa4_row0_col10\" class=\"data row0 col10\" >nan</td>\n",
              "      <td id=\"T_6cfa4_row0_col11\" class=\"data row0 col11\" >nan</td>\n",
              "      <td id=\"T_6cfa4_row0_col12\" class=\"data row0 col12\" >nan</td>\n",
              "      <td id=\"T_6cfa4_row0_col13\" class=\"data row0 col13\" >nan</td>\n",
              "      <td id=\"T_6cfa4_row0_col14\" class=\"data row0 col14\" >nan</td>\n",
              "      <td id=\"T_6cfa4_row0_col15\" class=\"data row0 col15\" >nan</td>\n",
              "      <td id=\"T_6cfa4_row0_col16\" class=\"data row0 col16\" >nan</td>\n",
              "      <td id=\"T_6cfa4_row0_col17\" class=\"data row0 col17\" >nan</td>\n",
              "      <td id=\"T_6cfa4_row0_col18\" class=\"data row0 col18\" >nan</td>\n",
              "      <td id=\"T_6cfa4_row0_col19\" class=\"data row0 col19\" >{'bootstrap': True, 'ccp_alpha...</td>\n",
              "      <td id=\"T_6cfa4_row0_col20\" class=\"data row0 col20\" >nan</td>\n",
              "      <td id=\"T_6cfa4_row0_col21\" class=\"data row0 col21\" >AIModelShare</td>\n",
              "      <td id=\"T_6cfa4_row0_col22\" class=\"data row0 col22\" >2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_6cfa4_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
              "      <td id=\"T_6cfa4_row1_col0\" class=\"data row1 col0\" >40.08%</td>\n",
              "      <td id=\"T_6cfa4_row1_col1\" class=\"data row1 col1\" >43.37%</td>\n",
              "      <td id=\"T_6cfa4_row1_col2\" class=\"data row1 col2\" >44.80%</td>\n",
              "      <td id=\"T_6cfa4_row1_col3\" class=\"data row1 col3\" >47.78%</td>\n",
              "      <td id=\"T_6cfa4_row1_col4\" class=\"data row1 col4\" >keras</td>\n",
              "      <td id=\"T_6cfa4_row1_col5\" class=\"data row1 col5\" >False</td>\n",
              "      <td id=\"T_6cfa4_row1_col6\" class=\"data row1 col6\" >True</td>\n",
              "      <td id=\"T_6cfa4_row1_col7\" class=\"data row1 col7\" >Sequential</td>\n",
              "      <td id=\"T_6cfa4_row1_col8\" class=\"data row1 col8\" >8.000000</td>\n",
              "      <td id=\"T_6cfa4_row1_col9\" class=\"data row1 col9\" >1847811.000000</td>\n",
              "      <td id=\"T_6cfa4_row1_col10\" class=\"data row1 col10\" >2.000000</td>\n",
              "      <td id=\"T_6cfa4_row1_col11\" class=\"data row1 col11\" >2.000000</td>\n",
              "      <td id=\"T_6cfa4_row1_col12\" class=\"data row1 col12\" >1.000000</td>\n",
              "      <td id=\"T_6cfa4_row1_col13\" class=\"data row1 col13\" >2.000000</td>\n",
              "      <td id=\"T_6cfa4_row1_col14\" class=\"data row1 col14\" >1.000000</td>\n",
              "      <td id=\"T_6cfa4_row1_col15\" class=\"data row1 col15\" >1.000000</td>\n",
              "      <td id=\"T_6cfa4_row1_col16\" class=\"data row1 col16\" >3.000000</td>\n",
              "      <td id=\"T_6cfa4_row1_col17\" class=\"data row1 col17\" >str</td>\n",
              "      <td id=\"T_6cfa4_row1_col18\" class=\"data row1 col18\" >RMSprop</td>\n",
              "      <td id=\"T_6cfa4_row1_col19\" class=\"data row1 col19\" >{'name': 'sequential', 'layers...</td>\n",
              "      <td id=\"T_6cfa4_row1_col20\" class=\"data row1 col20\" >2233032.000000</td>\n",
              "      <td id=\"T_6cfa4_row1_col21\" class=\"data row1 col21\" >AIModelShare</td>\n",
              "      <td id=\"T_6cfa4_row1_col22\" class=\"data row1 col22\" >1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n"
            ],
            "text/plain": [
              "<pandas.io.formats.style.Styler at 0x7f713be3a910>"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bwNKs0wP4r5s"
      },
      "source": [
        "## 5. Repeat submission process to improve place on leaderboard\n",
        "*Train and submit your own models using code modeled after what you see above.*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tukB40NshcaB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "16611d80-80fc-4e7b-c3b9-47d3ca544ec9"
      },
      "source": [
        "# Here are several classic ML architectures you can consider choosing from to experiment with next:\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "\n",
        "#Example code to fit model:\n",
        "model = RandomForestClassifier(n_estimators = 300, max_depth = 2, random_state=0)\n",
        "model.fit(X_train, y_train) # Fitting to the training set.\n",
        "model.score(X_train, y_train)\n",
        "\n",
        "# Save sklearn model to local ONNX file\n",
        "from aimodelshare.aimsonnx import model_to_onnx\n",
        "\n",
        "feature_count=X_test.shape[1] #Get count of preprocessed features\n",
        "initial_type = [('float_input', FloatTensorType([None, feature_count]))]  # Insert correct number of preprocessed features\n",
        "\n",
        "onnx_model = model_to_onnx(model, framework='sklearn',\n",
        "                          initial_types=initial_type,\n",
        "                          transfer_learning=False,\n",
        "                          deep_learning=False)\n",
        "\n",
        "with open(\"model.onnx\", \"wb\") as f:\n",
        "    f.write(onnx_model.SerializeToString())\n",
        "\n",
        "#-- Generate predicted values (a list of predicted labels \"real\" or \"fake\")\n",
        "prediction_labels = model.predict(X_test)\n",
        "\n",
        "# Submit model to Competition Leaderboard\n",
        "mycompetition.submit_model(model_filepath = \"model.onnx\",\n",
        "                                 preprocessor_filepath=\"preprocessor.zip\",\n",
        "                                 prediction_submission=prediction_labels)\n"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Insert search tags to help users find your model (optional): \n",
            "Provide any useful notes about your model (optional): \n",
            "\n",
            "Your model has been submitted as model version 3\n",
            "\n",
            "To submit code used to create this model or to view current leaderboard navigate to Model Playground: \n",
            "\n",
            " https://www.modelshare.org/detail/model:1535\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "It may also be useful to examine the architeture of models that perform particuarly well/poorly, or to compare models you've created with similar models submitted by others. Use the compare_models function in combination with the leaderboard to learn more about models that been previously submitted and potentially make decisiona about what you should do next."
      ],
      "metadata": {
        "id": "yL5Im_H0UMFE"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 438
        },
        "id": "qLl7yLpVEx26",
        "outputId": "9545898c-55b7-43e8-ff6e-b3f0848ce97b"
      },
      "source": [
        "# Compare two or more models\n",
        "data=mycompetition.compare_models([2, 3], verbose=1)\n",
        "mycompetition.stylize_compare(data)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<style type=\"text/css\">\n",
              "#T_38e87_ caption {\n",
              "  color: black;\n",
              "  font-size: 18px;\n",
              "}\n",
              "#T_38e87_row4_col2, #T_38e87_row4_col3, #T_38e87_row13_col3, #T_38e87_row16_col2, #T_38e87_row16_col3 {\n",
              "  background: tomato;\n",
              "}\n",
              "</style>\n",
              "<table id=\"T_38e87_\">\n",
              "  <caption>Model type: RandomForestClassifier</caption>\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th class=\"blank level0\" >&nbsp;</th>\n",
              "      <th class=\"col_heading level0 col0\" >param_name</th>\n",
              "      <th class=\"col_heading level0 col1\" >default_value</th>\n",
              "      <th class=\"col_heading level0 col2\" >model_version_2</th>\n",
              "      <th class=\"col_heading level0 col3\" >model_version_3</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th id=\"T_38e87_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
              "      <td id=\"T_38e87_row0_col0\" class=\"data row0 col0\" >bootstrap</td>\n",
              "      <td id=\"T_38e87_row0_col1\" class=\"data row0 col1\" >True</td>\n",
              "      <td id=\"T_38e87_row0_col2\" class=\"data row0 col2\" >True</td>\n",
              "      <td id=\"T_38e87_row0_col3\" class=\"data row0 col3\" >True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_38e87_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
              "      <td id=\"T_38e87_row1_col0\" class=\"data row1 col0\" >ccp_alpha</td>\n",
              "      <td id=\"T_38e87_row1_col1\" class=\"data row1 col1\" >0.000000</td>\n",
              "      <td id=\"T_38e87_row1_col2\" class=\"data row1 col2\" >0.000000</td>\n",
              "      <td id=\"T_38e87_row1_col3\" class=\"data row1 col3\" >0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_38e87_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
              "      <td id=\"T_38e87_row2_col0\" class=\"data row2 col0\" >class_weight</td>\n",
              "      <td id=\"T_38e87_row2_col1\" class=\"data row2 col1\" >None</td>\n",
              "      <td id=\"T_38e87_row2_col2\" class=\"data row2 col2\" >None</td>\n",
              "      <td id=\"T_38e87_row2_col3\" class=\"data row2 col3\" >None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_38e87_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
              "      <td id=\"T_38e87_row3_col0\" class=\"data row3 col0\" >criterion</td>\n",
              "      <td id=\"T_38e87_row3_col1\" class=\"data row3 col1\" >gini</td>\n",
              "      <td id=\"T_38e87_row3_col2\" class=\"data row3 col2\" >gini</td>\n",
              "      <td id=\"T_38e87_row3_col3\" class=\"data row3 col3\" >gini</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_38e87_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
              "      <td id=\"T_38e87_row4_col0\" class=\"data row4 col0\" >max_depth</td>\n",
              "      <td id=\"T_38e87_row4_col1\" class=\"data row4 col1\" >None</td>\n",
              "      <td id=\"T_38e87_row4_col2\" class=\"data row4 col2\" >3</td>\n",
              "      <td id=\"T_38e87_row4_col3\" class=\"data row4 col3\" >2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_38e87_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
              "      <td id=\"T_38e87_row5_col0\" class=\"data row5 col0\" >max_features</td>\n",
              "      <td id=\"T_38e87_row5_col1\" class=\"data row5 col1\" >auto</td>\n",
              "      <td id=\"T_38e87_row5_col2\" class=\"data row5 col2\" >auto</td>\n",
              "      <td id=\"T_38e87_row5_col3\" class=\"data row5 col3\" >auto</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_38e87_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
              "      <td id=\"T_38e87_row6_col0\" class=\"data row6 col0\" >max_leaf_nodes</td>\n",
              "      <td id=\"T_38e87_row6_col1\" class=\"data row6 col1\" >None</td>\n",
              "      <td id=\"T_38e87_row6_col2\" class=\"data row6 col2\" >None</td>\n",
              "      <td id=\"T_38e87_row6_col3\" class=\"data row6 col3\" >None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_38e87_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
              "      <td id=\"T_38e87_row7_col0\" class=\"data row7 col0\" >max_samples</td>\n",
              "      <td id=\"T_38e87_row7_col1\" class=\"data row7 col1\" >None</td>\n",
              "      <td id=\"T_38e87_row7_col2\" class=\"data row7 col2\" >None</td>\n",
              "      <td id=\"T_38e87_row7_col3\" class=\"data row7 col3\" >None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_38e87_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
              "      <td id=\"T_38e87_row8_col0\" class=\"data row8 col0\" >min_impurity_decrease</td>\n",
              "      <td id=\"T_38e87_row8_col1\" class=\"data row8 col1\" >0.000000</td>\n",
              "      <td id=\"T_38e87_row8_col2\" class=\"data row8 col2\" >0.000000</td>\n",
              "      <td id=\"T_38e87_row8_col3\" class=\"data row8 col3\" >0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_38e87_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
              "      <td id=\"T_38e87_row9_col0\" class=\"data row9 col0\" >min_impurity_split</td>\n",
              "      <td id=\"T_38e87_row9_col1\" class=\"data row9 col1\" >None</td>\n",
              "      <td id=\"T_38e87_row9_col2\" class=\"data row9 col2\" >None</td>\n",
              "      <td id=\"T_38e87_row9_col3\" class=\"data row9 col3\" >None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_38e87_level0_row10\" class=\"row_heading level0 row10\" >10</th>\n",
              "      <td id=\"T_38e87_row10_col0\" class=\"data row10 col0\" >min_samples_leaf</td>\n",
              "      <td id=\"T_38e87_row10_col1\" class=\"data row10 col1\" >1</td>\n",
              "      <td id=\"T_38e87_row10_col2\" class=\"data row10 col2\" >1</td>\n",
              "      <td id=\"T_38e87_row10_col3\" class=\"data row10 col3\" >1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_38e87_level0_row11\" class=\"row_heading level0 row11\" >11</th>\n",
              "      <td id=\"T_38e87_row11_col0\" class=\"data row11 col0\" >min_samples_split</td>\n",
              "      <td id=\"T_38e87_row11_col1\" class=\"data row11 col1\" >2</td>\n",
              "      <td id=\"T_38e87_row11_col2\" class=\"data row11 col2\" >2</td>\n",
              "      <td id=\"T_38e87_row11_col3\" class=\"data row11 col3\" >2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_38e87_level0_row12\" class=\"row_heading level0 row12\" >12</th>\n",
              "      <td id=\"T_38e87_row12_col0\" class=\"data row12 col0\" >min_weight_fraction_leaf</td>\n",
              "      <td id=\"T_38e87_row12_col1\" class=\"data row12 col1\" >0.000000</td>\n",
              "      <td id=\"T_38e87_row12_col2\" class=\"data row12 col2\" >0.000000</td>\n",
              "      <td id=\"T_38e87_row12_col3\" class=\"data row12 col3\" >0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_38e87_level0_row13\" class=\"row_heading level0 row13\" >13</th>\n",
              "      <td id=\"T_38e87_row13_col0\" class=\"data row13 col0\" >n_estimators</td>\n",
              "      <td id=\"T_38e87_row13_col1\" class=\"data row13 col1\" >100</td>\n",
              "      <td id=\"T_38e87_row13_col2\" class=\"data row13 col2\" >100</td>\n",
              "      <td id=\"T_38e87_row13_col3\" class=\"data row13 col3\" >300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_38e87_level0_row14\" class=\"row_heading level0 row14\" >14</th>\n",
              "      <td id=\"T_38e87_row14_col0\" class=\"data row14 col0\" >n_jobs</td>\n",
              "      <td id=\"T_38e87_row14_col1\" class=\"data row14 col1\" >None</td>\n",
              "      <td id=\"T_38e87_row14_col2\" class=\"data row14 col2\" >None</td>\n",
              "      <td id=\"T_38e87_row14_col3\" class=\"data row14 col3\" >None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_38e87_level0_row15\" class=\"row_heading level0 row15\" >15</th>\n",
              "      <td id=\"T_38e87_row15_col0\" class=\"data row15 col0\" >oob_score</td>\n",
              "      <td id=\"T_38e87_row15_col1\" class=\"data row15 col1\" >False</td>\n",
              "      <td id=\"T_38e87_row15_col2\" class=\"data row15 col2\" >False</td>\n",
              "      <td id=\"T_38e87_row15_col3\" class=\"data row15 col3\" >False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_38e87_level0_row16\" class=\"row_heading level0 row16\" >16</th>\n",
              "      <td id=\"T_38e87_row16_col0\" class=\"data row16 col0\" >random_state</td>\n",
              "      <td id=\"T_38e87_row16_col1\" class=\"data row16 col1\" >None</td>\n",
              "      <td id=\"T_38e87_row16_col2\" class=\"data row16 col2\" >0</td>\n",
              "      <td id=\"T_38e87_row16_col3\" class=\"data row16 col3\" >0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_38e87_level0_row17\" class=\"row_heading level0 row17\" >17</th>\n",
              "      <td id=\"T_38e87_row17_col0\" class=\"data row17 col0\" >verbose</td>\n",
              "      <td id=\"T_38e87_row17_col1\" class=\"data row17 col1\" >0</td>\n",
              "      <td id=\"T_38e87_row17_col2\" class=\"data row17 col2\" >0</td>\n",
              "      <td id=\"T_38e87_row17_col3\" class=\"data row17 col3\" >0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_38e87_level0_row18\" class=\"row_heading level0 row18\" >18</th>\n",
              "      <td id=\"T_38e87_row18_col0\" class=\"data row18 col0\" >warm_start</td>\n",
              "      <td id=\"T_38e87_row18_col1\" class=\"data row18 col1\" >False</td>\n",
              "      <td id=\"T_38e87_row18_col2\" class=\"data row18 col2\" >False</td>\n",
              "      <td id=\"T_38e87_row18_col3\" class=\"data row18 col3\" >False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\n"
          ]
        }
      ]
    }
  ]
}