{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "website_edit_Raudi_Notebook_4.17.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.5"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0BviI4QIdWiq"
      },
      "source": [
        "<p align=\"center\"><img width=\"50%\" src=\"https://aimodelsharecontent.s3.amazonaws.com/aimodshare_banner.jpg\" /></p>\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gYNp684Tk3tb"
      },
      "source": [
        "<p align=\"center\"><h1 align=\"center\">Quick Start: Titanic Tabular Classification Tutorial</h1> \n",
        "\n",
        "---\n",
        "\n",
        "<h3 align=\"center\">(Deploy model to an AI Model Share Model Playground REST API<br> and Web Dashboard in five easy steps...)</h3></p>\n",
        "<p align=\"center\"><img width=\"100%\" src=\"https://aimodelsharecontent.s3.amazonaws.com/aimstutorialsteps.gif\" /></p>\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0PhJ-XlGazpD"
      },
      "source": [
        "## **Credential Configuration**\n",
        "\n",
        "In order to deploy an AI Model Share Model Playground, you will need a credentials text file. \n",
        "\n",
        "Generating your credentials file requires two sets of information: \n",
        "1. Your AI Model Share username and password (create them [HERE](https://www.modelshare.org/login)). \n",
        "2. Your AWS (Amazon Web Services) access keys (follow the tutorial [HERE](https://docs.aws.amazon.com/general/latest/gr/aws-sec-cred-types.html)). \n",
        "\n",
        "You only need to generate your credentials file once. After running the configure function below, save the outputted file for all your future Model Playground deployments and competition submissions. \n",
        "\n",
        "*Note: Handle your credentials file with the same level of security you handle your passwords. Do not share your file with anyone, send via email, or upload to Github.*\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "puVzQBHyhS2Z"
      },
      "source": [
        "#install aimodelshare library\n",
        "! pip install aimodelshare-nightly"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Q7MCqBLcS20",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "55069ba9-1350-4c0f-e10c-3b56f743eef2"
      },
      "source": [
        "# Generate credentials file\n",
        "import aimodelshare as ai \n",
        "from aimodelshare.aws import configure_credentials \n",
        "\n",
        "configure_credentials()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AI Modelshare Username:··········\n",
            "AI Modelshare Password:··········\n",
            "AWS_ACCESS_KEY_ID:··········\n",
            "AWS_SECRET_ACCESS_KEY:··········\n",
            "AWS_REGION:··········\n",
            "Configuration successful. New credentials file saved as 'credentials.txt'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VliTV_HH-uz4"
      },
      "source": [
        "## **Set up Environment**\n",
        "\n",
        "Use your credentials file to set your credentials for all aimodelshare functions. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2u1QKNfEyN9A",
        "outputId": "e9658e5b-f950-4cad-83b8-f6cccd67466e"
      },
      "source": [
        "# Set credentials \n",
        "from aimodelshare.aws import set_credentials\n",
        "\n",
        "set_credentials(credential_file=\"credentials.txt\", type=\"deploy_model\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AI Model Share login credentials set successfully.\n",
            "AWS credentials set successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PwQcTsyyURIk",
        "outputId": "935a6608-1eb1-4598-ca02-cc080132f795"
      },
      "source": [
        "# Get materials for tutorial\n",
        "import aimodelshare as ai\n",
        "X_train, X_test, y_train, y_test, example_data, y_test_labels = ai.import_quickstart_data(\"titanic\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading [===>                                             ]\n",
            "\n",
            "Data downloaded successfully.\n",
            "\n",
            "Preparing downloaded files for use...\n",
            "\n",
            "Success! Your Quick Start materials have been downloaded. \n",
            "You are now ready to run the tutorial.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bIleM1F6nWSF"
      },
      "source": [
        "## **(1) Preprocessor Function & Setup**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Generate Pyspark Dataframe**"
      ],
      "metadata": {
        "id": "OcFmoioNdsn9"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B5Jz-1cmYN5Z"
      },
      "source": [
        "import pyspark\n",
        "\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.ml.feature import StringIndexer, OneHotEncoder\n",
        "from pyspark.ml.feature import Imputer, VectorAssembler\n",
        "from pyspark.ml.feature import StandardScaler, IndexToString\n",
        "\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.types import FloatType\n",
        "from pyspark.sql.functions import col\n",
        "\n",
        "# initiate spark session\n",
        "spark = SparkSession \\\n",
        "    .builder \\\n",
        "    .appName('Titanic Data') \\\n",
        "    .getOrCreate()\n",
        "\n",
        "numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
        "\n",
        "numeric_columns = X_train.select_dtypes(include=numerics).columns.to_list()\n",
        "categorical_columns = X_train.select_dtypes(exclude=numerics).columns.to_list()\n",
        "\n",
        "# load the data\n",
        "training_data = (\n",
        "    spark.read \\\n",
        "    .csv(\"titanic_competition_data/training_data.csv\", header=True)\n",
        ")\n",
        "\n",
        "# There is a limitation in column name\n",
        "for i, column in enumerate(numeric_columns):\n",
        "    training_data = training_data.withColumn(column, col(column).cast(FloatType()))\n",
        "    \n",
        "# load the data\n",
        "test_data = (\n",
        "    spark.read \\\n",
        "    .csv(\"titanic_competition_data/test_data.csv\", header=True)\n",
        ")\n",
        "\n",
        "# There is a limitation in column name\n",
        "for i, column in enumerate(numeric_columns):\n",
        "    test_data = test_data.withColumn(column, col(column).cast(FloatType()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WrEgo5zRxbed"
      },
      "source": [
        "### **Write a Preprocessor Function**\n",
        "\n",
        "\n",
        "> ###   Preprocessor functions are used to preprocess data into the precise data your model requires to generate predictions.  \n",
        "\n",
        "*  *Preprocessor functions should always be named \"preprocessor\".*\n",
        "*  *You can use any Python library in a preprocessor function, but all libraries should be imported inside your preprocessor function.*  \n",
        "*  *For tabular prediction models users should minimally include function inputs for an unpreprocessed pandas dataframe.*  \n",
        "*  *Any categorical features should be preprocessed to one hot encoded numeric values.* \n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create the preprocessing pipelines for both numeric and categorical data\n",
        "imputed_numeric_features = [\"imputed_\" + x for x in numeric_columns]\n",
        "imputed_categorical_features = [\"imputed_\" + x for x in categorical_columns]\n",
        "indexed_categorical_features = [\"indexed_\" + x for x in categorical_columns]\n",
        "one_hot_categorical_features = [\"one_hot_\" + x for x in categorical_columns]\n",
        "features =  imputed_numeric_features + one_hot_categorical_features\n",
        "\n",
        "preprocess = Pipeline(stages=[\n",
        "    Imputer(\n",
        "        strategy='median',\n",
        "        inputCols=numeric_columns,\n",
        "        outputCols=imputed_numeric_features\n",
        "    ),\n",
        "    StringIndexer(\n",
        "        inputCols=categorical_columns, \n",
        "        outputCols=indexed_categorical_features, \n",
        "        handleInvalid='keep'\n",
        "    ),\n",
        "    Imputer(\n",
        "        strategy='mode',\n",
        "        inputCols=indexed_categorical_features,\n",
        "        outputCols=imputed_categorical_features\n",
        "    ),\n",
        "    OneHotEncoder(\n",
        "        inputCols=imputed_categorical_features, \n",
        "        outputCols=one_hot_categorical_features,\n",
        "        dropLast=False\n",
        "    ),\n",
        "    VectorAssembler(\n",
        "        inputCols=features,\n",
        "        outputCol='features'\n",
        "    ),\n",
        "    StandardScaler(\n",
        "        inputCol='features',\n",
        "        outputCol='scaled_features',\n",
        "        withStd=True,\n",
        "        withMean=False\n",
        "    ),\n",
        "\n",
        "])\n",
        "\n",
        "label_indexer = StringIndexer(\n",
        "    inputCol='survived', \n",
        "    outputCol='indexed_label', \n",
        "    handleInvalid='skip'\n",
        ")\n",
        "\n",
        "# Main preprocessor\n",
        "preprocess_model = preprocess.fit(training_data)\n",
        "\n",
        "# To convert float label into string label\n",
        "label_indexer_model = label_indexer.fit(training_data)"
      ],
      "metadata": {
        "id": "4zH2awBvdfmt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Wu1tiP2S-eP"
      },
      "source": [
        "The current prediction API runtime can only digest Pandas Dataframe, therefore we need to create preprocessor functions for pandas dataframe (prediction API runtime) and pyspark dataframe (this notebook).\n",
        "\n",
        "\n",
        "-- Here is where we actually write the preprocessor function:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5D_6sac6nQUx"
      },
      "source": [
        "# Write function to transform data with preprocessor\n",
        "\n",
        "# Prediction API runtime preprocessor function for onnx model\n",
        "# the input is pandas dataframe\n",
        "def preprocessor(df_data):\n",
        "    import numpy as np\n",
        "    import os\n",
        "    import tempfile\n",
        "\n",
        "    # initiate spark session\n",
        "    spark = SparkSession.builder \\\n",
        "            .master(\"local[1]\") \\\n",
        "            .appName(\"Preprocessor Titanic Data\") \\\n",
        "            .getOrCreate()\n",
        "\n",
        "    # load the data\n",
        "    # we can only use /tmp in lambda\n",
        "    # https://aws.amazon.com/blogs/compute/choosing-between-aws-lambda-data-storage-options-in-web-apps/\n",
        "    temp_dir = tempfile.gettempdir()\n",
        "    temp_csv_path = temp_dir + \"/temp_preprocessor_data.csv\"\n",
        "    df_data.to_csv(temp_csv_path)\n",
        "    df_data = spark.read.csv(temp_csv_path, header=True)\n",
        "    \n",
        "    for i, column in enumerate(numeric_columns):\n",
        "        df_data = df_data.withColumn(column, col(column).cast(FloatType()))\n",
        "\n",
        "    preprocessed_data = preprocess_model.transform(df_data)\n",
        "    \n",
        "    def to_array(x):\n",
        "        return x[0].toArray().astype(np.float32)\n",
        "\n",
        "    input_data = preprocessed_data.select('scaled_features').toPandas().values\n",
        "\n",
        "    input_data = np.apply_along_axis(to_array, 1, input_data)\n",
        "\n",
        "    os.remove(temp_csv_path)\n",
        "    \n",
        "    return input_data\n",
        "\n",
        "# For pyspark training and testing code\n",
        "# the input is spark dataframe\n",
        "def preprocess_training(data):\n",
        "    return label_indexer_model.transform(preprocess_model.transform(data))\n",
        "\n",
        "# test data doesn't contain label\n",
        "def preprocess_test(data):\n",
        "    return preprocess_model.transform(data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xp_TTwew8jYU",
        "outputId": "1d098296-496b-4006-d82b-439d5d670123"
      },
      "source": [
        "# check data after preprocessing it using our new function\n",
        "preprocess_training(training_data).show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+------+------+-------+--------+--------+--------------+-----------+------------+-----------+----------------+-----------+----------------+-------------+----------------+--------------------+--------------------+-------------+\n",
            "|pclass|   sex|   age|   fare|embarked|survived|imputed_pclass|imputed_age|imputed_fare|indexed_sex|indexed_embarked|imputed_sex|imputed_embarked|  one_hot_sex|one_hot_embarked|            features|     scaled_features|indexed_label|\n",
            "+------+------+------+-------+--------+--------+--------------+-----------+------------+-----------+----------------+-----------+----------------+-------------+----------------+--------------------+--------------------+-------------+\n",
            "|   1.0|  male|  44.0|   90.0|       Q|    died|           1.0|       44.0|        90.0|        0.0|             2.0|        0.0|             2.0|(2,[0],[1.0])|   (4,[2],[1.0])|[1.0,44.0,90.0,1....|[1.19848275660349...|          0.0|\n",
            "|   3.0|  male|  null|   7.75|       Q|    died|           3.0|       28.0|        7.75|        0.0|             2.0|        0.0|             2.0|(2,[0],[1.0])|   (4,[2],[1.0])|[3.0,28.0,7.75,1....|[3.59544826981049...|          0.0|\n",
            "|   1.0|female|  38.0|   80.0|    null|survived|           1.0|       38.0|        80.0|        1.0|             3.0|        1.0|             3.0|(2,[1],[1.0])|   (4,[3],[1.0])|[1.0,38.0,80.0,0....|[1.19848275660349...|          1.0|\n",
            "|   3.0|female|  null|  7.225|       C|survived|           3.0|       28.0|       7.225|        1.0|             1.0|        1.0|             1.0|(2,[1],[1.0])|   (4,[1],[1.0])|[3.0,28.0,7.22499...|[3.59544826981049...|          1.0|\n",
            "|   1.0|  male|  37.0|52.5542|       S|survived|           1.0|       37.0|     52.5542|        0.0|             0.0|        0.0|             0.0|(2,[0],[1.0])|   (4,[0],[1.0])|[1.0,37.0,52.5541...|[1.19848275660349...|          1.0|\n",
            "|   3.0|  male|  19.0|   8.05|       S|survived|           3.0|       19.0|        8.05|        0.0|             0.0|        0.0|             0.0|(2,[0],[1.0])|   (4,[0],[1.0])|[3.0,19.0,8.05000...|[3.59544826981049...|          1.0|\n",
            "|   3.0|  male|  null| 7.8958|       C|    died|           3.0|       28.0|      7.8958|        0.0|             1.0|        0.0|             1.0|(2,[0],[1.0])|   (4,[1],[1.0])|[3.0,28.0,7.89580...|[3.59544826981049...|          0.0|\n",
            "|   2.0|female|  24.0|   26.0|       S|survived|           2.0|       24.0|        26.0|        1.0|             0.0|        1.0|             0.0|(2,[1],[1.0])|   (4,[0],[1.0])|[2.0,24.0,26.0,0....|[2.39696551320699...|          1.0|\n",
            "|   3.0|  male|  18.0|14.4542|       C|    died|           3.0|       18.0|     14.4542|        0.0|             1.0|        0.0|             1.0|(2,[0],[1.0])|   (4,[1],[1.0])|[3.0,18.0,14.4541...|[3.59544826981049...|          0.0|\n",
            "|   1.0|female|  16.0|57.9792|       C|survived|           1.0|       16.0|     57.9792|        1.0|             1.0|        1.0|             1.0|(2,[1],[1.0])|   (4,[1],[1.0])|[1.0,16.0,57.9791...|[1.19848275660349...|          1.0|\n",
            "|   2.0|female|  27.0|   10.5|       S|survived|           2.0|       27.0|        10.5|        1.0|             0.0|        1.0|             0.0|(2,[1],[1.0])|   (4,[0],[1.0])|[2.0,27.0,10.5,0....|[2.39696551320699...|          1.0|\n",
            "|   3.0|  male|  74.0|  7.775|       S|    died|           3.0|       74.0|       7.775|        0.0|             0.0|        0.0|             0.0|(2,[0],[1.0])|   (4,[0],[1.0])|[3.0,74.0,7.77500...|[3.59544826981049...|          0.0|\n",
            "|   3.0|female|  null| 7.8792|       Q|survived|           3.0|       28.0|      7.8792|        1.0|             2.0|        1.0|             2.0|(2,[1],[1.0])|   (4,[2],[1.0])|[3.0,28.0,7.87919...|[3.59544826981049...|          1.0|\n",
            "|   2.0|  male|   1.0|   39.0|       S|survived|           2.0|        1.0|        39.0|        0.0|             0.0|        0.0|             0.0|(2,[0],[1.0])|   (4,[0],[1.0])|[2.0,1.0,39.0,1.0...|[2.39696551320699...|          1.0|\n",
            "|   3.0|female|  30.0|  24.15|       S|    died|           3.0|       30.0|       24.15|        1.0|             0.0|        1.0|             0.0|(2,[1],[1.0])|   (4,[0],[1.0])|[3.0,30.0,24.1499...|[3.59544826981049...|          0.0|\n",
            "|   3.0|  male|0.8333|   9.35|       S|survived|           3.0|     0.8333|        9.35|        0.0|             0.0|        0.0|             0.0|(2,[0],[1.0])|   (4,[0],[1.0])|[3.0,0.8332999944...|[3.59544826981049...|          1.0|\n",
            "|   2.0|  male|  38.0|   21.0|       S|    died|           2.0|       38.0|        21.0|        0.0|             0.0|        0.0|             0.0|(2,[0],[1.0])|   (4,[0],[1.0])|[2.0,38.0,21.0,1....|[2.39696551320699...|          0.0|\n",
            "|   3.0|  male|  21.0|    7.8|       S|    died|           3.0|       21.0|         7.8|        0.0|             0.0|        0.0|             0.0|(2,[0],[1.0])|   (4,[0],[1.0])|[3.0,21.0,7.80000...|[3.59544826981049...|          0.0|\n",
            "|   2.0|  male|  43.0|  26.25|       S|    died|           2.0|       43.0|       26.25|        0.0|             0.0|        0.0|             0.0|(2,[0],[1.0])|   (4,[0],[1.0])|[2.0,43.0,26.25,1...|[2.39696551320699...|          0.0|\n",
            "|   2.0|female|  24.0|   65.0|       S|survived|           2.0|       24.0|        65.0|        1.0|             0.0|        1.0|             0.0|(2,[1],[1.0])|   (4,[0],[1.0])|[2.0,24.0,65.0,0....|[2.39696551320699...|          1.0|\n",
            "+------+------+------+-------+--------+--------+--------------+-----------+------------+-----------+----------------+-----------+----------------+-------------+----------------+--------------------+--------------------+-------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xJlhd6jvns0b"
      },
      "source": [
        "## **(2) Build Model Using pyspark (or Your Preferred ML Library)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fP7ZIVKe3luZ"
      },
      "source": [
        "### **Logistic Regression with L1 Regularization (Lasso)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HB7uImQbn088",
        "outputId": "b6cd9e12-2df0-4f54-c5e8-d8ad284dd2a2"
      },
      "source": [
        "from pyspark.ml.classification import LogisticRegression\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "\n",
        "# instantiate pyspark estimator\n",
        "lr_1 = Pipeline(stages=[\n",
        "    LogisticRegression(\n",
        "        regParam=10, \n",
        "        elasticNetParam=1.0, \n",
        "        featuresCol='scaled_features', \n",
        "        labelCol='indexed_label',\n",
        "        predictionCol='indexed_prediction'\n",
        "    ),\n",
        "    IndexToString(\n",
        "        inputCol=\"indexed_prediction\", \n",
        "        outputCol=\"prediction\", \n",
        "        labels=label_indexer_model.labels,\n",
        "    )\n",
        "])\n",
        "\n",
        "# Fit the model\n",
        "model = lr_1.fit(preprocess_training(training_data))\n",
        "\n",
        "# Evaluate our model\n",
        "predictions = model.transform(preprocess_training(training_data))\n",
        "\n",
        "evaluator = MulticlassClassificationEvaluator(\n",
        "    labelCol='indexed_label', \n",
        "    predictionCol='indexed_prediction', \n",
        "    metricName='accuracy')\n",
        "accuracy = evaluator.evaluate(predictions)\n",
        "accuracy"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6198662846227316"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FZGlu5PMWbNO"
      },
      "source": [
        "## **(3) Save Preprocessor**\n",
        "### Saves preprocessor function to \"preprocessor.zip\" file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wh_vkwblXx7r"
      },
      "source": [
        "import aimodelshare as ai\n",
        "ai.export_preprocessor(preprocessor,\"\") "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b58rg4pMMn4n"
      },
      "source": [
        "#  Now let's import and test the preprocessor function to see if it is working...\n",
        "\n",
        "import aimodelshare as ai\n",
        "prep=ai.import_preprocessor(\"preprocessor.zip\")\n",
        "\n",
        "# check the data after preprocessing \n",
        "prep(X_test).shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CdQOeF2J3PCv"
      },
      "source": [
        "## **(4) Save pyspark model to Onnx File Format**\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "temp = preprocess_model.transform(training_data)\n",
        "\n",
        "one_hot_feature_count = 0\n",
        "for feature_name in one_hot_categorical_features:\n",
        "    one_hot_feature_count += len(temp.collect()[0][feature_name])\n",
        "\n",
        "feature_count =  len(imputed_numeric_features) + one_hot_feature_count # structure of sparse vector"
      ],
      "metadata": {
        "id": "AiDUfc8zhvlE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r8fgi8f6qkbk"
      },
      "source": [
        "# Save pyspark model to local ONNX file\n",
        "from onnxmltools.convert.common.data_types import FloatTensorType\n",
        "from aimodelshare.aimsonnx import model_to_onnx\n",
        "\n",
        "# specify intial types of predictors\n",
        "initial_types = [('scaled_features', FloatTensorType([None, feature_count]))]\n",
        "\n",
        "# transform pyspark model to ONNX\n",
        "framework = 'pyspark'\n",
        "onnx_model = model_to_onnx(model, framework, initial_types=initial_types,\n",
        "                           spark_session=spark, transfer_learning=False, \n",
        "                           deep_learning=False)\n",
        "\n",
        "# Save model to local .onnx file\n",
        "with open(\"model.onnx\", \"wb\") as f:\n",
        "    f.write(onnx_model.SerializeToString())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1swt74XQUIFh"
      },
      "source": [
        "## **(5) Create your Model Playground and Deploy REST API/ Live Web-Application**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y-YKEcvDNmD3"
      },
      "source": [
        "#Set up arguments for Model Playground deployment\n",
        "import pandas as pd \n",
        "\n",
        "model_filepath = \"model.onnx\"\n",
        "preprocessor_filepath = \"preprocessor.zip\"\n",
        "exampledata = example_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T8C6IlYTFN5t"
      },
      "source": [
        "from aimodelshare import ModelPlayground\n",
        "\n",
        "#Instantiate ModelPlayground() Class\n",
        "\n",
        "myplayground=ModelPlayground(model_type=\"tabular\", classification=True, private=False)\n",
        "\n",
        "# Create Model Playground (generates live rest api and web-app for your model/preprocessor)\n",
        "\n",
        "myplayground.deploy(model_filepath, preprocessor_filepath, y_train, exampledata, pyspark_support=True, timeout=60) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eb9dfUFHhLr-"
      },
      "source": [
        "## **Use your new Model Playground!**\n",
        "\n",
        "Follow the link in the output above to:\n",
        "- Generate predictions with your interactive web dashboard\n",
        "- Access example code in Python, R, and Curl\n",
        "\n",
        "Or, follow the rest of the tutorial to create a competition for your Model Playground and: \n",
        "- Access verified model performance metrics \n",
        "- Upload multiple models to a leaderboard \n",
        "- Easily compare model performance & structure "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9YpyLkQNfqSI"
      },
      "source": [
        "## **Part 2: Create a Competition**\n",
        "\n",
        "-------\n",
        "\n",
        "After deploying your Model Playground, you can now create a competition. \n",
        "\n",
        "Creating a competition allows you to:\n",
        "1. Verify the model performance metrics on aimodelshare.org\n",
        "2. Submit models to a leaderboard\n",
        "3. Grant access to other users to submit models to the leaderboard\n",
        "4. Easily compare model performance and structure "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define Custom Evaluation Metrics (optional)"
      ],
      "metadata": {
        "id": "srRRbKfJAJip"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Eval metrics can be defined from scratch or use functions from other libraries (e.g., sklearn)\n",
        "# If you want multiple custom metrics, please make sure that the function returns a dict\n",
        "# The keys of the dict will be used as column identifiers in the leaderboard\n",
        "\n",
        "def custom_eval_metric(y_true, y_pred): \n",
        "\n",
        "  from sklearn.metrics import balanced_accuracy_score\n",
        "  from sklearn.metrics import f1_score\n",
        "\n",
        "  bal_acc = balanced_accuracy_score(y_true, y_pred)\n",
        "  f1_weighted = f1_score(y_true, y_pred, average='weighted')\n",
        "\n",
        "  metrics = {\"f1_weighted\": f1_weighted ,\n",
        "             \"balanced_accuracy\": bal_acc}\n",
        "\n",
        "  return metrics"
      ],
      "metadata": {
        "id": "opf8uX4v6EDX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Export custom evaluation function to zip file\n",
        "from aimodelshare.custom_eval_metrics import export_eval_metric\n",
        "export_eval_metric(custom_eval_metric, '', 'custom_eval')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d6269d52-92db-4368-dc56-ea8320db4009",
        "id": "SGM8MKna6EDY"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Your eval_metric is now saved to 'custom_eval.zip'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create Competition"
      ],
      "metadata": {
        "id": "hL0Z5KkzAFW1"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b7Zr5m6ocqzr"
      },
      "source": [
        "# Create list of authorized participants for competition\n",
        "# Note that participants should use the same email address when creating modelshare.org account\n",
        "emaillist=[\"pra2118@columbia.edu\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o2nKrLAMgc9o",
        "outputId": "c68c5019-f55a-4103-eb00-123b4c04d498",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Create Competition\n",
        "myplayground.create_competition(data_directory='titanic_competition_data', \n",
        "                                y_test = y_test_labels,\n",
        "                                eval_metric_filepath = 'custom_eval.zip',\n",
        "                                email_list=emaillist)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "custom_eval.zip\n",
            "\n",
            "--INPUT COMPETITION DETAILS--\n",
            "\n",
            "Enter competition name:test\n",
            "Enter competition description:\n",
            "\n",
            "--INPUT DATA DETAILS--\n",
            "\n",
            "Note: (optional) Save an optional LICENSE.txt file in your competition data directory to make users aware of any restrictions on data sharing/usage.\n",
            "\n",
            "Enter data description (i.e.- filenames denoting training and test data, file types, and any subfolders where files are stored):\n",
            "Enter optional data license descriptive name (e.g.- 'MIT, Apache 2.0, CC0, Other, etc.'):\n",
            "Uploading your data. Please wait for a confirmation message.\n",
            "\n",
            " Success! Model competition created. \n",
            "\n",
            "You may now update your prediction API runtime model and verify evaluation metrics with the update_runtime_model() function.\n",
            "\n",
            "To upload new models and/or preprocessors to this API, team members should use \n",
            "the following credentials:\n",
            "\n",
            "apiurl='https://xa6ln3rdr8.execute-api.us-east-1.amazonaws.com/prod/m'\n",
            "from aimodelshare.aws import set_credentials\n",
            "set_credentials(apiurl=apiurl)\n",
            "\n",
            "They can then submit models to your competition by using the following code: \n",
            "\n",
            "competition= ai.Competition(apiurl)\n",
            "download_data('public.ecr.aws/u8x7c3d2/titanic_competition_data-repository:latest') \n",
            "# Use this data to preprocess data and train model. Write and save preprocessor fxn, save model to onnx file, generate predicted y values\n",
            " using X test data, then submit a model below.\n",
            "\n",
            "competition.submit_model(model_filepath, preprocessor_filepath, prediction_submission_list)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SAJJWhdAfyo5"
      },
      "source": [
        "#Instantiate Competition\n",
        "#--Note: If you start a new session, the first argument should be the Model Playground url in quotes. \n",
        "#--e.g.- mycompetition= ai.Competition(\"https://2121212.execute-api.us-east-1.amazonaws.com/prod/m)\n",
        "#See Model Playground \"Compete\" tab for example model submission code.\n",
        "mycompetition= ai.Competition(myplayground.playground_url)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lnuZaLTxcwA2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "922e8a49-57b7-4a05-9fdb-d13d9085c9fb"
      },
      "source": [
        "\n",
        "# Add, remove, or completely update authorized participants for competition later\n",
        "emaillist=[\"emailaddress4@email.com\"]\n",
        "\n",
        "mycompetition.update_access_list(email_list=emaillist,update_type=\"Add\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['pra2118@columbia.edu', 'pra2118@columbia.edu', 'emailaddress4@email.com']\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Success: Your competition participant access list is now updated.'"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mqyzWZPwgoEH"
      },
      "source": [
        "Submit Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pPVcAXJ3czS1"
      },
      "source": [
        "#Authorized users can submit new models after setting credentials using modelshare.org username/password\n",
        "\n",
        "from aimodelshare.aws import set_credentials\n",
        "\n",
        "set_credentials(apiurl=myplayground.playground_url) # example url from deployed playground: apiurl= \"https://123456.execute-api.us-east-1.amazonaws.com/prod/m"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pJC2jl2PgfTf",
        "outputId": "e08a7795-b5e4-4183-c130-b39df480d226"
      },
      "source": [
        "#Submit Model 1: \n",
        "\n",
        "#-- Generate predicted values (a list of predicted labels \"survived\" or \"died\") (Model 1)\n",
        "predictions = model.transform(preprocess_test(test_data))\n",
        "prediction_index = predictions.select('prediction').toPandas().to_numpy()\n",
        "\n",
        "# Submit Model 1 to Competition Leaderboard\n",
        "mycompetition.submit_model(model_filepath = \"model.onnx\",\n",
        "                                 preprocessor_filepath=\"preprocessor.zip\",\n",
        "                                 prediction_submission=prediction_index)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Insert search tags to help users find your model (optional): \n",
            "Provide any useful notes about your model (optional): \n",
            "\n",
            "Your model has been submitted as model version 1\n",
            "\n",
            "To submit code used to create this model or to view current leaderboard navigate to Model Playground: \n",
            "\n",
            " https://www.modelshare.org/detail/model:1460\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hpzXNVPTop-O"
      },
      "source": [
        "# Create model 2 (L2 Regularization - Ridge)\n",
        "# instantiate pyspark estimator\n",
        "lr_2 = Pipeline(stages=[\n",
        "    LogisticRegression(\n",
        "        regParam=10, \n",
        "        elasticNetParam=0.0, \n",
        "        featuresCol='scaled_features', \n",
        "        labelCol='indexed_label',\n",
        "        predictionCol='indexed_prediction'\n",
        "    ),\n",
        "    IndexToString(\n",
        "        inputCol=\"indexed_prediction\", \n",
        "        outputCol=\"prediction\", \n",
        "        labels=label_indexer_model.labels,\n",
        "    )\n",
        "])\n",
        "\n",
        "# Fit the model\n",
        "model_2 = lr_2.fit(preprocess_training(training_data))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jraPDdsNX46e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "53e4297b-08ca-458c-ef7f-90c978c4fce4"
      },
      "source": [
        "# Save Model 2 to .onnx file\n",
        "# transform pyspark model to ONNX\n",
        "framework = 'pyspark'\n",
        "onnx_model = model_to_onnx(model_2, framework, initial_types=initial_types, \n",
        "                          spark_session=spark, transfer_learning=False,\n",
        "                          deep_learning=False)\n",
        "\n",
        "# Save model to local .onnx file\n",
        "with open(\"model_2.onnx\", \"wb\") as f:\n",
        "    f.write(onnx_model.SerializeToString())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'classlabels_ints': [0, 1],\n",
            " 'coefficients': [0.015509647857829247,\n",
            "                  0.0013041722755419913,\n",
            "                  -0.011493781488800765,\n",
            "                  0.02496369969047826,\n",
            "                  -0.024963699690478184,\n",
            "                  0.007439672349634482,\n",
            "                  -0.008861733293314019,\n",
            "                  0.0009338777959797627,\n",
            "                  -0.0024943580382469116,\n",
            "                  -0.015509647857829247,\n",
            "                  -0.0013041722755419913,\n",
            "                  0.011493781488800765,\n",
            "                  -0.02496369969047826,\n",
            "                  0.024963699690478184,\n",
            "                  -0.007439672349634482,\n",
            "                  0.008861733293314019,\n",
            "                  -0.0009338777959797627,\n",
            "                  0.0024943580382469116],\n",
            " 'intercepts': [0.386037263192894, -0.386037263192894],\n",
            " 'multi_class': 1,\n",
            " 'name': 'LinearClassifier',\n",
            " 'post_transform': 'LOGISTIC'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cme7T_gaYWlD",
        "outputId": "46031ff0-2903-490b-b66b-0bea542fe733"
      },
      "source": [
        "# Submit Model 2\n",
        "\n",
        "#-- Generate predicted y values (Model 2)\n",
        "predictions = model_2.transform(preprocess_test(test_data))\n",
        "prediction_index = predictions.select('prediction').toPandas().to_numpy()\n",
        "\n",
        "# Submit Model 2 to Competition Leaderboard\n",
        "mycompetition.submit_model(model_filepath=\"model_2.onnx\",\n",
        "                           preprocessor_filepath=\"preprocessor.zip\",\n",
        "                           prediction_submission=prediction_index)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Insert search tags to help users find your model (optional): \n",
            "Provide any useful notes about your model (optional): \n",
            "\n",
            "Your model has been submitted as model version 2\n",
            "\n",
            "To submit code used to create this model or to view current leaderboard navigate to Model Playground: \n",
            "\n",
            " https://www.modelshare.org/detail/model:1460\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Submit Predictions Only"
      ],
      "metadata": {
        "id": "lQJYzGi9_OHn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Submit predictions to Competition Leaderboard without the need to submit an ONNX object\n",
        "# This option can be used if the predictions were generated with a ML framework that is currently not supported\n",
        "# The model will be evaluated and represented in the leaderboard, but no other model metadata will be extracted automatically\n",
        "predictions = model.transform(preprocess_test(test_data))\n",
        "prediction_index = predictions.select('prediction').toPandas().to_numpy()\n",
        "\n",
        "mycompetition.submit_model(model_filepath = None,\n",
        "                           preprocessor_filepath=None,\n",
        "                           prediction_submission=prediction_index)"
      ],
      "metadata": {
        "id": "01_oESUM-5Er",
        "outputId": "37e4acbc-10c7-41a6-ee18-ebd9adad4a3d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Insert search tags to help users find your model (optional): \n",
            "Provide any useful notes about your model (optional): \n",
            "\n",
            "Your model has been submitted as model version 3\n",
            "\n",
            "To submit code used to create this model or to view current leaderboard navigate to Model Playground: \n",
            "\n",
            " https://www.modelshare.org/detail/model:1460\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Submit Model With Custom Metadata"
      ],
      "metadata": {
        "id": "mJdWDAbyBNWD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Custom metadata can be added by passing a dict to the custom_metadata argument of the submit_model() method\n",
        "# This option can be used to fill in missing data points or add new columns to the leaderboard\n",
        "\n",
        "custom_meta = {'team': 'one',\n",
        "               'model_type': 'your_model_type',\n",
        "               'new_column': 'new metadata'}\n",
        "\n",
        "mycompetition.submit_model(model_filepath = None,\n",
        "                                 preprocessor_filepath=None,\n",
        "                                 prediction_submission=prediction_index,\n",
        "                                 custom_metadata = custom_meta)"
      ],
      "metadata": {
        "id": "bDtBWMk6BMWk",
        "outputId": "7a91c86b-e96d-4803-f18b-ead23a782989",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Insert search tags to help users find your model (optional): \n",
            "Provide any useful notes about your model (optional): \n",
            "\n",
            "Your model has been submitted as model version 4\n",
            "\n",
            "To submit code used to create this model or to view current leaderboard navigate to Model Playground: \n",
            "\n",
            " https://www.modelshare.org/detail/model:1460\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iLYlCkWchWC_"
      },
      "source": [
        "Get Leaderboard"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 240
        },
        "id": "J0-B1h0chYDL",
        "outputId": "12998e44-9303-4f58-d56e-f5fdeb35fe92"
      },
      "source": [
        "data = mycompetition.get_leaderboard()\n",
        "mycompetition.stylize_leaderboard(data)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<style type=\"text/css\">\n",
              "#T_e8c42_row0_col0, #T_e8c42_row1_col0, #T_e8c42_row2_col0, #T_e8c42_row3_col0 {\n",
              "  text-align: center;\n",
              "  width: 10em;\n",
              "  height: 80%;\n",
              "  background: linear-gradient(90deg,#f5f8d6 65.3%, transparent 65.3%);\n",
              "  color: #251e1b;\n",
              "  font-size: 12px;\n",
              "}\n",
              "#T_e8c42_row0_col1, #T_e8c42_row1_col1, #T_e8c42_row2_col1, #T_e8c42_row3_col1 {\n",
              "  text-align: center;\n",
              "  width: 10em;\n",
              "  height: 80%;\n",
              "  background: linear-gradient(90deg,#c778c8 39.5%, transparent 39.5%);\n",
              "  color: #251e1b;\n",
              "  font-size: 12px;\n",
              "}\n",
              "#T_e8c42_row0_col2, #T_e8c42_row1_col2, #T_e8c42_row2_col2, #T_e8c42_row3_col2 {\n",
              "  text-align: center;\n",
              "  width: 10em;\n",
              "  height: 80%;\n",
              "  background: linear-gradient(90deg,#ff4971 32.6%, transparent 32.6%);\n",
              "  color: #251e1b;\n",
              "  font-size: 12px;\n",
              "}\n",
              "#T_e8c42_row0_col3, #T_e8c42_row1_col3, #T_e8c42_row2_col3, #T_e8c42_row3_col3 {\n",
              "  text-align: center;\n",
              "  width: 10em;\n",
              "  height: 80%;\n",
              "  background: linear-gradient(90deg,#aadbaa 50.0%, transparent 50.0%);\n",
              "  color: #251e1b;\n",
              "  font-size: 12px;\n",
              "}\n",
              "#T_e8c42_row0_col4, #T_e8c42_row0_col5, #T_e8c42_row0_col6, #T_e8c42_row0_col7, #T_e8c42_row0_col8, #T_e8c42_row0_col9, #T_e8c42_row0_col10, #T_e8c42_row0_col11, #T_e8c42_row0_col12, #T_e8c42_row0_col13, #T_e8c42_row1_col4, #T_e8c42_row1_col5, #T_e8c42_row1_col6, #T_e8c42_row1_col7, #T_e8c42_row1_col8, #T_e8c42_row1_col9, #T_e8c42_row1_col10, #T_e8c42_row1_col11, #T_e8c42_row1_col12, #T_e8c42_row1_col13, #T_e8c42_row2_col4, #T_e8c42_row2_col5, #T_e8c42_row2_col6, #T_e8c42_row2_col7, #T_e8c42_row2_col8, #T_e8c42_row2_col9, #T_e8c42_row2_col10, #T_e8c42_row2_col11, #T_e8c42_row2_col12, #T_e8c42_row2_col13, #T_e8c42_row3_col4, #T_e8c42_row3_col5, #T_e8c42_row3_col6, #T_e8c42_row3_col7, #T_e8c42_row3_col8, #T_e8c42_row3_col9, #T_e8c42_row3_col10, #T_e8c42_row3_col11, #T_e8c42_row3_col12, #T_e8c42_row3_col13 {\n",
              "  text-align: center;\n",
              "}\n",
              "</style>\n",
              "<table id=\"T_e8c42_\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th class=\"blank level0\" >&nbsp;</th>\n",
              "      <th class=\"col_heading level0 col0\" >accuracy</th>\n",
              "      <th class=\"col_heading level0 col1\" >f1_score</th>\n",
              "      <th class=\"col_heading level0 col2\" >precision</th>\n",
              "      <th class=\"col_heading level0 col3\" >recall</th>\n",
              "      <th class=\"col_heading level0 col4\" >f1_weighted</th>\n",
              "      <th class=\"col_heading level0 col5\" >balanced_accuracy</th>\n",
              "      <th class=\"col_heading level0 col6\" >ml_framework</th>\n",
              "      <th class=\"col_heading level0 col7\" >model_type</th>\n",
              "      <th class=\"col_heading level0 col8\" >num_params</th>\n",
              "      <th class=\"col_heading level0 col9\" >model_config</th>\n",
              "      <th class=\"col_heading level0 col10\" >new_column</th>\n",
              "      <th class=\"col_heading level0 col11\" >team</th>\n",
              "      <th class=\"col_heading level0 col12\" >username</th>\n",
              "      <th class=\"col_heading level0 col13\" >version</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th id=\"T_e8c42_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
              "      <td id=\"T_e8c42_row0_col0\" class=\"data row0 col0\" >65.27%</td>\n",
              "      <td id=\"T_e8c42_row0_col1\" class=\"data row0 col1\" >39.49%</td>\n",
              "      <td id=\"T_e8c42_row0_col2\" class=\"data row0 col2\" >32.63%</td>\n",
              "      <td id=\"T_e8c42_row0_col3\" class=\"data row0 col3\" >50.00%</td>\n",
              "      <td id=\"T_e8c42_row0_col4\" class=\"data row0 col4\" >0.515505</td>\n",
              "      <td id=\"T_e8c42_row0_col5\" class=\"data row0 col5\" >0.500000</td>\n",
              "      <td id=\"T_e8c42_row0_col6\" class=\"data row0 col6\" >pyspark</td>\n",
              "      <td id=\"T_e8c42_row0_col7\" class=\"data row0 col7\" >LogisticRegressionModel</td>\n",
              "      <td id=\"T_e8c42_row0_col8\" class=\"data row0 col8\" >9.000000</td>\n",
              "      <td id=\"T_e8c42_row0_col9\" class=\"data row0 col9\" >{'aggregationDepth': 2, 'elast...</td>\n",
              "      <td id=\"T_e8c42_row0_col10\" class=\"data row0 col10\" >nan</td>\n",
              "      <td id=\"T_e8c42_row0_col11\" class=\"data row0 col11\" >nan</td>\n",
              "      <td id=\"T_e8c42_row0_col12\" class=\"data row0 col12\" >raudipra</td>\n",
              "      <td id=\"T_e8c42_row0_col13\" class=\"data row0 col13\" >1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_e8c42_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
              "      <td id=\"T_e8c42_row1_col0\" class=\"data row1 col0\" >65.27%</td>\n",
              "      <td id=\"T_e8c42_row1_col1\" class=\"data row1 col1\" >39.49%</td>\n",
              "      <td id=\"T_e8c42_row1_col2\" class=\"data row1 col2\" >32.63%</td>\n",
              "      <td id=\"T_e8c42_row1_col3\" class=\"data row1 col3\" >50.00%</td>\n",
              "      <td id=\"T_e8c42_row1_col4\" class=\"data row1 col4\" >0.515505</td>\n",
              "      <td id=\"T_e8c42_row1_col5\" class=\"data row1 col5\" >0.500000</td>\n",
              "      <td id=\"T_e8c42_row1_col6\" class=\"data row1 col6\" >pyspark</td>\n",
              "      <td id=\"T_e8c42_row1_col7\" class=\"data row1 col7\" >LogisticRegressionModel</td>\n",
              "      <td id=\"T_e8c42_row1_col8\" class=\"data row1 col8\" >9.000000</td>\n",
              "      <td id=\"T_e8c42_row1_col9\" class=\"data row1 col9\" >{'aggregationDepth': 2, 'elast...</td>\n",
              "      <td id=\"T_e8c42_row1_col10\" class=\"data row1 col10\" >nan</td>\n",
              "      <td id=\"T_e8c42_row1_col11\" class=\"data row1 col11\" >nan</td>\n",
              "      <td id=\"T_e8c42_row1_col12\" class=\"data row1 col12\" >raudipra</td>\n",
              "      <td id=\"T_e8c42_row1_col13\" class=\"data row1 col13\" >2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_e8c42_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
              "      <td id=\"T_e8c42_row2_col0\" class=\"data row2 col0\" >65.27%</td>\n",
              "      <td id=\"T_e8c42_row2_col1\" class=\"data row2 col1\" >39.49%</td>\n",
              "      <td id=\"T_e8c42_row2_col2\" class=\"data row2 col2\" >32.63%</td>\n",
              "      <td id=\"T_e8c42_row2_col3\" class=\"data row2 col3\" >50.00%</td>\n",
              "      <td id=\"T_e8c42_row2_col4\" class=\"data row2 col4\" >0.515505</td>\n",
              "      <td id=\"T_e8c42_row2_col5\" class=\"data row2 col5\" >0.500000</td>\n",
              "      <td id=\"T_e8c42_row2_col6\" class=\"data row2 col6\" >unknown</td>\n",
              "      <td id=\"T_e8c42_row2_col7\" class=\"data row2 col7\" >unknown</td>\n",
              "      <td id=\"T_e8c42_row2_col8\" class=\"data row2 col8\" >nan</td>\n",
              "      <td id=\"T_e8c42_row2_col9\" class=\"data row2 col9\" >None...</td>\n",
              "      <td id=\"T_e8c42_row2_col10\" class=\"data row2 col10\" >nan</td>\n",
              "      <td id=\"T_e8c42_row2_col11\" class=\"data row2 col11\" >nan</td>\n",
              "      <td id=\"T_e8c42_row2_col12\" class=\"data row2 col12\" >raudipra</td>\n",
              "      <td id=\"T_e8c42_row2_col13\" class=\"data row2 col13\" >3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_e8c42_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
              "      <td id=\"T_e8c42_row3_col0\" class=\"data row3 col0\" >65.27%</td>\n",
              "      <td id=\"T_e8c42_row3_col1\" class=\"data row3 col1\" >39.49%</td>\n",
              "      <td id=\"T_e8c42_row3_col2\" class=\"data row3 col2\" >32.63%</td>\n",
              "      <td id=\"T_e8c42_row3_col3\" class=\"data row3 col3\" >50.00%</td>\n",
              "      <td id=\"T_e8c42_row3_col4\" class=\"data row3 col4\" >0.515505</td>\n",
              "      <td id=\"T_e8c42_row3_col5\" class=\"data row3 col5\" >0.500000</td>\n",
              "      <td id=\"T_e8c42_row3_col6\" class=\"data row3 col6\" >unknown</td>\n",
              "      <td id=\"T_e8c42_row3_col7\" class=\"data row3 col7\" >your_model_type</td>\n",
              "      <td id=\"T_e8c42_row3_col8\" class=\"data row3 col8\" >nan</td>\n",
              "      <td id=\"T_e8c42_row3_col9\" class=\"data row3 col9\" >None...</td>\n",
              "      <td id=\"T_e8c42_row3_col10\" class=\"data row3 col10\" >new metadata</td>\n",
              "      <td id=\"T_e8c42_row3_col11\" class=\"data row3 col11\" >one</td>\n",
              "      <td id=\"T_e8c42_row3_col12\" class=\"data row3 col12\" >raudipra</td>\n",
              "      <td id=\"T_e8c42_row3_col13\" class=\"data row3 col13\" >4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n"
            ],
            "text/plain": [
              "<pandas.io.formats.style.Styler at 0x7fedc780ce10>"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g_bklL3shOER"
      },
      "source": [
        "Compare Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "quo_V3A3hNS3"
      },
      "source": [
        "# Compare two or more models \n",
        "data=mycompetition.compare_models([1,2,3,4], verbose=1)\n",
        "mycompetition.stylize_compare(data)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FKm9ugiBhQFn"
      },
      "source": [
        "#### Check structure of y test data \n",
        "(This helps users understand how to submit predicted values to leaderboard)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dqY82D22hPZx",
        "outputId": "ad23d856-f094-4024-ff9d-385cc67926a8"
      },
      "source": [
        "mycompetition.inspect_y_test()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'class_balance': {'died': 171, 'survived': 91},\n",
              " 'class_labels': ['died', 'survived'],\n",
              " 'label_dtypes': {\"<class 'str'>\": 262},\n",
              " 'y_length': 262,\n",
              " 'ytest_example': ['survived', 'died', 'died', 'survived', 'died']}"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iA-nYjr7WCIp"
      },
      "source": [
        "## **Part 3: Maintaining your Model Playground**\n",
        "\n",
        "-------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0UIWnHIXWM0F"
      },
      "source": [
        "Update Runtime model\n",
        "\n",
        "*Use this function to 1) update the prediction API behind your Model Playground with a new model, chosen from the leaderboard and 2) verify the modelperformance metrics in your Model Playground*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wAchpcGLWLxE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d4bab5d-5961-4bdd-fddc-ebf43e84c6f2"
      },
      "source": [
        "myplayground.update_runtime_model(model_version=2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Runtime model & preprocessor for api: https://xa6ln3rdr8.execute-api.us-east-1.amazonaws.com/prod/m updated to model version 2.\n",
            "\n",
            "Model metrics are now updated and verified for this model playground.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xhJRaiN-WaO1"
      },
      "source": [
        "Delete Deployment \n",
        "\n",
        "*Use this function to delete the entire Model Playground, including the REST API, web dashboard, competition, and all submitted models*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mCkf-exLWyDK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 100
        },
        "outputId": "18c3b43a-fc31-472e-f559-3932787ed320"
      },
      "source": [
        "myplayground.delete_deployment()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running this function will permanently delete all resources tied to this deployment, \n",
            " including the eval lambda and all models submitted to the model competition.\n",
            "\n",
            "To confirm, type 'permanently delete':permanently delete\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Deployment deleted successfully.'"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "uWzpOOR9fpdy"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}