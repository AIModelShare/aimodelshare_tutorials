{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "W19EexvEUC6C",
        "ir2LcWyQM66k"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<p align=\"center\"><img width=\"50%\" src=\"https://aimodelsharecontent.s3.amazonaws.com/aimodshare_banner.jpg\" /></p>\n",
        "\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "Lv1XBVquWDKL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p align=\"center\"><h1 align=\"center\">Quick Start: Deploy ML Model into REST API that Uses Customized Serverless Function Code </h1> \n",
        "\n",
        "---\n",
        "\n",
        "<h3 align=\"center\">(Deploy a production-ready REST API and serverless function in 10 minutes...)</h3></p>\n",
        "\n",
        "\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "9kH5pszoWHIY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install aimodelshare --upgrade"
      ],
      "metadata": {
        "id": "D8ylJ1RCeb7E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W19EexvEUC6C"
      },
      "source": [
        "# **Deploying an ML Model Using the aimodelshare Library**\n",
        "\n",
        "> This tutorial will take you through how to deploy a machine learning model on AWS's serverless computing infrastructure using the Python library. \n",
        ">\n",
        ">**This tutorial has five steps:** \n",
        "> 1. [Train a Model](#step-1)\n",
        "> 2. [Save Objects to Local Folder](#step-2)\n",
        "> 3. [Define Expected REST API Input And Output JSON](#step-3)\n",
        "> 4. [Write Code to Accept REST API Input and Return Output (Custom Code used in live Serverless Lambda)](#step-4)\n",
        "> 5. [Deploy Model into REST API On AWS Using AI Model Share Initiative's aimodelshare Library](#step-5)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-n049VbGeNHT"
      },
      "source": [
        "<a name=\"step-1\"></a>\n",
        "# **[1] Train Model**\n",
        "\n",
        "> We will cheat to speed things up rather than training a model.  Let's import a pretrained image classification model.  The model classifies images into five flower categories.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import aimodelshare as ai\n",
        "keras_model, y_train_labels = ai.import_quickstart_data(\"flowers\")\n",
        "\n"
      ],
      "metadata": {
        "id": "Hm_3cDULE9AB",
        "outputId": "6508951c-f4b9-43dd-d2a1-94a1ee726f3e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading [================================================>]\n",
            "\n",
            "Data downloaded successfully.\n",
            "\n",
            "Preparing downloaded files for use...\n",
            "\n",
            "Success! Your Quick Start materials have been downloaded. \n",
            "You are now ready to run the tutorial.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-00z-y6ElPaR"
      },
      "source": [
        "<a name=\"step-2\"></a>\n",
        "# **[2] Prepare Deployment Folder**\n",
        "\n",
        "> Here we simply create a folder named \"deploy\" to store any files you need available in your deployment environment (i.e.- your model file and preprocessor). This folder will be uploaded to AWS's serverless computing infrastructure. \n",
        ">\n",
        ">**The steps to prepare the deployment folder consist of:**\n",
        "> 1. Create Deployment Folder\n",
        "> 2. Save Model to Deployment Folder"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BOE_YRp4_3zU"
      },
      "source": [
        "### **[2.1] Create Deployment Folder**\n",
        "\n",
        "> Create a new folder with a suitable name to store all the required files and folders in."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u2aeBKlES0b0"
      },
      "source": [
        "deployment_folder = 'deploy'\n",
        "\n",
        "import os\n",
        "if os.path.isdir(deployment_folder):\n",
        "    shutil.rmtree(deployment_folder)\n",
        "os.mkdir(deployment_folder)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8o63hf9kAO8r"
      },
      "source": [
        "### **[2.2] Save Model To Deployment Folder**\n",
        "\n",
        "> We are using the Onnx Python library to save a model because it only requires a light library to save space in the final serverless function, but you can use Tensorflow or Pytorch among other options."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ptdx-Z8u_2bl"
      },
      "source": [
        "# convert TensorFlow Keras model to ONNX model\n",
        "from aimodelshare.aimsonnx import model_to_onnx\n",
        "onnx_model = model_to_onnx(keras_model,\n",
        "                           framework='keras',\n",
        "                           transfer_learning=False,\n",
        "                           deep_learning=True)\n",
        "\n",
        "# save the model to the deployment folder\n",
        "with open(os.path.join(deployment_folder, \"runtime_model.onnx\"), \"wb\") as f:\n",
        "    f.write(onnx_model.SerializeToString())"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iPcmjUbATJ0l"
      },
      "source": [
        "<a name=\"step-3\"></a>\n",
        "# **[3] Define Input And Output JSON Formats**\n",
        "\n",
        "Define the input and output JSON that your REST API requires to successfully process a request through the code in your Serverless function (see example code in final step below!)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pxaGPQpcUC70"
      },
      "source": [
        "The input JSON structure we are using here has 'data' as the key and its value is in the form of a base64 encoded image string.  Base64 encoding allows REST APIs to send files like images as strings.:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oPjiE_pRfyHJ"
      },
      "source": [
        "input_json_exampledata = {\n",
        "         \"data\": \"base64 encoded string\"\n",
        "    }"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NPciNXa9UGng"
      },
      "source": [
        "The output JSON structure we are using here is a list with a single string label:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3XY2Ha7HgYQt"
      },
      "source": [
        "output_json_exampledata = [\"label\"]"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L3JbLynz-_UW"
      },
      "source": [
        "<a name=\"step-4\"></a>\n",
        "# **[4] Write Serverless Fxn Code to Process Image Input into Output**\n",
        "\n",
        "> Serverless code will:\n",
        "> 1. Load the model and code to preprocess/transform image data into the global runtime environment\n",
        "> 2. Preprocess the input passed\n",
        "> 3. Pass preprocessed input to model and generate prediction\n",
        "> 4. Return prediction to output result\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gRsNO5pua_6n"
      },
      "source": [
        "custom_lambda_handler_code = \"\"\"\n",
        "\n",
        "# Importing all the required libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import six\n",
        "import imghdr\n",
        "import base64\n",
        "import json\n",
        "import onnxruntime as rt\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "# load the ML model in global environment for faster inference time for subsequent function calls\n",
        "model_file_path = 'runtime_model.onnx'\n",
        "model = rt.InferenceSession('./' + model_file_path)\n",
        "\n",
        "# this is the preprocessor function \n",
        "def preprocessor(data, shape=(192, 192)):\n",
        "\n",
        "    # Resize a color image and min/max transform the image\n",
        "    img = cv2.imread(data) # read in image from filepath\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB) # cv2 reads in images in order of BGR, we convert the order to RGB\n",
        "    img = cv2.resize(img, shape) # change height and width of image\n",
        "    img = img / 255.0 # min/max transform\n",
        "\n",
        "    # Convert cv2 image to NumPy array\n",
        "    X = np.array(img) # converting to NumPy array\n",
        "    X = np.expand_dims(X, axis=0) # increase dimensions to convert object shape to [1, h, w, channels]\n",
        "    X = np.array(X, dtype=np.float32) # reduce precision for faster training and inferencing\n",
        "\n",
        "    return X\n",
        "\n",
        "# this is the predict function to preprocess image data and generate predictions from our model\n",
        "def predict(image_path):\n",
        "\n",
        "    # labels corresponding to the index that is predicted\n",
        "    labels = ['daisy', 'dandelion', 'roses', 'sunflowers', 'tulips']\n",
        "\n",
        "    # preprocessing the input data\n",
        "    input_data = preprocessor(image_path)\n",
        "    \n",
        "    # generate prediction\n",
        "    input_name = model.get_inputs()[0].name\n",
        "    res = model.run(None, {input_name: input_data})\n",
        "    prob = res[0]\n",
        "\n",
        "    # map label to index with highest probability\n",
        "    index = prob.argmax(axis=-1)\n",
        "    result = list(map(lambda x: labels[x], index))\n",
        "\n",
        "    return result\n",
        "\n",
        "### event['body'] is the input JSON data from REST API request ###\n",
        "\n",
        "def handler(event, context):\n",
        "\n",
        "    # Contents of 'body' key is string, converting content to JSON object\n",
        "    body = event['body']\n",
        "    if isinstance(body, six.string_types):\n",
        "        body = json.loads(body)\n",
        "\n",
        "    # Fetching image in the form of a base64 encoded string stored within 'data' key of body\n",
        "    data = body['data']\n",
        "\n",
        "    # Decoding base64 encoded string into required data type\n",
        "    sample = base64.b64decode(data)\n",
        "\n",
        "    # Predict function requires path to image file as argument, saving data to file\n",
        "    temp_file = \"/tmp/temp_file\"\n",
        "    with open(temp_file, \"wb\") as fh:\n",
        "        fh.write(sample)\n",
        "\n",
        "    # Calling the  predict function\n",
        "    result = predict(temp_file)\n",
        "\n",
        "    # Deleting the image file created by the user for prediction\n",
        "    os.remove(temp_file)\n",
        "\n",
        "    # Returning predictions to REST API output\n",
        "    result_dict = {\n",
        "        \"statusCode\": 200,\n",
        "        \"headers\": {\n",
        "            \"Access-Control-Allow-Origin\" : \"*\",\n",
        "            \"Access-Control-Allow-Credentials\": True,\n",
        "            \"Allow\" : \"GET, OPTIONS, POST\",\n",
        "            \"Access-Control-Allow-Methods\" : \"GET, OPTIONS, POST\",\n",
        "            \"Access-Control-Allow-Headers\" : \"*\"\n",
        "        },\n",
        "        \"body\":  json.dumps(result)\n",
        "    }\n",
        "    return result_dict \n",
        "\n",
        "\"\"\""
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PCSum_Or4mLk"
      },
      "source": [
        "#Save lambda serverless function code somewhere besideds \"deploy\" folder\n",
        "\n",
        "with open(\"custom_lambda_handler.py\", \"w\") as handler_file:\n",
        "    handler_file.writelines(custom_lambda_handler_code)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9BbJG9VJVjIz"
      },
      "source": [
        "<a name=\"step-5\"></a>\n",
        "# **[5] Deploy Model On AWS Using aimodelshare Library**\n",
        "\n",
        "> We have finally finished modifying the deployment folder. Now we can use the aimodelshare library to deploy our model on AWS's serverless computing infrastructure and generate an API endpoint. Simply set your AWS credentials and then run a single Python function to create your live REST API:\n",
        "> 1. Set AWS Credentials\n",
        "> 2. Deploy Model into Scalable REST API"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xrTnCy6gaTiX"
      },
      "source": [
        "### **[5.1] Setting AWS Credentials**\n",
        "\n",
        "> The path to the user's AWS credentials, credentials.txt, should be passed as the parameter to set_credentials function.\n",
        "\n",
        "#### **Need to create a credentials file?**  See [credentials instructions here](https://aimodelshare.readthedocs.io/en/latest/create_credentials.html#create-credentials)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9RMevbALaEvS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2e41725b-7d89-4b73-a1a2-6221599992dd"
      },
      "source": [
        "from aimodelshare.aws import set_credentials\n",
        "set_credentials(credential_file=\"credentials.txt\", type=\"deploy_model\", manual=False)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AI Model Share login credentials set successfully.\n",
            "AWS credentials set successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yQxhUiJcapsZ"
      },
      "source": [
        "### **[5.2] Deploying Model**\n",
        "\n",
        "> Now that your credentials are set, use the deploy_custom_lambda() function to create your REST API. \n",
        "\n",
        "deploy_custom_lambda requires the following arguments:\n",
        "> 1. input_json_exampldata: the format of the JSON input\n",
        "> 2. output_json_exampldata: the format of the JSON output\n",
        "> 3. custom_lambda_filepath: the relative path of the custom lambda handler (serverless function code) file\n",
        "> 4. deployment_dir: the deployment folder's relative path\n",
        "> 5. custom_libraries: all the libraries required for running the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YrgP1_VCVIZF"
      },
      "source": [
        "custom_lambda_filepath = \"custom_lambda_handler.py\"\n",
        "deployment_dir = \"deploy\"\n",
        "private = \"FALSE\"\n",
        "custom_libraries = \"onnxruntime,opencv-python,numpy,pandas,pillow\"\n",
        "\n",
        "from aimodelshare.deploy_custom_lambda import deploy_custom_lambda\n",
        "deploy_custom_lambda(input_json_exampledata,\n",
        "                     output_json_exampledata,\n",
        "                     custom_lambda_filepath,\n",
        "                     deployment_dir,\n",
        "                     private,\n",
        "                     custom_libraries=custom_libraries)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8tLqOqMcBU_L"
      },
      "source": [
        "**Let's test your new REST API by sending it a base64 encoded image:**\n",
        "> Note: If you get an API Timeout error, then you may need to wait a few mins for your REST API to be available on AWS.  Once you see information returned, it's live and ready to use.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T9X3XR09a_sz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a6dbfc4e-e0d9-405c-86db-e966de379f32"
      },
      "source": [
        "import base64\n",
        "import requests\n",
        "import json\n",
        "\n",
        "api_url = \"https://vnq5u7ryr6.execute-api.us-east-2.amazonaws.com/prod/m\"\n",
        "\n",
        "\n",
        "# Import example flower image and base64 encode\n",
        "with open(\"/content/quickstart_materials/example_data/100080576_f52e8ee070_n.jpg\", \"rb\") as image_file:\n",
        "  encoded_string = base64.b64encode(image_file.read())\n",
        "  data = json.dumps({\"data\": encoded_string.decode('utf-8') })\n",
        "\n",
        "# Set up authorization headers and add token (Your API token is available in your playground page...\n",
        "# under predict > programmatic)\n",
        "headers = {\"Content-Type\": \"application/json\", \"authorizationToken\": \"eyJraWQiOiIxRHBcL2FMakJvNmozdHRHZFd6dEVEbUR5V0FPN3JtVEVyaHRDRnltQmlVST0iLCJhbGciOiJSUzI1NiJ9.eyJjdXN0b206b3JnYW5pemF0aW9uIjoiQ29sdW1iaWEgVW5pdmVyc2l0eSBDb21wdXRlciBTY2llbmNlIiwic3ViIjoiMTA4YmM2OGQtN2YxYS00MGVmLWJmOWYtMWY1NDFkY2MwNTIwIiwiZW1haWxfdmVyaWZpZWQiOnRydWUsImlzcyI6Imh0dHBzOlwvXC9jb2duaXRvLWlkcC51cy1lYXN0LTIuYW1hem9uYXdzLmNvbVwvdXMtZWFzdC0yX1gzQlRHNzhnMiIsInBob25lX251bWJlcl92ZXJpZmllZCI6ZmFsc2UsImNvZ25pdG86dXNlcm5hbWUiOiJNTF9HZW5vbWljcyIsImF1ZCI6IjI1dnNzYm5lZDJiYmFvaTFxN3JzNGk5MTR1IiwiZXZlbnRfaWQiOiI1MTBiNTc3MC1mYmUwLTQ1YzItODg0OC1hNTgxOGNkYjAwNjciLCJ0b2tlbl91c2UiOiJpZCIsImF1dGhfdGltZSI6MTY2NTU4MjkyOCwibmFtZSI6Ik1hY2hpbmUgTGVhcm5pbmcgZm9yIEZ1bmN0aW9uYWwgR2Vub21pY3MiLCJwaG9uZV9udW1iZXIiOiIrMTIwMzg5MjI4OTAiLCJleHAiOjE2NjU2OTI0NTQsImlhdCI6MTY2NTYwNjA1NCwiZW1haWwiOiJhaW1vZGVsc2hhcmUyQGdtYWlsLmNvbSJ9.fSrxtriNK6FN60LCucta_Z_klGjvIzwDrMT1vTQ4YV7WNRdfG2L5VgTKxbX2lr6FgkNGRMLYjcwajiMnBHO8EB9LCpmz_Jrn--etHJtE5aGqVknIOh0CyhaY3GqTol2SC2vtILgy7ZveFW82Tjm25tbD5TBUWd4j-oNV7Z0oHOLxHS-3ZpQ_W7dCAIhosmhtmeq426wyfcOnpfvFldI9r-B1PrzfHIGXpmkhapJRA9THgK2fOmNcW1uKAKafmlnSRuNcLuHdhh9SaqT9T1KI72Y96uoU5G3F3YAT5NN0VHaNLg_nsThbEWMZrvS56EAGKJXrxhsEhTTnsmkCyDbk1A\" }\n",
        "\n",
        "prediction = requests.request(\"POST\", api_url, headers = headers, data=data)\n",
        "\n",
        "# Print prediction\n",
        "json.loads(prediction.text)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'statusCode': 200,\n",
              " 'headers': {'Access-Control-Allow-Origin': '*',\n",
              "  'Access-Control-Allow-Credentials': True,\n",
              "  'Allow': 'GET, OPTIONS, POST',\n",
              "  'Access-Control-Allow-Methods': 'GET, OPTIONS, POST',\n",
              "  'Access-Control-Allow-Headers': '*'},\n",
              " 'body': '[\"daisy\"]'}"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    }
  ]
}