{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "[TITANIC] Quick Start: Tabular Model Playground Deployment and Competition Creation.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.5"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0BviI4QIdWiq"
      },
      "source": [
        "<p align=\"center\"><img width=\"50%\" src=\"https://aimodelsharecontent.s3.amazonaws.com/aimodshare_banner.jpg\" /></p>\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gYNp684Tk3tb"
      },
      "source": [
        "<p align=\"center\"><h1 align=\"center\">Quick Start: Titanic Tabular Classification Tutorial</h1> \n",
        "\n",
        "---\n",
        "\n",
        "<h3 align=\"center\">(Deploy model to an AI Model Share Model Playground REST API<br> and Web Dashboard in five easy steps...)</h3></p>\n",
        "<p align=\"center\"><img width=\"100%\" src=\"https://aimodelsharecontent.s3.amazonaws.com/aimstutorialsteps.gif\" /></p>\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0PhJ-XlGazpD"
      },
      "source": [
        "## **Credential Configuration**\n",
        "\n",
        "In order to deploy an AI Model Share Model Playground, you will need a credentials text file. \n",
        "\n",
        "Generating your credentials file requires two sets of information: \n",
        "1. Your AI Model Share username and password (create them [HERE](https://www.modelshare.org/login)). \n",
        "2. Your AWS (Amazon Web Services) access keys (follow the tutorial [HERE](https://docs.aws.amazon.com/general/latest/gr/aws-sec-cred-types.html)). \n",
        "\n",
        "You only need to generate your credentials file once. After running the configure function below, save the outputted file for all your future Model Playground deployments and competition submissions. \n",
        "\n",
        "*Note: Handle your credentials file with the same level of security you handle your passwords. Do not share your file with anyone, send via email, or upload to Github.*\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "puVzQBHyhS2Z"
      },
      "source": [
        "#install aimodelshare library\n",
        "#! pip install aimodelshare\n",
        "! pip install --extra-index-url https://test.pypi.org/simple/ --upgrade aimodelsharedev==656.618.838\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Q7MCqBLcS20"
      },
      "source": [
        "# Generate credentials file\n",
        "import aimodelshare as ai \n",
        "from aimodelshare.aws import configure_credentials \n",
        "\n",
        "configure_credentials()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VliTV_HH-uz4"
      },
      "source": [
        "## **Set up Environment**\n",
        "\n",
        "Use your credentials file to set your credentials for all aimodelshare functions. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2u1QKNfEyN9A",
        "outputId": "b3d78688-d57b-4781-f75c-9d6c22a4c6e8"
      },
      "source": [
        "# Set credentials \n",
        "import aimodelshare as ai\n",
        "from aimodelshare.aws import set_credentials\n",
        "\n",
        "set_credentials(credential_file=\"credentials.txt\", type=\"deploy_model\")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AI Model Share login credentials set successfully.\n",
            "AWS credentials set successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PwQcTsyyURIk",
        "outputId": "e2b5bfda-3e90-41a2-ac52-f7963f560f15"
      },
      "source": [
        "# Get materials for tutorial\n",
        "import aimodelshare as ai\n",
        "X_train, X_test, y_train, y_test, example_data, y_test_labels = ai.import_quickstart_data(\"titanic\")"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading [====>                                            ]\n",
            "\n",
            "Data downloaded successfully.\n",
            "\n",
            "Preparing downloaded files for use...\n",
            "\n",
            "Success! Your Quick Start materials have been downloaded. \n",
            "You are now ready to run the tutorial.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bIleM1F6nWSF"
      },
      "source": [
        "## **(1) Preprocessor Function & Setup**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WrEgo5zRxbed"
      },
      "source": [
        "### **Write a Preprocessor Function**\n",
        "\n",
        "\n",
        "> ###   Preprocessor functions are used to preprocess data into the precise data your model requires to generate predictions.  \n",
        "\n",
        "*  *Preprocessor functions should always be named \"preprocessor\".*\n",
        "*  *You can use any Python library in a preprocessor function, but all libraries should be imported inside your preprocessor function.*  \n",
        "*  *For tabular prediction models users should minimally include function inputs for an unpreprocessed pandas dataframe.*  \n",
        "*  *Any categorical features should be preprocessed to one hot encoded numeric values.* \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B5Jz-1cmYN5Z"
      },
      "source": [
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "\n",
        "#Preprocess data using sklearn's Column Transformer approach\n",
        "\n",
        "# We create the preprocessing pipelines for both numeric and categorical data.\n",
        "numeric_features = ['age', 'fare']\n",
        "numeric_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='median')), #'imputer' names the step\n",
        "    ('scaler', StandardScaler())])\n",
        "\n",
        "categorical_features = ['embarked', 'sex', 'pclass']\n",
        "\n",
        "# Replacing missing values with Modal value and then one-hot encoding.\n",
        "categorical_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
        "    ('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
        "\n",
        "# Final preprocessor object set up with ColumnTransformer...\n",
        "\n",
        "preprocess = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', numeric_transformer, numeric_features),\n",
        "        ('cat', categorical_transformer, categorical_features)])\n",
        "\n",
        "# fit preprocessor to your data\n",
        "preprocess = preprocess.fit(X_train)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5D_6sac6nQUx"
      },
      "source": [
        "# Write function to transform data with preprocessor \n",
        "# In this case we use sklearn's Column transformer in our preprocessor function\n",
        "\n",
        "def preprocessor(data):\n",
        "    preprocessed_data=preprocess.transform(data)\n",
        "    return preprocessed_data"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xp_TTwew8jYU",
        "outputId": "5e359ebf-5e9e-415a-fb28-8b70adcca830"
      },
      "source": [
        "# check shape of X data \n",
        "preprocessor(X_train).shape"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1047, 10)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xJlhd6jvns0b"
      },
      "source": [
        "## **(2) Build Model Using sklearn (or Your Preferred ML Library)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fP7ZIVKe3luZ"
      },
      "source": [
        "### **Penalized Logit**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HB7uImQbn088",
        "outputId": "2d5d550a-e533-47e3-c533-fed3543e8c5d"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "model = LogisticRegression(C=10, penalty='l2')\n",
        "model.fit(preprocessor(X_train), y_train) # Fitting to the training set.\n",
        "model.score(preprocessor(X_train), y_train) # Fit score, 0-1 scale."
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7793696275071633"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FZGlu5PMWbNO"
      },
      "source": [
        "## **(3) Save Preprocessor**\n",
        "### Saves preprocessor function to \"preprocessor.zip\" file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wh_vkwblXx7r",
        "outputId": "0b3c8556-69d2-4183-e727-bdea77dc0950"
      },
      "source": [
        "import aimodelshare as ai\n",
        "ai.export_preprocessor(preprocessor,\"\") "
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Your preprocessor is now saved to 'preprocessor.zip'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b58rg4pMMn4n",
        "outputId": "dc71f57f-dfce-40e9-e8ea-733cb415bef1"
      },
      "source": [
        "#  Now let's import and test the preprocessor function to see if it is working...\n",
        "\n",
        "import aimodelshare as ai\n",
        "prep=ai.import_preprocessor(\"preprocessor.zip\")\n",
        "\n",
        "prep(X_test).shape"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(262, 10)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CdQOeF2J3PCv"
      },
      "source": [
        "## **(4) Save sklearn model to Onnx File Format**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r8fgi8f6qkbk"
      },
      "source": [
        "# Save sklearn model to local ONNX file\n",
        "from aimodelshare.aimsonnx import model_to_onnx\n",
        "\n",
        "# Check how many preprocessed input features are there?\n",
        "from skl2onnx.common.data_types import FloatTensorType\n",
        "initial_type = [('float_input', FloatTensorType([None, 10]))]  # You need to insert correct number of features in preprocesed data\n",
        "\n",
        "onnx_model = model_to_onnx(model, framework='sklearn',\n",
        "                          initial_types=initial_type,\n",
        "                          transfer_learning=False,\n",
        "                          deep_learning=False)\n",
        "\n",
        "with open(\"model.onnx\", \"wb\") as f:\n",
        "    f.write(onnx_model.SerializeToString())"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a6wfxCWAq48v"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1swt74XQUIFh"
      },
      "source": [
        "## **(5) Create your Model Playground**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y-YKEcvDNmD3"
      },
      "source": [
        "#Set up arguments for Model Playground deployment\n",
        "import pandas as pd \n",
        "\n",
        "model_filepath=\"model.onnx\"\n",
        "preprocessor_filepath=\"preprocessor.zip\"\n",
        "exampledata = example_data"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T8C6IlYTFN5t",
        "outputId": "68af9f0f-3047-4084-f5a1-b54d2374f9f3"
      },
      "source": [
        "from aimodelshare import ModelPlayground\n",
        "\n",
        "#Instantiate ModelPlayground() Class\n",
        "\n",
        "myplayground=ModelPlayground(model_type=\"tabular\", classification=\"TRUE\", private=\"FALSE\")\n",
        "\n",
        "# Create Model Playground (generates live rest api and web-app for your model/preprocessor)\n",
        "\n",
        "myplayground.deploy(model_filepath, preprocessor_filepath, y_train, exampledata) "
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "We need some information about your model before we can build your REST API and interactive Model Playground.\n",
            "   \n",
            "Model Name (for AI Model Share Website):Titanic survival classifier\n",
            "Model Description (Explain what your model does and \n",
            " why end-users would find your model useful):This model takes passenger attributes such as gender, ticket class, and age to predict titanic survival.\n",
            "Model Key Words (Search categories that describe your model, separated with commas):tabular, classification, titanic\n",
            "   \n",
            "Creating your prediction API. (This process may take several minutes.)\n",
            "\n",
            "[=====================================] Progress: 100% - Complete!                                            \n",
            "\n",
            "Success! Your Model Playground was created in 65 seconds. \n",
            " Playground Url: \"https://evxjcyzox2.execute-api.us-east-1.amazonaws.com/prod/m\"\n",
            "\n",
            "You can now use your Model Playground.\n",
            "\n",
            "Follow this link to explore your Model Playground's functionality\n",
            "You can make predictions with the Dashboard and access example code from the Programmatic tab.\n",
            "https://www.modelshare.org/detail/model:494\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eb9dfUFHhLr-"
      },
      "source": [
        "## **Use your new Model Playground!**\n",
        "\n",
        "Follow the link in the output above to:\n",
        "- Generate predictions with your interactive web dashboard\n",
        "- Access example code in Python, R, and Curl\n",
        "\n",
        "Or, follow the rest of the tutorial to create a competition for your Model Playground and: \n",
        "- Access verified model performance metrics \n",
        "- Upload multiple models to a leaderboard \n",
        "- Easily compare model performance & structure "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9YpyLkQNfqSI"
      },
      "source": [
        "## **Part 2: Create a Competition**\n",
        "\n",
        "-------\n",
        "\n",
        "After deploying your Model Playground, you can now create a competition. \n",
        "\n",
        "Creating a competition allows you to:\n",
        "1. Verify the model performance metrics on aimodelshare.org\n",
        "2. Submit models to a leaderboard\n",
        "3. Grant access to other users to submit models to the leaderboard\n",
        "4. Easily compare model performance and structure "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o2nKrLAMgc9o",
        "outputId": "8e56066c-cfd8-43fc-c63b-053def3fa175"
      },
      "source": [
        "# Create Competition\n",
        "myplayground.create_competition(data_directory='titanic_competition_data', \n",
        "                      e          y_test = y_test_labels, \n",
        "                                generate_credentials_file = True)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter competition name:Titanic Survival Competition\n",
            "Enter competition description:Submit models to predict titanic survival.\n",
            "Enter data description (i.e.- filenames denoting training and test data, file types, and any subfolders where files are stored):training data includes target variable.  Use test data to generate predictions of labels \"survived\" or \"died\" to make submissions to this competition. \n",
            "Uploading your data. Please wait for a confirmation message.\n",
            "\n",
            " Success! Model competition created. \n",
            "\n",
            "Your team members can now make use of the following functions: \n",
            "submit_model() to submit new models to the competition leaderboard. \n",
            "download_data('public.ecr.aws/y2e2a1d6/titanic_competition_data-repository:latest') to download your competition data.  \n",
            "\n",
            "You may update your prediction API runtime model with the update_runtime_model() function.\n",
            "\n",
            "To upload new models and/or preprocessors to this API, team members should use \n",
            "the following credentials:\n",
            "\n",
            "#Credentials for Competition: evxjcyzox2\n",
            "[submit_model:\"https://evxjcyzox2.execute-api.us-east-1.amazonaws.com/prod/m\"]\n",
            "AWS_ACCESS_KEY_ID = \"AKIAXQ2NM4KZG6TUYN6U\"\n",
            "AWS_SECRET_ACCESS_KEY = \"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\"\n",
            "AWS_REGION = \"us-east-1\"\n",
            "\n",
            "(This aws key/password combination limits team members to file upload access only.)\n",
            "\n",
            "These credentials have been saved as: evxjcyzox2_credentials.txt.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SAJJWhdAfyo5"
      },
      "source": [
        "#Instantiate Competition\n",
        "#--Note: If you start a new session, the first argument should be the Model Playground url in quotes. \n",
        "#--e.g.- mycompetition= ai.Competition(\"https://2121212.execute-api.us-east-1.amazonaws.com/prod/m)\n",
        "#See Model Playground \"Compete\" tab for example model submission code.\n",
        "\n",
        "mycompetition= ai.Competition(myplayground.playground_url)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mqyzWZPwgoEH"
      },
      "source": [
        "Submit Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pJC2jl2PgfTf",
        "outputId": "fad2f3b6-bb28-4b64-c348-f450cffbcdd2"
      },
      "source": [
        "#Submit Model 1: \n",
        "\n",
        "#-- Generate predicted values (a list of predicted labels \"survived\" or \"died\") (Model 1)\n",
        "prediction_labels = model.predict(preprocessor(X_test))\n",
        "\n",
        "# Submit Model 1 to Competition Leaderboard\n",
        "mycompetition.submit_model(model_filepath = \"model.onnx\",\n",
        "                                 preprocessor_filepath=\"preprocessor.zip\",\n",
        "                                 prediction_submission=prediction_labels)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Insert search tags to help users find your model (optional): penalized logistic regression\n",
            "Provide any useful notes about your model (optional): did not tune C\n",
            "\n",
            "Your model has been submitted as model version 1\n",
            "\n",
            "To submit code used to create this model or to view current leaderboard navigate to Model Playground: \n",
            "\n",
            " https://www.modelshare.org/detail/model:494\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hpzXNVPTop-O",
        "outputId": "df0ebe81-99d3-431f-bfd7-859ddd530613"
      },
      "source": [
        "# Create model 2 (Gradient Boosting Classifier)\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "\n",
        "model_2 = GradientBoostingClassifier()\n",
        "model_2.fit(preprocessor(X_train), y_train)\n",
        "model_2.score(preprocessor(X_train), y_train)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8701050620821394"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jraPDdsNX46e"
      },
      "source": [
        "# Save Model 2 to .onnx file\n",
        "\n",
        "# How many preprocessed input features are there?\n",
        "from skl2onnx.common.data_types import FloatTensorType\n",
        "initial_type = [('float_input', FloatTensorType([None, 10]))]  # need number of features in preprocesed data\n",
        "\n",
        "onnx_model = model_to_onnx(model_2, framework='sklearn',\n",
        "                          initial_types=initial_type,\n",
        "                          transfer_learning=False,\n",
        "                          deep_learning=False)\n",
        "\n",
        "# Save model to local .onnx file\n",
        "with open(\"model_2.onnx\", \"wb\") as f:\n",
        "    f.write(onnx_model.SerializeToString()) "
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cme7T_gaYWlD",
        "outputId": "a0caffa8-27e2-4a59-8e66-b01ed2d2ab8c"
      },
      "source": [
        "# Submit Model 2\n",
        "\n",
        "#-- Generate predicted y values (Model 2)\n",
        "prediction_labels = model_2.predict(preprocessor(X_test))\n",
        "\n",
        "# Submit Model 2 to Competition Leaderboard\n",
        "mycompetition.submit_model(model_filepath = \"model_2.onnx\",\n",
        "                                 prediction_submission=prediction_labels,\n",
        "                                 preprocessor_filepath=\"preprocessor.zip\")"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Insert search tags to help users find your model (optional): gb classifier, untuned\n",
            "Provide any useful notes about your model (optional): gb classifier set to default arguments\n",
            "\n",
            "Your model has been submitted as model version 2\n",
            "\n",
            "To submit code used to create this model or to view current leaderboard navigate to Model Playground: \n",
            "\n",
            " https://www.modelshare.org/detail/model:494\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iLYlCkWchWC_"
      },
      "source": [
        "Get Leaderboard"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "id": "J0-B1h0chYDL",
        "outputId": "ea0389b6-bc9e-432c-b918-7f7a26273c5f"
      },
      "source": [
        "data = mycompetition.get_leaderboard()\n",
        "mycompetition.stylize_leaderboard(data)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<style  type=\"text/css\" >\n",
              "#T_f3a677e8_1566_11ec_bcd1_0242ac1c0002row0_col0{\n",
              "            text-align:  center;\n",
              "            width:  10em;\n",
              "             height:  80%;\n",
              "            background:  linear-gradient(90deg,#f5f8d6 81.7%, transparent 81.7%);\n",
              "            color:  #251e1b;\n",
              "            font-size:  12px;\n",
              "        }#T_f3a677e8_1566_11ec_bcd1_0242ac1c0002row0_col1,#T_f3a677e8_1566_11ec_bcd1_0242ac1c0002row1_col1{\n",
              "            text-align:  center;\n",
              "            width:  10em;\n",
              "             height:  80%;\n",
              "            background:  linear-gradient(90deg,#c778c8 80.1%, transparent 80.1%);\n",
              "            color:  #251e1b;\n",
              "            font-size:  12px;\n",
              "        }#T_f3a677e8_1566_11ec_bcd1_0242ac1c0002row0_col2{\n",
              "            text-align:  center;\n",
              "            width:  10em;\n",
              "             height:  80%;\n",
              "            background:  linear-gradient(90deg,#ff4971 81.2%, transparent 81.2%);\n",
              "            color:  #251e1b;\n",
              "            font-size:  12px;\n",
              "        }#T_f3a677e8_1566_11ec_bcd1_0242ac1c0002row0_col3{\n",
              "            text-align:  center;\n",
              "            width:  10em;\n",
              "             height:  80%;\n",
              "            background:  linear-gradient(90deg,#aadbaa 79.4%, transparent 79.4%);\n",
              "            color:  #251e1b;\n",
              "            font-size:  12px;\n",
              "        }#T_f3a677e8_1566_11ec_bcd1_0242ac1c0002row0_col4,#T_f3a677e8_1566_11ec_bcd1_0242ac1c0002row0_col5,#T_f3a677e8_1566_11ec_bcd1_0242ac1c0002row0_col6,#T_f3a677e8_1566_11ec_bcd1_0242ac1c0002row0_col7,#T_f3a677e8_1566_11ec_bcd1_0242ac1c0002row0_col8,#T_f3a677e8_1566_11ec_bcd1_0242ac1c0002row0_col9,#T_f3a677e8_1566_11ec_bcd1_0242ac1c0002row0_col10,#T_f3a677e8_1566_11ec_bcd1_0242ac1c0002row0_col11,#T_f3a677e8_1566_11ec_bcd1_0242ac1c0002row0_col12,#T_f3a677e8_1566_11ec_bcd1_0242ac1c0002row1_col4,#T_f3a677e8_1566_11ec_bcd1_0242ac1c0002row1_col5,#T_f3a677e8_1566_11ec_bcd1_0242ac1c0002row1_col6,#T_f3a677e8_1566_11ec_bcd1_0242ac1c0002row1_col7,#T_f3a677e8_1566_11ec_bcd1_0242ac1c0002row1_col8,#T_f3a677e8_1566_11ec_bcd1_0242ac1c0002row1_col9,#T_f3a677e8_1566_11ec_bcd1_0242ac1c0002row1_col10,#T_f3a677e8_1566_11ec_bcd1_0242ac1c0002row1_col11,#T_f3a677e8_1566_11ec_bcd1_0242ac1c0002row1_col12{\n",
              "            text-align:  center;\n",
              "        }#T_f3a677e8_1566_11ec_bcd1_0242ac1c0002row1_col0{\n",
              "            text-align:  center;\n",
              "            width:  10em;\n",
              "             height:  80%;\n",
              "            background:  linear-gradient(90deg,#f5f8d6 82.1%, transparent 82.1%);\n",
              "            color:  #251e1b;\n",
              "            font-size:  12px;\n",
              "        }#T_f3a677e8_1566_11ec_bcd1_0242ac1c0002row1_col2{\n",
              "            text-align:  center;\n",
              "            width:  10em;\n",
              "             height:  80%;\n",
              "            background:  linear-gradient(90deg,#ff4971 82.5%, transparent 82.5%);\n",
              "            color:  #251e1b;\n",
              "            font-size:  12px;\n",
              "        }#T_f3a677e8_1566_11ec_bcd1_0242ac1c0002row1_col3{\n",
              "            text-align:  center;\n",
              "            width:  10em;\n",
              "             height:  80%;\n",
              "            background:  linear-gradient(90deg,#aadbaa 79.0%, transparent 79.0%);\n",
              "            color:  #251e1b;\n",
              "            font-size:  12px;\n",
              "        }</style><table id=\"T_f3a677e8_1566_11ec_bcd1_0242ac1c0002\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >accuracy</th>        <th class=\"col_heading level0 col1\" >f1_score</th>        <th class=\"col_heading level0 col2\" >precision</th>        <th class=\"col_heading level0 col3\" >recall</th>        <th class=\"col_heading level0 col4\" >ml_framework</th>        <th class=\"col_heading level0 col5\" >transfer_learning</th>        <th class=\"col_heading level0 col6\" >deep_learning</th>        <th class=\"col_heading level0 col7\" >model_type</th>        <th class=\"col_heading level0 col8\" >num_params</th>        <th class=\"col_heading level0 col9\" >optimizer</th>        <th class=\"col_heading level0 col10\" >model_config</th>        <th class=\"col_heading level0 col11\" >username</th>        <th class=\"col_heading level0 col12\" >version</th>    </tr></thead><tbody>\n",
              "                <tr>\n",
              "                        <th id=\"T_f3a677e8_1566_11ec_bcd1_0242ac1c0002level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
              "                        <td id=\"T_f3a677e8_1566_11ec_bcd1_0242ac1c0002row0_col0\" class=\"data row0 col0\" >81.68%</td>\n",
              "                        <td id=\"T_f3a677e8_1566_11ec_bcd1_0242ac1c0002row0_col1\" class=\"data row0 col1\" >80.09%</td>\n",
              "                        <td id=\"T_f3a677e8_1566_11ec_bcd1_0242ac1c0002row0_col2\" class=\"data row0 col2\" >81.15%</td>\n",
              "                        <td id=\"T_f3a677e8_1566_11ec_bcd1_0242ac1c0002row0_col3\" class=\"data row0 col3\" >79.44%</td>\n",
              "                        <td id=\"T_f3a677e8_1566_11ec_bcd1_0242ac1c0002row0_col4\" class=\"data row0 col4\" >sklearn</td>\n",
              "                        <td id=\"T_f3a677e8_1566_11ec_bcd1_0242ac1c0002row0_col5\" class=\"data row0 col5\" >False</td>\n",
              "                        <td id=\"T_f3a677e8_1566_11ec_bcd1_0242ac1c0002row0_col6\" class=\"data row0 col6\" >False</td>\n",
              "                        <td id=\"T_f3a677e8_1566_11ec_bcd1_0242ac1c0002row0_col7\" class=\"data row0 col7\" >LogisticRegression</td>\n",
              "                        <td id=\"T_f3a677e8_1566_11ec_bcd1_0242ac1c0002row0_col8\" class=\"data row0 col8\" >10.000000</td>\n",
              "                        <td id=\"T_f3a677e8_1566_11ec_bcd1_0242ac1c0002row0_col9\" class=\"data row0 col9\" >lbfgs</td>\n",
              "                        <td id=\"T_f3a677e8_1566_11ec_bcd1_0242ac1c0002row0_col10\" class=\"data row0 col10\" >{'C': 10, 'class_weight': None...</td>\n",
              "                        <td id=\"T_f3a677e8_1566_11ec_bcd1_0242ac1c0002row0_col11\" class=\"data row0 col11\" >mikedparrott</td>\n",
              "                        <td id=\"T_f3a677e8_1566_11ec_bcd1_0242ac1c0002row0_col12\" class=\"data row0 col12\" >1</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_f3a677e8_1566_11ec_bcd1_0242ac1c0002level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
              "                        <td id=\"T_f3a677e8_1566_11ec_bcd1_0242ac1c0002row1_col0\" class=\"data row1 col0\" >82.06%</td>\n",
              "                        <td id=\"T_f3a677e8_1566_11ec_bcd1_0242ac1c0002row1_col1\" class=\"data row1 col1\" >80.06%</td>\n",
              "                        <td id=\"T_f3a677e8_1566_11ec_bcd1_0242ac1c0002row1_col2\" class=\"data row1 col2\" >82.48%</td>\n",
              "                        <td id=\"T_f3a677e8_1566_11ec_bcd1_0242ac1c0002row1_col3\" class=\"data row1 col3\" >78.99%</td>\n",
              "                        <td id=\"T_f3a677e8_1566_11ec_bcd1_0242ac1c0002row1_col4\" class=\"data row1 col4\" >sklearn</td>\n",
              "                        <td id=\"T_f3a677e8_1566_11ec_bcd1_0242ac1c0002row1_col5\" class=\"data row1 col5\" >False</td>\n",
              "                        <td id=\"T_f3a677e8_1566_11ec_bcd1_0242ac1c0002row1_col6\" class=\"data row1 col6\" >False</td>\n",
              "                        <td id=\"T_f3a677e8_1566_11ec_bcd1_0242ac1c0002row1_col7\" class=\"data row1 col7\" >GradientBoostingClassifier</td>\n",
              "                        <td id=\"T_f3a677e8_1566_11ec_bcd1_0242ac1c0002row1_col8\" class=\"data row1 col8\" >nan</td>\n",
              "                        <td id=\"T_f3a677e8_1566_11ec_bcd1_0242ac1c0002row1_col9\" class=\"data row1 col9\" >nan</td>\n",
              "                        <td id=\"T_f3a677e8_1566_11ec_bcd1_0242ac1c0002row1_col10\" class=\"data row1 col10\" >{'ccp_alpha': 0.0, 'criterion'...</td>\n",
              "                        <td id=\"T_f3a677e8_1566_11ec_bcd1_0242ac1c0002row1_col11\" class=\"data row1 col11\" >mikedparrott</td>\n",
              "                        <td id=\"T_f3a677e8_1566_11ec_bcd1_0242ac1c0002row1_col12\" class=\"data row1 col12\" >2</td>\n",
              "            </tr>\n",
              "    </tbody></table>"
            ],
            "text/plain": [
              "<pandas.io.formats.style.Styler at 0x7f67989b1110>"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g_bklL3shOER"
      },
      "source": [
        "Compare Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "quo_V3A3hNS3"
      },
      "source": [
        "# Compare two or more models (Experimental, Git-like Diffs for Model Architectures)\n",
        "mycompetition.compare_models([1,2])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e3zMPbbrhHRq"
      },
      "source": [
        "Import a model from the leaderboard"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LK9_k9w-hInl",
        "outputId": "9c2b080a-a47c-4456-b31c-0624c1539961"
      },
      "source": [
        "mymodel = mycompetition.instantiate_model(2, trained=True)\n",
        "\n",
        "#Generate new predictions to test model\n",
        "mymodel.predict(preprocessor(X_test))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['died', 'survived', 'died', 'died', 'died', 'died', 'survived',\n",
              "       'died', 'died', 'died', 'died', 'survived', 'died', 'survived',\n",
              "       'died', 'died', 'died', 'died', 'died', 'died', 'died', 'died',\n",
              "       'died', 'died', 'died', 'died', 'survived', 'died', 'survived',\n",
              "       'survived', 'died', 'died', 'died', 'died', 'died', 'survived',\n",
              "       'survived', 'died', 'died', 'survived', 'died', 'died', 'died',\n",
              "       'died', 'died', 'survived', 'died', 'died', 'survived', 'survived',\n",
              "       'died', 'died', 'survived', 'survived', 'survived', 'died', 'died',\n",
              "       'survived', 'survived', 'died', 'died', 'died', 'died', 'died',\n",
              "       'survived', 'died', 'died', 'died', 'died', 'died', 'died', 'died',\n",
              "       'survived', 'survived', 'survived', 'survived', 'survived',\n",
              "       'survived', 'died', 'died', 'died', 'died', 'survived', 'survived',\n",
              "       'died', 'died', 'survived', 'survived', 'survived', 'survived',\n",
              "       'died', 'died', 'survived', 'died', 'survived', 'died', 'died',\n",
              "       'died', 'survived', 'died', 'died', 'died', 'survived', 'died',\n",
              "       'died', 'died', 'died', 'died', 'died', 'died', 'died', 'died',\n",
              "       'died', 'survived', 'died', 'died', 'died', 'died', 'died',\n",
              "       'survived', 'survived', 'died', 'survived', 'died', 'died', 'died',\n",
              "       'survived', 'died', 'survived', 'died', 'died', 'died', 'survived',\n",
              "       'survived', 'died', 'died', 'died', 'died', 'survived', 'died',\n",
              "       'survived', 'died', 'died', 'survived', 'died', 'survived', 'died',\n",
              "       'died', 'died', 'survived', 'survived', 'died', 'died', 'died',\n",
              "       'died', 'died', 'died', 'died', 'died', 'survived', 'died', 'died',\n",
              "       'survived', 'died', 'died', 'died', 'died', 'died', 'survived',\n",
              "       'survived', 'died', 'died', 'died', 'survived', 'died', 'died',\n",
              "       'survived', 'died', 'survived', 'died', 'survived', 'died',\n",
              "       'survived', 'died', 'died', 'survived', 'died', 'died', 'survived',\n",
              "       'died', 'died', 'died', 'died', 'died', 'died', 'died', 'died',\n",
              "       'died', 'died', 'survived', 'died', 'died', 'survived', 'survived',\n",
              "       'died', 'survived', 'survived', 'died', 'died', 'died', 'survived',\n",
              "       'died', 'survived', 'survived', 'died', 'died', 'died', 'died',\n",
              "       'died', 'died', 'survived', 'died', 'died', 'survived', 'survived',\n",
              "       'died', 'survived', 'died', 'died', 'died', 'died', 'survived',\n",
              "       'died', 'died', 'died', 'died', 'died', 'died', 'survived', 'died',\n",
              "       'died', 'survived', 'survived', 'died', 'survived', 'died', 'died',\n",
              "       'died', 'died', 'died', 'died', 'died', 'died', 'died', 'died',\n",
              "       'survived', 'died', 'died', 'survived', 'died', 'died', 'died'],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FKm9ugiBhQFn"
      },
      "source": [
        "#### Check structure of y test data \n",
        "(This helps users understand how to submit predicted values to leaderboard)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dqY82D22hPZx",
        "outputId": "f3a87586-bda6-4c67-94ea-801f8690e8a9"
      },
      "source": [
        "mycompetition.inspect_y_test()"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'class_balance': {'died': 162, 'survived': 100},\n",
              " 'class_labels': ['died', 'survived'],\n",
              " 'label_dtypes': {\"<class 'str'>\": 262},\n",
              " 'y_length': 262,\n",
              " 'ytest_example': ['survived', 'survived', 'survived', 'died', 'died']}"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iA-nYjr7WCIp"
      },
      "source": [
        "## **Part 3: Maintaining your Model Playground**\n",
        "\n",
        "-------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0UIWnHIXWM0F"
      },
      "source": [
        "Update Runtime model\n",
        "\n",
        "*Use this function to 1) update the prediction API behind your Model Playground with a new model, chosen from the leaderboard and 2) verify the modelperformance metrics in your Model Playground*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wAchpcGLWLxE",
        "outputId": "2dcce65c-74ac-4277-b8e1-3006be359f70"
      },
      "source": [
        "myplayground.update_runtime_model(model_version=2)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Runtime model & preprocessor for api: https://evxjcyzox2.execute-api.us-east-1.amazonaws.com/prod/m updated to model version 2.\n",
            "\n",
            "Model metrics are now updated and verified for this model playground.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xhJRaiN-WaO1"
      },
      "source": [
        "Delete Deployment \n",
        "\n",
        "*Use this function to delete the entire Model Playground, including the REST API, web dashboard, competition, and all submitted models*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        },
        "id": "mCkf-exLWyDK",
        "outputId": "f3b7bf57-c879-462e-f68d-0d296d993182"
      },
      "source": [
        "myplayground.delete_deployment()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running this function will permanently delete all resources tied to this deployment, \n",
            " including the eval lambda and all models submitted to the model competition.\n",
            "\n",
            "To confirm, type 'permanently delete':permanently delete\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'API deleted successfully.'"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    }
  ]
}