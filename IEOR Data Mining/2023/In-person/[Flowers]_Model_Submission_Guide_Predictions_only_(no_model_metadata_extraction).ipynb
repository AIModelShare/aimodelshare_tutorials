{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m_DMeZsXxpEZ"
   },
   "source": [
    "<p align=\"center\"><img width=\"50%\" src=\"https://aimodelsharecontent.s3.amazonaws.com/aimodshare_banner.jpg\" /></p>\n",
    "\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JXxGTgJz152A"
   },
   "source": [
    "<p align=\"center\"><h1 align=\"center\">Flower Image Classification Model Submission Guide - Predictions Only (No Model Metadata Extraction)\n",
    "\n",
    "---\n",
    "Let's share our models to a centralized leaderboard, so that we can collaborate and learn from the model experimentation process...\n",
    "\n",
    "**Instructions:**\n",
    "1.   Get data in and set up X_train / X_test / y_train\n",
    "2.   Preprocess data\n",
    "3. Fit model on preprocessed data\n",
    "4. Generate predictions from X_test data and submit to competition\n",
    "5. Repeat submission process to improve place on leaderboard\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5gSrVJwp3E9H"
   },
   "source": [
    "## 1. Get data in and set up X_train, X_test, y_train objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PLTIaMB3ChSW"
   },
   "outputs": [],
   "source": [
    "#install aimodelshare library\n",
    "! pip install aimodelshare==0.0.189"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d3PiJXBhC5y-",
    "outputId": "506af2b6-21f5-4b6e-98e4-bfbc68790603"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading [================================================>]\n",
      "\n",
      "Data downloaded successfully.\n"
     ]
    }
   ],
   "source": [
    "# Get competition data\n",
    "from aimodelshare import download_data\n",
    "download_data('public.ecr.aws/y2e2a1d6/flower_competition_data-repository:latest') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KujkkcWsiGFO",
    "outputId": "2f8df4d2-d6f4-4aac-8c55-031790744820"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of images for each category: [507, 718, 513, 559, 639]\n",
      "flower_competition_data/train_images/daisy/9515186037_3be48fe68f.jpg\n"
     ]
    }
   ],
   "source": [
    "# Create training data objects \n",
    "\n",
    "# Extracting all filepaths iteratively...\n",
    "import os \n",
    "\n",
    "base_path = 'flower_competition_data/train_images'\n",
    "categories = ['daisy', 'dandelion', 'roses', 'sunflowers', 'tulips']\n",
    "\n",
    "# Load file paths to fnames list object...\n",
    "fnames = []\n",
    "for category in categories:\n",
    "    flower_folder = os.path.join(base_path, category)\n",
    "    file_names = os.listdir(flower_folder)\n",
    "    full_path = [os.path.join(flower_folder, file_name) for file_name in file_names]\n",
    "    fnames.append(full_path)\n",
    "\n",
    "print('number of images for each category:', [len(f) for f in fnames])\n",
    "print(fnames[0][1]) # Examples of file names...\n",
    "\n",
    "# Create y data made up of correctly ordered labels from file folders...\n",
    "from itertools import repeat\n",
    "\n",
    "daisy = list(repeat(\"daisy\", 507)) #i.e.: 507 filenames in daisy folder\n",
    "dandelion = list(repeat(\"dandelion\", 718))\n",
    "roses = list(repeat(\"roses\", 513))\n",
    "sunflowers = list(repeat(\"sunflowers\", 559))\n",
    "tulips = list(repeat(\"tulips\", 639))\n",
    "\n",
    "# Combine into single list of y labels...\n",
    "y_labels = daisy + dandelion + roses + sunflowers + tulips \n",
    "\n",
    "# Need to one-hot encode for Keras. Let's use Pandas...\n",
    "import pandas as pd\n",
    "y_train = pd.get_dummies(y_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gEzPoXPj3V7u"
   },
   "source": [
    "##2.   Preprocess data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6IKOmKsXiZjh"
   },
   "outputs": [],
   "source": [
    "# Write and execute code to preprocess data here - an example is provided below "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "wgZFbZjKjzoH"
   },
   "outputs": [],
   "source": [
    "# Here is a pre-designed preprocessor, but you could also build your own to prepare the data differently\n",
    "\n",
    "def preprocessor(image_filepath, shape=(192, 192)):\n",
    "        \"\"\"\n",
    "        This function preprocesses reads in images, resizes them to a fixed shape and\n",
    "        min/max transforms them before converting feature values to float32 numeric values\n",
    "        required by onnx files.\n",
    "        \n",
    "        params:\n",
    "            image_filepath\n",
    "                full filepath of a particular image\n",
    "                      \n",
    "        returns:\n",
    "            X\n",
    "                numpy array of preprocessed image data\n",
    "                  \n",
    "        \"\"\"\n",
    "           \n",
    "        import cv2\n",
    "        import numpy as np\n",
    "\n",
    "        \"Resize a color image and min/max transform the image\"\n",
    "        img = cv2.imread(image_filepath) # Read in image from filepath.\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB) # cv2 reads in images in order of blue green and red, we reverse the order for ML.\n",
    "        img = cv2.resize(img, shape) # Change height and width of image.\n",
    "        img = img / 255.0 # Min-max transform.\n",
    "\n",
    "\n",
    "        # Resize all the images...\n",
    "        X = np.array(img)\n",
    "        X = np.expand_dims(X, axis=0) # Expand dims to add \"1\" to object shape [1, h, w, channels] for keras model.\n",
    "        X = np.array(X, dtype=np.float32) # Final shape for onnx runtime.\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "Rmk3I_ysj0UE"
   },
   "outputs": [],
   "source": [
    "# Use preprocessor to create X_train object \n",
    "\n",
    "# Import image, load to array of shape height, width, channels, then min/max transform...\n",
    "# Read in all images from filenames...\n",
    "import numpy as np \n",
    "\n",
    "preprocessed_image_data = [preprocessor(x) for x in fnames[0] + fnames[1] + fnames[2] + \n",
    "                           fnames[3] + fnames[4]]\n",
    "\n",
    "# Object needs to be an array rather than a list for Keras. (vstack converts above list to array object.)\n",
    "X_train = np.vstack(preprocessed_image_data)\n",
    "# Assigning to X_train to highlight that this represents feature input data for our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "G_sdpBG9j3YS"
   },
   "outputs": [],
   "source": [
    "# Preprocess X_test image data to generate predictions from models \n",
    "import numpy as np\n",
    "\n",
    "file_names = [('flower_competition_data/test_images/' + str(i) + '.jpg') for i in range(1, 735)]\n",
    "\n",
    "preprocessed_image_data = [preprocessor(x) for x in file_names]\n",
    "\n",
    "#Create single X_test array from preprocessed images\n",
    "X_test = np.vstack(preprocessed_image_data) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X52kECL43b-O"
   },
   "source": [
    "##3. Fit model on preprocessed data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NCbBf8j9ClYl"
   },
   "outputs": [],
   "source": [
    "# Write and execute code to fit model on preprocessed data here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RtgkM02MDpkO",
    "outputId": "1d470f4a-335f-4e2b-a49f-1a1276259c27"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI Modelshare Username:··········\n",
      "AI Modelshare Password:··········\n",
      "AI Model Share login credentials set successfully.\n"
     ]
    }
   ],
   "source": [
    "#Set credentials using modelshare.org username/password\n",
    "\n",
    "from aimodelshare.aws import set_credentials\n",
    "    \n",
    "apiurl=\"https://baow3dbru5.execute-api.us-east-1.amazonaws.com/prod/m\"\n",
    "#This is the unique rest api that powers this Fashhion-MNIST Image Classification Playground\n",
    "\n",
    "set_credentials(apiurl=apiurl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "fKNGSww8EGgi"
   },
   "outputs": [],
   "source": [
    "#Instantiate Competition\n",
    "import aimodelshare as ai\n",
    "mycompetition= ai.Competition(apiurl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W66Pr1_K2sQV"
   },
   "source": [
    "## **4. Submit Model predictions to leaderboard (without extracting model architecture information):**\n",
    "- model metadata extraction allows you use compare_models() and instantiate_model() functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "IS09g9DF0HGP"
   },
   "outputs": [],
   "source": [
    "#Generate a list of predictions using X_test data\n",
    "\n",
    "# This example uses randomly chosen values from y_labels to generate a list of predictions\n",
    "import random \n",
    "predicted_values = random.sample(y_labels, len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_Ql4wksyEUnP"
   },
   "outputs": [],
   "source": [
    "#Submit Model predictions to leaderboard (without extracting model architecture information): \n",
    "\n",
    "# Submit to Competition Leaderboard\n",
    "mycompetition.submit_model(model_filepath = None,\n",
    "                                 preprocessor_filepath=None,\n",
    "                                 prediction_submission=predicted_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 226
    },
    "id": "GN1zvAmNEq17",
    "outputId": "2c8534dd-ee70-43ba-8ff2-aa608f1a3993"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_ec206_row0_col0, #T_ec206_row1_col0 {\n",
       "  text-align: center;\n",
       "  width: 10em;\n",
       "  background: linear-gradient(90deg, #f5f8d6 48.5%, transparent 48.5%);\n",
       "  color: #251e1b;\n",
       "  font-size: 12px;\n",
       "}\n",
       "#T_ec206_row0_col1, #T_ec206_row1_col1 {\n",
       "  text-align: center;\n",
       "  width: 10em;\n",
       "  background: linear-gradient(90deg, #c778c8 47.4%, transparent 47.4%);\n",
       "  color: #251e1b;\n",
       "  font-size: 12px;\n",
       "}\n",
       "#T_ec206_row0_col2, #T_ec206_row1_col2 {\n",
       "  text-align: center;\n",
       "  width: 10em;\n",
       "  background: linear-gradient(90deg, #ff4971 54.8%, transparent 54.8%);\n",
       "  color: #251e1b;\n",
       "  font-size: 12px;\n",
       "}\n",
       "#T_ec206_row0_col3, #T_ec206_row1_col3 {\n",
       "  text-align: center;\n",
       "  width: 10em;\n",
       "  background: linear-gradient(90deg, #aadbaa 49.2%, transparent 49.2%);\n",
       "  color: #251e1b;\n",
       "  font-size: 12px;\n",
       "}\n",
       "#T_ec206_row0_col4, #T_ec206_row0_col5, #T_ec206_row0_col6, #T_ec206_row0_col7, #T_ec206_row0_col8, #T_ec206_row0_col9, #T_ec206_row0_col10, #T_ec206_row0_col11, #T_ec206_row0_col12, #T_ec206_row0_col13, #T_ec206_row0_col14, #T_ec206_row0_col15, #T_ec206_row0_col16, #T_ec206_row0_col17, #T_ec206_row0_col18, #T_ec206_row0_col19, #T_ec206_row0_col20, #T_ec206_row1_col4, #T_ec206_row1_col5, #T_ec206_row1_col6, #T_ec206_row1_col7, #T_ec206_row1_col8, #T_ec206_row1_col9, #T_ec206_row1_col10, #T_ec206_row1_col11, #T_ec206_row1_col12, #T_ec206_row1_col13, #T_ec206_row1_col14, #T_ec206_row1_col15, #T_ec206_row1_col16, #T_ec206_row1_col17, #T_ec206_row1_col18, #T_ec206_row1_col19, #T_ec206_row1_col20, #T_ec206_row2_col4, #T_ec206_row2_col5, #T_ec206_row2_col6, #T_ec206_row2_col7, #T_ec206_row2_col8, #T_ec206_row2_col9, #T_ec206_row2_col10, #T_ec206_row2_col11, #T_ec206_row2_col12, #T_ec206_row2_col13, #T_ec206_row2_col14, #T_ec206_row2_col15, #T_ec206_row2_col16, #T_ec206_row2_col17, #T_ec206_row2_col18, #T_ec206_row2_col19, #T_ec206_row2_col20, #T_ec206_row3_col4, #T_ec206_row3_col5, #T_ec206_row3_col6, #T_ec206_row3_col7, #T_ec206_row3_col8, #T_ec206_row3_col9, #T_ec206_row3_col10, #T_ec206_row3_col11, #T_ec206_row3_col12, #T_ec206_row3_col13, #T_ec206_row3_col14, #T_ec206_row3_col15, #T_ec206_row3_col16, #T_ec206_row3_col17, #T_ec206_row3_col18, #T_ec206_row3_col19, #T_ec206_row3_col20, #T_ec206_row4_col4, #T_ec206_row4_col5, #T_ec206_row4_col6, #T_ec206_row4_col7, #T_ec206_row4_col8, #T_ec206_row4_col9, #T_ec206_row4_col10, #T_ec206_row4_col11, #T_ec206_row4_col12, #T_ec206_row4_col13, #T_ec206_row4_col14, #T_ec206_row4_col15, #T_ec206_row4_col16, #T_ec206_row4_col17, #T_ec206_row4_col18, #T_ec206_row4_col19, #T_ec206_row4_col20 {\n",
       "  text-align: center;\n",
       "}\n",
       "#T_ec206_row2_col0 {\n",
       "  text-align: center;\n",
       "  width: 10em;\n",
       "  background: linear-gradient(90deg, #f5f8d6 42.8%, transparent 42.8%);\n",
       "  color: #251e1b;\n",
       "  font-size: 12px;\n",
       "}\n",
       "#T_ec206_row2_col1 {\n",
       "  text-align: center;\n",
       "  width: 10em;\n",
       "  background: linear-gradient(90deg, #c778c8 39.0%, transparent 39.0%);\n",
       "  color: #251e1b;\n",
       "  font-size: 12px;\n",
       "}\n",
       "#T_ec206_row2_col2 {\n",
       "  text-align: center;\n",
       "  width: 10em;\n",
       "  background: linear-gradient(90deg, #ff4971 37.3%, transparent 37.3%);\n",
       "  color: #251e1b;\n",
       "  font-size: 12px;\n",
       "}\n",
       "#T_ec206_row2_col3 {\n",
       "  text-align: center;\n",
       "  width: 10em;\n",
       "  background: linear-gradient(90deg, #aadbaa 45.0%, transparent 45.0%);\n",
       "  color: #251e1b;\n",
       "  font-size: 12px;\n",
       "}\n",
       "#T_ec206_row3_col0 {\n",
       "  text-align: center;\n",
       "  width: 10em;\n",
       "  background: linear-gradient(90deg, #f5f8d6 34.1%, transparent 34.1%);\n",
       "  color: #251e1b;\n",
       "  font-size: 12px;\n",
       "}\n",
       "#T_ec206_row3_col1 {\n",
       "  text-align: center;\n",
       "  width: 10em;\n",
       "  background: linear-gradient(90deg, #c778c8 26.5%, transparent 26.5%);\n",
       "  color: #251e1b;\n",
       "  font-size: 12px;\n",
       "}\n",
       "#T_ec206_row3_col2 {\n",
       "  text-align: center;\n",
       "  width: 10em;\n",
       "  background: linear-gradient(90deg, #ff4971 32.0%, transparent 32.0%);\n",
       "  color: #251e1b;\n",
       "  font-size: 12px;\n",
       "}\n",
       "#T_ec206_row3_col3 {\n",
       "  text-align: center;\n",
       "  width: 10em;\n",
       "  background: linear-gradient(90deg, #aadbaa 34.4%, transparent 34.4%);\n",
       "  color: #251e1b;\n",
       "  font-size: 12px;\n",
       "}\n",
       "#T_ec206_row4_col0 {\n",
       "  text-align: center;\n",
       "  width: 10em;\n",
       "  background: linear-gradient(90deg, #f5f8d6 21.3%, transparent 21.3%);\n",
       "  color: #251e1b;\n",
       "  font-size: 12px;\n",
       "}\n",
       "#T_ec206_row4_col1 {\n",
       "  text-align: center;\n",
       "  width: 10em;\n",
       "  background: linear-gradient(90deg, #c778c8 21.2%, transparent 21.2%);\n",
       "  color: #251e1b;\n",
       "  font-size: 12px;\n",
       "}\n",
       "#T_ec206_row4_col2 {\n",
       "  text-align: center;\n",
       "  width: 10em;\n",
       "  background: linear-gradient(90deg, #ff4971 21.3%, transparent 21.3%);\n",
       "  color: #251e1b;\n",
       "  font-size: 12px;\n",
       "}\n",
       "#T_ec206_row4_col3 {\n",
       "  text-align: center;\n",
       "  width: 10em;\n",
       "  background: linear-gradient(90deg, #aadbaa 21.1%, transparent 21.1%);\n",
       "  color: #251e1b;\n",
       "  font-size: 12px;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_ec206\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_ec206_level0_col0\" class=\"col_heading level0 col0\" >accuracy</th>\n",
       "      <th id=\"T_ec206_level0_col1\" class=\"col_heading level0 col1\" >f1_score</th>\n",
       "      <th id=\"T_ec206_level0_col2\" class=\"col_heading level0 col2\" >precision</th>\n",
       "      <th id=\"T_ec206_level0_col3\" class=\"col_heading level0 col3\" >recall</th>\n",
       "      <th id=\"T_ec206_level0_col4\" class=\"col_heading level0 col4\" >ml_framework</th>\n",
       "      <th id=\"T_ec206_level0_col5\" class=\"col_heading level0 col5\" >deep_learning</th>\n",
       "      <th id=\"T_ec206_level0_col6\" class=\"col_heading level0 col6\" >model_type</th>\n",
       "      <th id=\"T_ec206_level0_col7\" class=\"col_heading level0 col7\" >depth</th>\n",
       "      <th id=\"T_ec206_level0_col8\" class=\"col_heading level0 col8\" >num_params</th>\n",
       "      <th id=\"T_ec206_level0_col9\" class=\"col_heading level0 col9\" >dense_layers</th>\n",
       "      <th id=\"T_ec206_level0_col10\" class=\"col_heading level0 col10\" >conv2d_layers</th>\n",
       "      <th id=\"T_ec206_level0_col11\" class=\"col_heading level0 col11\" >flatten_layers</th>\n",
       "      <th id=\"T_ec206_level0_col12\" class=\"col_heading level0 col12\" >maxpooling2d_layers</th>\n",
       "      <th id=\"T_ec206_level0_col13\" class=\"col_heading level0 col13\" >dropout_layers</th>\n",
       "      <th id=\"T_ec206_level0_col14\" class=\"col_heading level0 col14\" >relu_act</th>\n",
       "      <th id=\"T_ec206_level0_col15\" class=\"col_heading level0 col15\" >softmax_act</th>\n",
       "      <th id=\"T_ec206_level0_col16\" class=\"col_heading level0 col16\" >loss</th>\n",
       "      <th id=\"T_ec206_level0_col17\" class=\"col_heading level0 col17\" >optimizer</th>\n",
       "      <th id=\"T_ec206_level0_col18\" class=\"col_heading level0 col18\" >memory_size</th>\n",
       "      <th id=\"T_ec206_level0_col19\" class=\"col_heading level0 col19\" >username</th>\n",
       "      <th id=\"T_ec206_level0_col20\" class=\"col_heading level0 col20\" >version</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_ec206_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_ec206_row0_col0\" class=\"data row0 col0\" >48.50%</td>\n",
       "      <td id=\"T_ec206_row0_col1\" class=\"data row0 col1\" >47.45%</td>\n",
       "      <td id=\"T_ec206_row0_col2\" class=\"data row0 col2\" >54.79%</td>\n",
       "      <td id=\"T_ec206_row0_col3\" class=\"data row0 col3\" >49.19%</td>\n",
       "      <td id=\"T_ec206_row0_col4\" class=\"data row0 col4\" >keras</td>\n",
       "      <td id=\"T_ec206_row0_col5\" class=\"data row0 col5\" >True</td>\n",
       "      <td id=\"T_ec206_row0_col6\" class=\"data row0 col6\" >Sequential</td>\n",
       "      <td id=\"T_ec206_row0_col7\" class=\"data row0 col7\" >11.000000</td>\n",
       "      <td id=\"T_ec206_row0_col8\" class=\"data row0 col8\" >2773673.000000</td>\n",
       "      <td id=\"T_ec206_row0_col9\" class=\"data row0 col9\" >2.000000</td>\n",
       "      <td id=\"T_ec206_row0_col10\" class=\"data row0 col10\" >4.000000</td>\n",
       "      <td id=\"T_ec206_row0_col11\" class=\"data row0 col11\" >1.000000</td>\n",
       "      <td id=\"T_ec206_row0_col12\" class=\"data row0 col12\" >2.000000</td>\n",
       "      <td id=\"T_ec206_row0_col13\" class=\"data row0 col13\" >2.000000</td>\n",
       "      <td id=\"T_ec206_row0_col14\" class=\"data row0 col14\" >5.000000</td>\n",
       "      <td id=\"T_ec206_row0_col15\" class=\"data row0 col15\" >1.000000</td>\n",
       "      <td id=\"T_ec206_row0_col16\" class=\"data row0 col16\" >str</td>\n",
       "      <td id=\"T_ec206_row0_col17\" class=\"data row0 col17\" >RMSprop</td>\n",
       "      <td id=\"T_ec206_row0_col18\" class=\"data row0 col18\" >11096464.000000</td>\n",
       "      <td id=\"T_ec206_row0_col19\" class=\"data row0 col19\" >IEOR_Data_Mining</td>\n",
       "      <td id=\"T_ec206_row0_col20\" class=\"data row0 col20\" >3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ec206_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_ec206_row1_col0\" class=\"data row1 col0\" >48.50%</td>\n",
       "      <td id=\"T_ec206_row1_col1\" class=\"data row1 col1\" >47.45%</td>\n",
       "      <td id=\"T_ec206_row1_col2\" class=\"data row1 col2\" >54.79%</td>\n",
       "      <td id=\"T_ec206_row1_col3\" class=\"data row1 col3\" >49.19%</td>\n",
       "      <td id=\"T_ec206_row1_col4\" class=\"data row1 col4\" >keras</td>\n",
       "      <td id=\"T_ec206_row1_col5\" class=\"data row1 col5\" >True</td>\n",
       "      <td id=\"T_ec206_row1_col6\" class=\"data row1 col6\" >Sequential</td>\n",
       "      <td id=\"T_ec206_row1_col7\" class=\"data row1 col7\" >11.000000</td>\n",
       "      <td id=\"T_ec206_row1_col8\" class=\"data row1 col8\" >2773673.000000</td>\n",
       "      <td id=\"T_ec206_row1_col9\" class=\"data row1 col9\" >2.000000</td>\n",
       "      <td id=\"T_ec206_row1_col10\" class=\"data row1 col10\" >4.000000</td>\n",
       "      <td id=\"T_ec206_row1_col11\" class=\"data row1 col11\" >1.000000</td>\n",
       "      <td id=\"T_ec206_row1_col12\" class=\"data row1 col12\" >2.000000</td>\n",
       "      <td id=\"T_ec206_row1_col13\" class=\"data row1 col13\" >2.000000</td>\n",
       "      <td id=\"T_ec206_row1_col14\" class=\"data row1 col14\" >5.000000</td>\n",
       "      <td id=\"T_ec206_row1_col15\" class=\"data row1 col15\" >1.000000</td>\n",
       "      <td id=\"T_ec206_row1_col16\" class=\"data row1 col16\" >str</td>\n",
       "      <td id=\"T_ec206_row1_col17\" class=\"data row1 col17\" >RMSprop</td>\n",
       "      <td id=\"T_ec206_row1_col18\" class=\"data row1 col18\" >11096464.000000</td>\n",
       "      <td id=\"T_ec206_row1_col19\" class=\"data row1 col19\" >IEOR_Data_Mining</td>\n",
       "      <td id=\"T_ec206_row1_col20\" class=\"data row1 col20\" >4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ec206_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_ec206_row2_col0\" class=\"data row2 col0\" >42.78%</td>\n",
       "      <td id=\"T_ec206_row2_col1\" class=\"data row2 col1\" >39.01%</td>\n",
       "      <td id=\"T_ec206_row2_col2\" class=\"data row2 col2\" >37.25%</td>\n",
       "      <td id=\"T_ec206_row2_col3\" class=\"data row2 col3\" >45.00%</td>\n",
       "      <td id=\"T_ec206_row2_col4\" class=\"data row2 col4\" >keras</td>\n",
       "      <td id=\"T_ec206_row2_col5\" class=\"data row2 col5\" >True</td>\n",
       "      <td id=\"T_ec206_row2_col6\" class=\"data row2 col6\" >Sequential</td>\n",
       "      <td id=\"T_ec206_row2_col7\" class=\"data row2 col7\" >11.000000</td>\n",
       "      <td id=\"T_ec206_row2_col8\" class=\"data row2 col8\" >1850913.000000</td>\n",
       "      <td id=\"T_ec206_row2_col9\" class=\"data row2 col9\" >2.000000</td>\n",
       "      <td id=\"T_ec206_row2_col10\" class=\"data row2 col10\" >4.000000</td>\n",
       "      <td id=\"T_ec206_row2_col11\" class=\"data row2 col11\" >1.000000</td>\n",
       "      <td id=\"T_ec206_row2_col12\" class=\"data row2 col12\" >2.000000</td>\n",
       "      <td id=\"T_ec206_row2_col13\" class=\"data row2 col13\" >2.000000</td>\n",
       "      <td id=\"T_ec206_row2_col14\" class=\"data row2 col14\" >5.000000</td>\n",
       "      <td id=\"T_ec206_row2_col15\" class=\"data row2 col15\" >1.000000</td>\n",
       "      <td id=\"T_ec206_row2_col16\" class=\"data row2 col16\" >str</td>\n",
       "      <td id=\"T_ec206_row2_col17\" class=\"data row2 col17\" >RMSprop</td>\n",
       "      <td id=\"T_ec206_row2_col18\" class=\"data row2 col18\" >7405424.000000</td>\n",
       "      <td id=\"T_ec206_row2_col19\" class=\"data row2 col19\" >IEOR_Data_Mining</td>\n",
       "      <td id=\"T_ec206_row2_col20\" class=\"data row2 col20\" >1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ec206_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_ec206_row3_col0\" class=\"data row3 col0\" >34.06%</td>\n",
       "      <td id=\"T_ec206_row3_col1\" class=\"data row3 col1\" >26.50%</td>\n",
       "      <td id=\"T_ec206_row3_col2\" class=\"data row3 col2\" >31.96%</td>\n",
       "      <td id=\"T_ec206_row3_col3\" class=\"data row3 col3\" >34.42%</td>\n",
       "      <td id=\"T_ec206_row3_col4\" class=\"data row3 col4\" >keras</td>\n",
       "      <td id=\"T_ec206_row3_col5\" class=\"data row3 col5\" >True</td>\n",
       "      <td id=\"T_ec206_row3_col6\" class=\"data row3 col6\" >Sequential</td>\n",
       "      <td id=\"T_ec206_row3_col7\" class=\"data row3 col7\" >5.000000</td>\n",
       "      <td id=\"T_ec206_row3_col8\" class=\"data row3 col8\" >11805061.000000</td>\n",
       "      <td id=\"T_ec206_row3_col9\" class=\"data row3 col9\" >4.000000</td>\n",
       "      <td id=\"T_ec206_row3_col10\" class=\"data row3 col10\" >nan</td>\n",
       "      <td id=\"T_ec206_row3_col11\" class=\"data row3 col11\" >1.000000</td>\n",
       "      <td id=\"T_ec206_row3_col12\" class=\"data row3 col12\" >nan</td>\n",
       "      <td id=\"T_ec206_row3_col13\" class=\"data row3 col13\" >nan</td>\n",
       "      <td id=\"T_ec206_row3_col14\" class=\"data row3 col14\" >3.000000</td>\n",
       "      <td id=\"T_ec206_row3_col15\" class=\"data row3 col15\" >1.000000</td>\n",
       "      <td id=\"T_ec206_row3_col16\" class=\"data row3 col16\" >str</td>\n",
       "      <td id=\"T_ec206_row3_col17\" class=\"data row3 col17\" >RMSprop</td>\n",
       "      <td id=\"T_ec206_row3_col18\" class=\"data row3 col18\" >47221344.000000</td>\n",
       "      <td id=\"T_ec206_row3_col19\" class=\"data row3 col19\" >IEOR_Data_Mining</td>\n",
       "      <td id=\"T_ec206_row3_col20\" class=\"data row3 col20\" >2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ec206_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_ec206_row4_col0\" class=\"data row4 col0\" >21.25%</td>\n",
       "      <td id=\"T_ec206_row4_col1\" class=\"data row4 col1\" >21.16%</td>\n",
       "      <td id=\"T_ec206_row4_col2\" class=\"data row4 col2\" >21.26%</td>\n",
       "      <td id=\"T_ec206_row4_col3\" class=\"data row4 col3\" >21.11%</td>\n",
       "      <td id=\"T_ec206_row4_col4\" class=\"data row4 col4\" >unknown</td>\n",
       "      <td id=\"T_ec206_row4_col5\" class=\"data row4 col5\" >nan</td>\n",
       "      <td id=\"T_ec206_row4_col6\" class=\"data row4 col6\" >unknown</td>\n",
       "      <td id=\"T_ec206_row4_col7\" class=\"data row4 col7\" >nan</td>\n",
       "      <td id=\"T_ec206_row4_col8\" class=\"data row4 col8\" >nan</td>\n",
       "      <td id=\"T_ec206_row4_col9\" class=\"data row4 col9\" >nan</td>\n",
       "      <td id=\"T_ec206_row4_col10\" class=\"data row4 col10\" >nan</td>\n",
       "      <td id=\"T_ec206_row4_col11\" class=\"data row4 col11\" >nan</td>\n",
       "      <td id=\"T_ec206_row4_col12\" class=\"data row4 col12\" >nan</td>\n",
       "      <td id=\"T_ec206_row4_col13\" class=\"data row4 col13\" >nan</td>\n",
       "      <td id=\"T_ec206_row4_col14\" class=\"data row4 col14\" >nan</td>\n",
       "      <td id=\"T_ec206_row4_col15\" class=\"data row4 col15\" >nan</td>\n",
       "      <td id=\"T_ec206_row4_col16\" class=\"data row4 col16\" >nan</td>\n",
       "      <td id=\"T_ec206_row4_col17\" class=\"data row4 col17\" >nan</td>\n",
       "      <td id=\"T_ec206_row4_col18\" class=\"data row4 col18\" >nan</td>\n",
       "      <td id=\"T_ec206_row4_col19\" class=\"data row4 col19\" >IEOR_Data_Mining</td>\n",
       "      <td id=\"T_ec206_row4_col20\" class=\"data row4 col20\" >5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f0be1c89490>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get leaderboard to explore current best model architectures\n",
    "\n",
    "# Get raw data in pandas data frame\n",
    "data = mycompetition.get_leaderboard()\n",
    "\n",
    "# Stylize leaderboard data\n",
    "mycompetition.stylize_leaderboard(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OK9F-jPs38K5"
   },
   "source": [
    "You can also compare two or more models for any models submitted to the leaderboard using example code for model metadata extraction (see code tab for this competition at www.modelshare.org for submission examples.)\n",
    "```\n",
    "data=mycompetition.compare_models([1,2], verbose=1)\n",
    "mycompetition.stylize_compare(data)\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bwNKs0wP4r5s"
   },
   "source": [
    "#####  (Optional Extension) Submit Model With Custom Metadata: \n",
    "Can use to add team names or any other missing data you may wish to share on the leaderboard\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FgSs5PAtPCZH"
   },
   "outputs": [],
   "source": [
    "# Custom metadata can be added by passing a dict to the custom_metadata argument of the submit_model() method\n",
    "# This option can be used to fill in missing data points or add new columns to the leaderboard\n",
    "\n",
    "custom_meta = {'team': 'team one',\n",
    "               'model_type': 'your_model_type',\n",
    "               'new_column': 'new metadata'}\n",
    "\n",
    "mycompetition.submit_model(model_filepath = None,\n",
    "                                 preprocessor_filepath=None,\n",
    "                                 prediction_submission=predicted_values,\n",
    "                                 custom_metadata = custom_meta)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
