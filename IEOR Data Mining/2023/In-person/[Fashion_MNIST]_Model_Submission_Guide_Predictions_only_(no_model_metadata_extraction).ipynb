{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<p align=\"center\"><img width=\"50%\" src=\"https://aimodelsharecontent.s3.amazonaws.com/aimodshare_banner.jpg\" /></p>\n",
        "\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "m_DMeZsXxpEZ"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JXxGTgJz152A"
      },
      "source": [
        "<p align=\"center\"><h1 align=\"center\">Fashion-MNIST Image Classification Model Submission Guide - Predictions Only (No Model Metadata Extraction)\n",
        "\n",
        "---\n",
        "Let's share our models to a centralized leaderboard, so that we can collaborate and learn from the model experimentation process...\n",
        "\n",
        "**Instructions:**\n",
        "1.   Get data in and set up X_train / X_test / y_train\n",
        "2.   Preprocess data\n",
        "3. Fit model on preprocessed data\n",
        "4. Generate predictions from X_test data and submit to competition\n",
        "5. Repeat submission process to improve place on leaderboard\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5gSrVJwp3E9H"
      },
      "source": [
        "## 1. Get data in and set up X_train, X_test, y_train objects"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PLTIaMB3ChSW"
      },
      "source": [
        "#install aimodelshare library\n",
        "! pip install aimodelshare --upgrade"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d3PiJXBhC5y-",
        "outputId": "2d802670-bd30-4d3b-cf97-f758f8dca85e"
      },
      "source": [
        "# Get competition data\n",
        "from aimodelshare import download_data\n",
        "download_data('public.ecr.aws/y2e2a1d6/fashion_mnist_competition_data-repository:latest') "
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading [================================================>]\n",
            "\n",
            "Data downloaded successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gEzPoXPj3V7u"
      },
      "source": [
        "##2.   Preprocess data\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Here is a pre-designed preprocessor, but you could also build your own to prepare the data differently\n",
        "\n",
        "def preprocessor(image_filepath, shape=(28, 28)):\n",
        "        \"\"\"\n",
        "        This function reads in images, resizes them to a fixed shape and\n",
        "        min/max transforms them before converting feature values to float32 numeric values\n",
        "        required by onnx files.\n",
        "        \n",
        "        params:\n",
        "            image_filepath\n",
        "                full filepath of a particular image\n",
        "                      \n",
        "        returns:\n",
        "            X\n",
        "                numpy array of preprocessed image data\n",
        "        \"\"\"\n",
        "           \n",
        "        import cv2\n",
        "        import numpy as np\n",
        "\n",
        "        \"Resize a color image and min/max transform the image\"\n",
        "        img = cv2.imread(image_filepath) # Read in image from filepath.\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB) # cv2 reads in images in order of blue green and red, we reverse the order for ML.\n",
        "        img = cv2.resize(img, shape) # Change height and width of image.\n",
        "        img = img / 255.0 # Min-max transform.\n",
        "\n",
        "        # Resize all the images...\n",
        "        X = np.array(img)\n",
        "        X = np.expand_dims(X, axis=0) # Expand dims to add \"1\" to object shape [1, h, w, channels] for keras model.\n",
        "        X = np.array(X, dtype=np.float32) # Final shape for onnx runtime.\n",
        "        return X"
      ],
      "metadata": {
        "id": "HbYM9lI6Wo15"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jT0qFCZFNzHq"
      },
      "source": [
        "#  Create training data objects\n",
        "\n",
        "# Preprocess X_train image data to generate predictions from models \n",
        "import numpy as np\n",
        "\n",
        "file_names = [('fashion_mnist_competition_data/training_data/train_' + str(i) + '.jpeg') for i in range(60000)]\n",
        "preprocessed_image_data = [preprocessor(x) for x in file_names]\n",
        "\n",
        "#Create single X_test array from preprocessed images\n",
        "X_train = np.vstack(preprocessed_image_data) \n",
        "\n",
        "# Load y_train labels \n",
        "import pickle\n",
        "with open(\"fashion_mnist_competition_data/y_train_labels.pkl\", \"rb\") as fp:  \n",
        "    y_train_labels = pickle.load(fp)\n",
        "\n",
        "# One-hot encode y_train labels (y_train.columns used to generate prediction labels below)\n",
        "import pandas as pd\n",
        "y_train = pd.get_dummies(y_train_labels)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create test data objects\n",
        "\n",
        "# Preprocess X_test image data to generate predictions from models \n",
        "import numpy as np\n",
        "\n",
        "file_names = [('fashion_mnist_competition_data/test_data/test_' + str(i) + '.jpeg') for i in range(10000)]\n",
        "preprocessed_image_data = [preprocessor(x) for x in file_names]\n",
        "\n",
        "#Create single X_test array from preprocessed images\n",
        "X_test = np.vstack(preprocessed_image_data) "
      ],
      "metadata": {
        "id": "C46W_rEJWhio"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train.shape)\n",
        "print(X_test.shape)\n",
        "print(y_train.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uq_XUtjYxamD",
        "outputId": "169a1f25-1182-488c-9134-cbbbc5a11369"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(60000, 28, 28, 3)\n",
            "(10000, 28, 28, 3)\n",
            "(60000, 10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X52kECL43b-O"
      },
      "source": [
        "##3. Fit model on preprocessed data\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NCbBf8j9ClYl"
      },
      "source": [
        "# Write and execute code to fit model on preprocessed data here."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RtgkM02MDpkO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e95902b6-023f-4423-b515-4a59fa9ea22a"
      },
      "source": [
        "#Set credentials using modelshare.org username/password\n",
        "\n",
        "from aimodelshare.aws import set_credentials\n",
        "    \n",
        "apiurl=\"https://nt9u2xcbdf.execute-api.us-east-1.amazonaws.com/prod/m\"\n",
        "#This is the unique rest api that powers this Fashhion-MNIST Image Classification Playground\n",
        "\n",
        "set_credentials(apiurl=apiurl)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AI Modelshare Username:··········\n",
            "AI Modelshare Password:··········\n",
            "AI Model Share login credentials set successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fKNGSww8EGgi"
      },
      "source": [
        "#Instantiate Competition\n",
        "import aimodelshare as ai\n",
        "mycompetition= ai.Competition(apiurl)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **4. Submit Model predictions to leaderboard (without extracting model architecture information):**\n",
        "- model metadata extraction allows you use compare_models() and instantiate_model() functions."
      ],
      "metadata": {
        "id": "W66Pr1_K2sQV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Generate a list of predictions using X_test data\n",
        "\n",
        "# This example uses randomly chosen values from y_train to generate a list of predictions\n",
        "predicted_values = list(y_train_labels.sample(n=len(X_test)))"
      ],
      "metadata": {
        "id": "IS09g9DF0HGP"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Ql4wksyEUnP"
      },
      "source": [
        "#Submit Model predictions to leaderboard (without extracting model architecture information): \n",
        "\n",
        "# Submit to Competition Leaderboard\n",
        "mycompetition.submit_model(model_filepath = None,\n",
        "                                 preprocessor_filepath=None,\n",
        "                                 prediction_submission=predicted_values)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 194
        },
        "id": "GN1zvAmNEq17",
        "outputId": "1967a5e0-df21-4a92-aa42-6e30522a35c7"
      },
      "source": [
        "# Get leaderboard to explore current best model architectures\n",
        "\n",
        "# Get raw data in pandas data frame\n",
        "data = mycompetition.get_leaderboard()\n",
        "\n",
        "# Stylize leaderboard data\n",
        "mycompetition.stylize_leaderboard(data)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pandas.io.formats.style.Styler at 0x7f35a9b008b0>"
            ],
            "text/html": [
              "<style type=\"text/css\">\n",
              "#T_26d82_row0_col0 {\n",
              "  text-align: center;\n",
              "  width: 10em;\n",
              "  background: linear-gradient(90deg, #f5f8d6 88.0%, transparent 88.0%);\n",
              "  color: #251e1b;\n",
              "  font-size: 12px;\n",
              "}\n",
              "#T_26d82_row0_col1 {\n",
              "  text-align: center;\n",
              "  width: 10em;\n",
              "  background: linear-gradient(90deg, #c778c8 87.8%, transparent 87.8%);\n",
              "  color: #251e1b;\n",
              "  font-size: 12px;\n",
              "}\n",
              "#T_26d82_row0_col2 {\n",
              "  text-align: center;\n",
              "  width: 10em;\n",
              "  background: linear-gradient(90deg, #ff4971 87.9%, transparent 87.9%);\n",
              "  color: #251e1b;\n",
              "  font-size: 12px;\n",
              "}\n",
              "#T_26d82_row0_col3 {\n",
              "  text-align: center;\n",
              "  width: 10em;\n",
              "  background: linear-gradient(90deg, #aadbaa 88.0%, transparent 88.0%);\n",
              "  color: #251e1b;\n",
              "  font-size: 12px;\n",
              "}\n",
              "#T_26d82_row0_col4, #T_26d82_row0_col5, #T_26d82_row0_col6, #T_26d82_row0_col7, #T_26d82_row0_col8, #T_26d82_row0_col9, #T_26d82_row0_col10, #T_26d82_row0_col11, #T_26d82_row0_col12, #T_26d82_row0_col13, #T_26d82_row0_col14, #T_26d82_row0_col15, #T_26d82_row0_col16, #T_26d82_row0_col17, #T_26d82_row0_col18, #T_26d82_row0_col19, #T_26d82_row0_col20, #T_26d82_row1_col4, #T_26d82_row1_col5, #T_26d82_row1_col6, #T_26d82_row1_col7, #T_26d82_row1_col8, #T_26d82_row1_col9, #T_26d82_row1_col10, #T_26d82_row1_col11, #T_26d82_row1_col12, #T_26d82_row1_col13, #T_26d82_row1_col14, #T_26d82_row1_col15, #T_26d82_row1_col16, #T_26d82_row1_col17, #T_26d82_row1_col18, #T_26d82_row1_col19, #T_26d82_row1_col20, #T_26d82_row2_col4, #T_26d82_row2_col5, #T_26d82_row2_col6, #T_26d82_row2_col7, #T_26d82_row2_col8, #T_26d82_row2_col9, #T_26d82_row2_col10, #T_26d82_row2_col11, #T_26d82_row2_col12, #T_26d82_row2_col13, #T_26d82_row2_col14, #T_26d82_row2_col15, #T_26d82_row2_col16, #T_26d82_row2_col17, #T_26d82_row2_col18, #T_26d82_row2_col19, #T_26d82_row2_col20, #T_26d82_row3_col4, #T_26d82_row3_col5, #T_26d82_row3_col6, #T_26d82_row3_col7, #T_26d82_row3_col8, #T_26d82_row3_col9, #T_26d82_row3_col10, #T_26d82_row3_col11, #T_26d82_row3_col12, #T_26d82_row3_col13, #T_26d82_row3_col14, #T_26d82_row3_col15, #T_26d82_row3_col16, #T_26d82_row3_col17, #T_26d82_row3_col18, #T_26d82_row3_col19, #T_26d82_row3_col20 {\n",
              "  text-align: center;\n",
              "}\n",
              "#T_26d82_row1_col0 {\n",
              "  text-align: center;\n",
              "  width: 10em;\n",
              "  background: linear-gradient(90deg, #f5f8d6 85.4%, transparent 85.4%);\n",
              "  color: #251e1b;\n",
              "  font-size: 12px;\n",
              "}\n",
              "#T_26d82_row1_col1 {\n",
              "  text-align: center;\n",
              "  width: 10em;\n",
              "  background: linear-gradient(90deg, #c778c8 85.4%, transparent 85.4%);\n",
              "  color: #251e1b;\n",
              "  font-size: 12px;\n",
              "}\n",
              "#T_26d82_row1_col2 {\n",
              "  text-align: center;\n",
              "  width: 10em;\n",
              "  background: linear-gradient(90deg, #ff4971 85.5%, transparent 85.5%);\n",
              "  color: #251e1b;\n",
              "  font-size: 12px;\n",
              "}\n",
              "#T_26d82_row1_col3 {\n",
              "  text-align: center;\n",
              "  width: 10em;\n",
              "  background: linear-gradient(90deg, #aadbaa 85.4%, transparent 85.4%);\n",
              "  color: #251e1b;\n",
              "  font-size: 12px;\n",
              "}\n",
              "#T_26d82_row2_col0 {\n",
              "  text-align: center;\n",
              "  width: 10em;\n",
              "  background: linear-gradient(90deg, #f5f8d6 82.6%, transparent 82.6%);\n",
              "  color: #251e1b;\n",
              "  font-size: 12px;\n",
              "}\n",
              "#T_26d82_row2_col1 {\n",
              "  text-align: center;\n",
              "  width: 10em;\n",
              "  background: linear-gradient(90deg, #c778c8 83.0%, transparent 83.0%);\n",
              "  color: #251e1b;\n",
              "  font-size: 12px;\n",
              "}\n",
              "#T_26d82_row2_col2 {\n",
              "  text-align: center;\n",
              "  width: 10em;\n",
              "  background: linear-gradient(90deg, #ff4971 84.8%, transparent 84.8%);\n",
              "  color: #251e1b;\n",
              "  font-size: 12px;\n",
              "}\n",
              "#T_26d82_row2_col3 {\n",
              "  text-align: center;\n",
              "  width: 10em;\n",
              "  background: linear-gradient(90deg, #aadbaa 82.6%, transparent 82.6%);\n",
              "  color: #251e1b;\n",
              "  font-size: 12px;\n",
              "}\n",
              "#T_26d82_row3_col0 {\n",
              "  text-align: center;\n",
              "  width: 10em;\n",
              "  background: linear-gradient(90deg, #f5f8d6 10.9%, transparent 10.9%);\n",
              "  color: #251e1b;\n",
              "  font-size: 12px;\n",
              "}\n",
              "#T_26d82_row3_col1 {\n",
              "  text-align: center;\n",
              "  width: 10em;\n",
              "  background: linear-gradient(90deg, #c778c8 10.9%, transparent 10.9%);\n",
              "  color: #251e1b;\n",
              "  font-size: 12px;\n",
              "}\n",
              "#T_26d82_row3_col2 {\n",
              "  text-align: center;\n",
              "  width: 10em;\n",
              "  background: linear-gradient(90deg, #ff4971 10.9%, transparent 10.9%);\n",
              "  color: #251e1b;\n",
              "  font-size: 12px;\n",
              "}\n",
              "#T_26d82_row3_col3 {\n",
              "  text-align: center;\n",
              "  width: 10em;\n",
              "  background: linear-gradient(90deg, #aadbaa 10.9%, transparent 10.9%);\n",
              "  color: #251e1b;\n",
              "  font-size: 12px;\n",
              "}\n",
              "</style>\n",
              "<table id=\"T_26d82\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th class=\"blank level0\" >&nbsp;</th>\n",
              "      <th id=\"T_26d82_level0_col0\" class=\"col_heading level0 col0\" >accuracy</th>\n",
              "      <th id=\"T_26d82_level0_col1\" class=\"col_heading level0 col1\" >f1_score</th>\n",
              "      <th id=\"T_26d82_level0_col2\" class=\"col_heading level0 col2\" >precision</th>\n",
              "      <th id=\"T_26d82_level0_col3\" class=\"col_heading level0 col3\" >recall</th>\n",
              "      <th id=\"T_26d82_level0_col4\" class=\"col_heading level0 col4\" >ml_framework</th>\n",
              "      <th id=\"T_26d82_level0_col5\" class=\"col_heading level0 col5\" >deep_learning</th>\n",
              "      <th id=\"T_26d82_level0_col6\" class=\"col_heading level0 col6\" >model_type</th>\n",
              "      <th id=\"T_26d82_level0_col7\" class=\"col_heading level0 col7\" >depth</th>\n",
              "      <th id=\"T_26d82_level0_col8\" class=\"col_heading level0 col8\" >num_params</th>\n",
              "      <th id=\"T_26d82_level0_col9\" class=\"col_heading level0 col9\" >conv2d_layers</th>\n",
              "      <th id=\"T_26d82_level0_col10\" class=\"col_heading level0 col10\" >maxpooling2d_layers</th>\n",
              "      <th id=\"T_26d82_level0_col11\" class=\"col_heading level0 col11\" >flatten_layers</th>\n",
              "      <th id=\"T_26d82_level0_col12\" class=\"col_heading level0 col12\" >dropout_layers</th>\n",
              "      <th id=\"T_26d82_level0_col13\" class=\"col_heading level0 col13\" >dense_layers</th>\n",
              "      <th id=\"T_26d82_level0_col14\" class=\"col_heading level0 col14\" >relu_act</th>\n",
              "      <th id=\"T_26d82_level0_col15\" class=\"col_heading level0 col15\" >softmax_act</th>\n",
              "      <th id=\"T_26d82_level0_col16\" class=\"col_heading level0 col16\" >loss</th>\n",
              "      <th id=\"T_26d82_level0_col17\" class=\"col_heading level0 col17\" >optimizer</th>\n",
              "      <th id=\"T_26d82_level0_col18\" class=\"col_heading level0 col18\" >memory_size</th>\n",
              "      <th id=\"T_26d82_level0_col19\" class=\"col_heading level0 col19\" >username</th>\n",
              "      <th id=\"T_26d82_level0_col20\" class=\"col_heading level0 col20\" >version</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th id=\"T_26d82_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
              "      <td id=\"T_26d82_row0_col0\" class=\"data row0 col0\" >87.98%</td>\n",
              "      <td id=\"T_26d82_row0_col1\" class=\"data row0 col1\" >87.84%</td>\n",
              "      <td id=\"T_26d82_row0_col2\" class=\"data row0 col2\" >87.94%</td>\n",
              "      <td id=\"T_26d82_row0_col3\" class=\"data row0 col3\" >87.98%</td>\n",
              "      <td id=\"T_26d82_row0_col4\" class=\"data row0 col4\" >keras</td>\n",
              "      <td id=\"T_26d82_row0_col5\" class=\"data row0 col5\" >True</td>\n",
              "      <td id=\"T_26d82_row0_col6\" class=\"data row0 col6\" >Sequential</td>\n",
              "      <td id=\"T_26d82_row0_col7\" class=\"data row0 col7\" >11.000000</td>\n",
              "      <td id=\"T_26d82_row0_col8\" class=\"data row0 col8\" >88688.000000</td>\n",
              "      <td id=\"T_26d82_row0_col9\" class=\"data row0 col9\" >4.000000</td>\n",
              "      <td id=\"T_26d82_row0_col10\" class=\"data row0 col10\" >2.000000</td>\n",
              "      <td id=\"T_26d82_row0_col11\" class=\"data row0 col11\" >1.000000</td>\n",
              "      <td id=\"T_26d82_row0_col12\" class=\"data row0 col12\" >2.000000</td>\n",
              "      <td id=\"T_26d82_row0_col13\" class=\"data row0 col13\" >2.000000</td>\n",
              "      <td id=\"T_26d82_row0_col14\" class=\"data row0 col14\" >5.000000</td>\n",
              "      <td id=\"T_26d82_row0_col15\" class=\"data row0 col15\" >1.000000</td>\n",
              "      <td id=\"T_26d82_row0_col16\" class=\"data row0 col16\" >str</td>\n",
              "      <td id=\"T_26d82_row0_col17\" class=\"data row0 col17\" >RMSprop</td>\n",
              "      <td id=\"T_26d82_row0_col18\" class=\"data row0 col18\" >356520.000000</td>\n",
              "      <td id=\"T_26d82_row0_col19\" class=\"data row0 col19\" >IEOR_Data_Mining</td>\n",
              "      <td id=\"T_26d82_row0_col20\" class=\"data row0 col20\" >3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_26d82_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
              "      <td id=\"T_26d82_row1_col0\" class=\"data row1 col0\" >85.36%</td>\n",
              "      <td id=\"T_26d82_row1_col1\" class=\"data row1 col1\" >85.37%</td>\n",
              "      <td id=\"T_26d82_row1_col2\" class=\"data row1 col2\" >85.53%</td>\n",
              "      <td id=\"T_26d82_row1_col3\" class=\"data row1 col3\" >85.36%</td>\n",
              "      <td id=\"T_26d82_row1_col4\" class=\"data row1 col4\" >keras</td>\n",
              "      <td id=\"T_26d82_row1_col5\" class=\"data row1 col5\" >True</td>\n",
              "      <td id=\"T_26d82_row1_col6\" class=\"data row1 col6\" >Sequential</td>\n",
              "      <td id=\"T_26d82_row1_col7\" class=\"data row1 col7\" >11.000000</td>\n",
              "      <td id=\"T_26d82_row1_col8\" class=\"data row1 col8\" >47168.000000</td>\n",
              "      <td id=\"T_26d82_row1_col9\" class=\"data row1 col9\" >4.000000</td>\n",
              "      <td id=\"T_26d82_row1_col10\" class=\"data row1 col10\" >2.000000</td>\n",
              "      <td id=\"T_26d82_row1_col11\" class=\"data row1 col11\" >1.000000</td>\n",
              "      <td id=\"T_26d82_row1_col12\" class=\"data row1 col12\" >2.000000</td>\n",
              "      <td id=\"T_26d82_row1_col13\" class=\"data row1 col13\" >2.000000</td>\n",
              "      <td id=\"T_26d82_row1_col14\" class=\"data row1 col14\" >5.000000</td>\n",
              "      <td id=\"T_26d82_row1_col15\" class=\"data row1 col15\" >1.000000</td>\n",
              "      <td id=\"T_26d82_row1_col16\" class=\"data row1 col16\" >str</td>\n",
              "      <td id=\"T_26d82_row1_col17\" class=\"data row1 col17\" >RMSprop</td>\n",
              "      <td id=\"T_26d82_row1_col18\" class=\"data row1 col18\" >190440.000000</td>\n",
              "      <td id=\"T_26d82_row1_col19\" class=\"data row1 col19\" >IEOR_Data_Mining</td>\n",
              "      <td id=\"T_26d82_row1_col20\" class=\"data row1 col20\" >1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_26d82_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
              "      <td id=\"T_26d82_row2_col0\" class=\"data row2 col0\" >82.62%</td>\n",
              "      <td id=\"T_26d82_row2_col1\" class=\"data row2 col1\" >83.03%</td>\n",
              "      <td id=\"T_26d82_row2_col2\" class=\"data row2 col2\" >84.80%</td>\n",
              "      <td id=\"T_26d82_row2_col3\" class=\"data row2 col3\" >82.62%</td>\n",
              "      <td id=\"T_26d82_row2_col4\" class=\"data row2 col4\" >keras</td>\n",
              "      <td id=\"T_26d82_row2_col5\" class=\"data row2 col5\" >True</td>\n",
              "      <td id=\"T_26d82_row2_col6\" class=\"data row2 col6\" >Sequential</td>\n",
              "      <td id=\"T_26d82_row2_col7\" class=\"data row2 col7\" >5.000000</td>\n",
              "      <td id=\"T_26d82_row2_col8\" class=\"data row2 col8\" >514698.000000</td>\n",
              "      <td id=\"T_26d82_row2_col9\" class=\"data row2 col9\" >nan</td>\n",
              "      <td id=\"T_26d82_row2_col10\" class=\"data row2 col10\" >nan</td>\n",
              "      <td id=\"T_26d82_row2_col11\" class=\"data row2 col11\" >1.000000</td>\n",
              "      <td id=\"T_26d82_row2_col12\" class=\"data row2 col12\" >nan</td>\n",
              "      <td id=\"T_26d82_row2_col13\" class=\"data row2 col13\" >4.000000</td>\n",
              "      <td id=\"T_26d82_row2_col14\" class=\"data row2 col14\" >3.000000</td>\n",
              "      <td id=\"T_26d82_row2_col15\" class=\"data row2 col15\" >1.000000</td>\n",
              "      <td id=\"T_26d82_row2_col16\" class=\"data row2 col16\" >str</td>\n",
              "      <td id=\"T_26d82_row2_col17\" class=\"data row2 col17\" >RMSprop</td>\n",
              "      <td id=\"T_26d82_row2_col18\" class=\"data row2 col18\" >2059888.000000</td>\n",
              "      <td id=\"T_26d82_row2_col19\" class=\"data row2 col19\" >IEOR_Data_Mining</td>\n",
              "      <td id=\"T_26d82_row2_col20\" class=\"data row2 col20\" >2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_26d82_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
              "      <td id=\"T_26d82_row3_col0\" class=\"data row3 col0\" >10.92%</td>\n",
              "      <td id=\"T_26d82_row3_col1\" class=\"data row3 col1\" >10.90%</td>\n",
              "      <td id=\"T_26d82_row3_col2\" class=\"data row3 col2\" >10.89%</td>\n",
              "      <td id=\"T_26d82_row3_col3\" class=\"data row3 col3\" >10.92%</td>\n",
              "      <td id=\"T_26d82_row3_col4\" class=\"data row3 col4\" >unknown</td>\n",
              "      <td id=\"T_26d82_row3_col5\" class=\"data row3 col5\" >nan</td>\n",
              "      <td id=\"T_26d82_row3_col6\" class=\"data row3 col6\" >unknown</td>\n",
              "      <td id=\"T_26d82_row3_col7\" class=\"data row3 col7\" >nan</td>\n",
              "      <td id=\"T_26d82_row3_col8\" class=\"data row3 col8\" >nan</td>\n",
              "      <td id=\"T_26d82_row3_col9\" class=\"data row3 col9\" >nan</td>\n",
              "      <td id=\"T_26d82_row3_col10\" class=\"data row3 col10\" >nan</td>\n",
              "      <td id=\"T_26d82_row3_col11\" class=\"data row3 col11\" >nan</td>\n",
              "      <td id=\"T_26d82_row3_col12\" class=\"data row3 col12\" >nan</td>\n",
              "      <td id=\"T_26d82_row3_col13\" class=\"data row3 col13\" >nan</td>\n",
              "      <td id=\"T_26d82_row3_col14\" class=\"data row3 col14\" >nan</td>\n",
              "      <td id=\"T_26d82_row3_col15\" class=\"data row3 col15\" >nan</td>\n",
              "      <td id=\"T_26d82_row3_col16\" class=\"data row3 col16\" >nan</td>\n",
              "      <td id=\"T_26d82_row3_col17\" class=\"data row3 col17\" >nan</td>\n",
              "      <td id=\"T_26d82_row3_col18\" class=\"data row3 col18\" >nan</td>\n",
              "      <td id=\"T_26d82_row3_col19\" class=\"data row3 col19\" >IEOR_Data_Mining</td>\n",
              "      <td id=\"T_26d82_row3_col20\" class=\"data row3 col20\" >4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can also compare two or more models for any models submitted to the leaderboard using example code for model metadata extraction (see code tab for this competition at www.modelshare.org for submission examples.)\n",
        "```\n",
        "data=mycompetition.compare_models([1,2], verbose=1)\n",
        "mycompetition.stylize_compare(data)\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "OK9F-jPs38K5"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bwNKs0wP4r5s"
      },
      "source": [
        "#####  (Optional Extension) Submit Model With Custom Metadata: \n",
        "Can use to add team names or any other missing data you may wish to share on the leaderboard\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FgSs5PAtPCZH"
      },
      "source": [
        "# Custom metadata can be added by passing a dict to the custom_metadata argument of the submit_model() method\n",
        "# This option can be used to fill in missing data points or add new columns to the leaderboard\n",
        "\n",
        "custom_meta = {'team': 'team one',\n",
        "               'model_type': 'your_model_type',\n",
        "               'new_column': 'new metadata'}\n",
        "\n",
        "mycompetition.submit_model(model_filepath = None,\n",
        "                                 preprocessor_filepath=None,\n",
        "                                 prediction_submission=predicted_values,\n",
        "                                 custom_metadata = custom_meta)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}