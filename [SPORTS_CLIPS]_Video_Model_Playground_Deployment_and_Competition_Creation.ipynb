{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0BviI4QIdWiq"
   },
   "source": [
    "<p align=\"center\"><img width=\"50%\" src=\"https://aimodelsharecontent.s3.amazonaws.com/aimodshare_banner.jpg\" /></p>\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gYNp684Tk3tb"
   },
   "source": [
    "<p align=\"center\"><h1 align=\"center\">Quick Start: Sports Clips Video Classification Tutorial</h1> \n",
    "\n",
    "---\n",
    "\n",
    "<h3 align=\"center\">(Deploy model to an AI Model Share Model Playground REST API<br> and Web Dashboard in five easy steps...)</h3></p>\n",
    "<p align=\"center\"><img width=\"100%\" src=\"https://aimodelsharecontent.s3.amazonaws.com/aimstutorialsteps.gif\" /></p>\n",
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0PhJ-XlGazpD"
   },
   "source": [
    "## **Credential Configuration**\n",
    "\n",
    "In order to deploy an AI Model Share Model Playground, you will need a credentials text file. \n",
    "\n",
    "Generating your credentials file requires two sets of information: \n",
    "1. Your AI Model Share username and password (create them [HERE](https://www.modelshare.org/login)). \n",
    "2. Your AWS (Amazon Web Services) access keys (follow the tutorial [HERE](hhttps://aimodelshare.readthedocs.io/en/latest/create_credentials.html)). \n",
    "\n",
    "You only need to generate your credentials file once. After running the configure function below, save the outputted file for all your future Model Playground deployments and competition submissions. \n",
    "\n",
    "*Note: Handle your credentials file with the same level of security you handle your passwords. Do not share your file with anyone, send via email, or upload to Github.*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "puVzQBHyhS2Z"
   },
   "outputs": [],
   "source": [
    "#install aimodelshare library\n",
    "! pip install aimodelshare --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4Q7MCqBLcS20",
    "outputId": "540bb4ec-8ec5-4836-a19c-9442bb0b5abb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI Modelshare Username:··········\n",
      "AI Modelshare Password:··········\n",
      "AWS_ACCESS_KEY_ID:··········\n",
      "AWS_SECRET_ACCESS_KEY:··········\n",
      "AWS_REGION:··········\n",
      "Configuration successful. New credentials file saved as 'credentials.txt'\n"
     ]
    }
   ],
   "source": [
    "# Generate credentials file\n",
    "import aimodelshare as ai \n",
    "from aimodelshare.aws import configure_credentials \n",
    "\n",
    "configure_credentials()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VliTV_HH-uz4"
   },
   "source": [
    "## **Set up Environment**\n",
    "\n",
    "Use your credentials file to set your credentials for all aimodelshare functions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2u1QKNfEyN9A",
    "outputId": "a50c5c5a-298e-4b2d-9ab3-32bb76567e49"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI Model Share login credentials set successfully.\n",
      "AWS credentials set successfully.\n"
     ]
    }
   ],
   "source": [
    "# Set credentials \n",
    "import aimodelshare as ai\n",
    "from aimodelshare.aws import set_credentials\n",
    "\n",
    "set_credentials(credential_file=\"credentials.txt\", type=\"deploy_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PwQcTsyyURIk",
    "outputId": "d426daa9-3f92-4d52-c511-f1a8dd575152"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading [================================================>]\n",
      "\n",
      "Data downloaded successfully.\n",
      "\n",
      "Preparing downloaded files for use...\n",
      "\n",
      "Success! Your Quick Start materials have been downloaded. \n",
      "You are now ready to run the tutorial.\n"
     ]
    }
   ],
   "source": [
    "# Get materials for tutorial\n",
    "import aimodelshare as ai\n",
    "keras_model, y_train_labels = ai.import_quickstart_data(\"sports\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bIleM1F6nWSF"
   },
   "source": [
    "## **(1) Preprocessor Function & Setup**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WrEgo5zRxbed"
   },
   "source": [
    "### **Write a Preprocessor Function**\n",
    "\n",
    "\n",
    "> ###   Preprocessor functions are used to preprocess data into the precise data your model requires to generate predictions.  \n",
    "\n",
    "*  *Preprocessor functions should always be named \"preprocessor\".*\n",
    "*  *You can use any Python library in a preprocessor function, but all libraries should be imported inside your preprocessor function.*  \n",
    "*  *For image prediction models users should minimally include function inputs for an image filepath and values to reshape the image height and width.*  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "B5Jz-1cmYN5Z"
   },
   "outputs": [],
   "source": [
    "# Here is a pre-designed preprocessor, but you could also build your own to prepare the data differently\n",
    "\n",
    "def preprocessor(video_file_path, num_frames=60, gap_frames=3, **kwargs):\n",
    "\n",
    "    \"\"\"\n",
    "      This function preprocesses the data to extract frames out of each video and resize\n",
    "      them to a fixed size of (128x128) pixels. Moreover, these images are flattened out to\n",
    "      act as features for each time step.\n",
    "      \n",
    "      params:\n",
    "          video_file_path\n",
    "              location of video file to be processed\n",
    "\n",
    "          num_frames\n",
    "              the number of frames to be extracted from each video. If there aren't\n",
    "              sufficient frames, then the list is padded with zeros\n",
    "              \n",
    "          gap_frames:\n",
    "              the number of frames after which we extract the next frame. If =1,\n",
    "              contiguous frames are extracted\n",
    "              \n",
    "      returns:\n",
    "          X\n",
    "              transformed features corresponding to data passed as input to model\n",
    "      \n",
    "    \"\"\"\n",
    "\n",
    "    import cv2\n",
    "    import numpy as np\n",
    "\n",
    "    vidcap = cv2.VideoCapture(video_file_path)\n",
    "    \n",
    "    frames = []\n",
    "\n",
    "    success, frame = vidcap.read()\n",
    "    idx = 0\n",
    "\n",
    "    while success:\n",
    "        # for each frame, do if we satisfy the gap_frames parameter\n",
    "        if idx % gap_frames == 0:\n",
    "            # convert to RGB (default cv2 is BGR)\n",
    "            # this is important because the vgg model is trained on RGB images\n",
    "            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            frame = cv2.resize(frame, (128, 128))\n",
    "\n",
    "            # extract features for the resized image\n",
    "            frame = frame / 255.0 # Min-max transform.\n",
    "\n",
    "            # flatten the features and append to a list of features for this video\n",
    "            frame = frame.reshape(-1)\n",
    "\n",
    "            frames.append(frame)\n",
    "\n",
    "            if len(frames) >= num_frames:\n",
    "                break\n",
    "\n",
    "        idx += 1\n",
    "        success, frame = vidcap.read()\n",
    "\n",
    "    # if number of timesteps or frames < num_frames, pad with zeroes for consistent shape\n",
    "    while len(frames) < num_frames:\n",
    "        frames.append(np.zeros(*frames[-1].shape))\n",
    "\n",
    "    X = np.array(frames)\n",
    "    X = np.expand_dims(X, axis=0)\n",
    "    X = np.array(X, dtype=np.float32)\n",
    "\n",
    "    return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xJlhd6jvns0b"
   },
   "source": [
    "## **(2) Train Model Using tf.keras (or Your Preferred ML Library)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fP7ZIVKe3luZ"
   },
   "source": [
    "### **Keras Model with One LSTM Layer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_r-c5br8cElz",
    "outputId": "76be5c9a-13f4-4ef0-da9d-0ffc1785b08d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 50)                9840600   \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 20)                1020      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 3)                 63        \n",
      "=================================================================\n",
      "Total params: 9,841,683\n",
      "Trainable params: 9,841,683\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Here is a pre-trained keras_model, but you could also train your own model after preprocessing data with your preprocessor function.\n",
    "keras_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FZGlu5PMWbNO"
   },
   "source": [
    "## **(3) Save Preprocessor**\n",
    "### Saves preprocessor function to \"preprocessor.zip\" file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Wh_vkwblXx7r",
    "outputId": "528290eb-8042-410b-edff-188436e410e1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your preprocessor is now saved to 'preprocessor.zip'\n"
     ]
    }
   ],
   "source": [
    "import aimodelshare as ai\n",
    "ai.export_preprocessor(preprocessor,\"\") #Saving to your current working directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b58rg4pMMn4n",
    "outputId": "e3547762-8704-4f63-ec95-2c810143ebcf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 60, 49152)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  Now let's import and test the preprocessor function to see if it is working...\n",
    "\n",
    "import aimodelshare as ai\n",
    "prep=ai.import_preprocessor(\"preprocessor.zip\")\n",
    "\n",
    "prep('sports_quick_start_materials/example_data/HorseRace_ex1.avi').shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CdQOeF2J3PCv"
   },
   "source": [
    "## **(4) Save Keras Model to Onnx File Format**\n",
    "...Takes a minute b/c model has nearly 10 million parameters!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "r8fgi8f6qkbk"
   },
   "outputs": [],
   "source": [
    "# Save tf.keras model (or any tensorflow model) to local ONNX file\n",
    "from aimodelshare.aimsonnx import model_to_onnx\n",
    "\n",
    "onnx_model = model_to_onnx(keras_model, framework='keras',\n",
    "                          transfer_learning=False,\n",
    "                          deep_learning=True)\n",
    "\n",
    "with open(\"model.onnx\", \"wb\") as f:\n",
    "    f.write(onnx_model.SerializeToString())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1swt74XQUIFh"
   },
   "source": [
    "## **(5) Create your Model Playground and Deploy REST API/ Live Web-Application**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "Y-YKEcvDNmD3"
   },
   "outputs": [],
   "source": [
    "#Set up arguments for Model Playground deployment\n",
    "import pandas as pd \n",
    "\n",
    "model_filepath=\"model.onnx\"\n",
    "preprocessor_filepath=\"preprocessor.zip\"\n",
    "exampledata_filepath = \"sports_quick_start_materials/example_data\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "T8C6IlYTFN5t",
    "outputId": "86d92497-c745-417d-c942-6ecf8401b88a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We need some information about your model before we can build your REST API and interactive Model Playground.\n",
      "   \n",
      "Model Name (for AI Model Share Website):Sports Video Classifier\n",
      "Model Description (Explain what your model does and \n",
      " why end-users would find your model useful):Takes videos as input and classifiers them into one of three categories (horseracing, kayaking, or pullups). We present a model that predicts three categories only to simplify this example, but of course you can train a model on any number of categories.\n",
      "Model Key Words (Search categories that describe your model, separated with commas):video, sports, classification\n",
      "   \n",
      "Creating your prediction API. (This process may take several minutes.)\n",
      "\n",
      "[=====================================] Progress: 100% - Complete!                                            \n",
      "\n",
      "Success! Your Model Playground was created in 81 seconds. \n",
      " Playground Url: \"https://fzix5hpw88.execute-api.us-east-1.amazonaws.com/prod/m\"\n",
      "\n",
      "You can now use your Model Playground.\n",
      "\n",
      "Follow this link to explore your Model Playground's functionality\n",
      "You can make predictions with the Dashboard and access example code from the Programmatic tab.\n",
      "https://www.modelshare.org/detail/model:761\n"
     ]
    }
   ],
   "source": [
    "from aimodelshare import ModelPlayground\n",
    "\n",
    "#Instantiate ModelPlayground() Class\n",
    "\n",
    "myplayground=ModelPlayground(model_type=\"video\", classification=True, private=False)\n",
    "\n",
    "# Create Model Playground (generates live rest api and web-app for your model/preprocessor)\n",
    "\n",
    "myplayground.deploy(model_filepath, preprocessor_filepath, y_train_labels, exampledata_filepath) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Eb9dfUFHhLr-"
   },
   "source": [
    "## **Use your new Model Playground!**\n",
    "\n",
    "Follow the link in the output above to:\n",
    "- Generate predictions with your interactive web dashboard\n",
    "- Access example code in Python, R, and Curl\n",
    "\n",
    "Or, follow the rest of the tutorial to create a competition for your Model Playground and: \n",
    "- Access verified model performance metrics \n",
    "- Upload multiple models to a leaderboard \n",
    "- Easily compare model performance & structure "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9YpyLkQNfqSI"
   },
   "source": [
    "## **Part 2: Create a Competition**\n",
    "\n",
    "-------\n",
    "\n",
    "After deploying your Model Playground, you can now create a competition. \n",
    "\n",
    "Creating a competition allows you to:\n",
    "1. Verify the model performance metrics on aimodelshare.org\n",
    "2. Submit models to a leaderboard\n",
    "3. Grant access to other users to submit models to the leaderboard\n",
    "4. Easily compare model performance and structure "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pmklVtx1dFXB",
    "outputId": "bf25852f-ce93-4294-cc9a-9148579f6e91"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading [================================================>]\n",
      "\n",
      "Data downloaded successfully.\n",
      "\n",
      "Preparing downloaded files for use...\n",
      "\n",
      "Success! Your Quick Start materials have been downloaded. \n",
      "You are now ready to run the tutorial.\n"
     ]
    }
   ],
   "source": [
    "#Download competition data and y_test labels to evaluate model prediction submissions\n",
    "import aimodelshare as ai\n",
    "keras_model_2, y_test, y_test_labels = ai.import_quickstart_data(\"sports\", \"competition\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "Zr_aNRhhDJAM"
   },
   "outputs": [],
   "source": [
    "# Create list of authorized participants for competition\n",
    "# Note that participants should use the same email address when creating modelshare.org account\n",
    "\n",
    "emaillist=[\"emailaddress1@email.com\", \"emailaddress2@email.com\", \"emailaddress3@email.com\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "o2nKrLAMgc9o"
   },
   "outputs": [],
   "source": [
    "# Create Competition\n",
    "myplayground.create_competition(data_directory='sports_clips_competition_data', \n",
    "                                y_test = y_test_labels, \n",
    "                                email_list=emaillist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "SAJJWhdAfyo5"
   },
   "outputs": [],
   "source": [
    "#Instantiate Competition\n",
    "#--Note: If you start a new session, the first argument should be the Model Playground url in quotes. \n",
    "#--e.g.- mycompetition= ai.Competition(\"https://2121212.execute-api.us-east-1.amazonaws.com/prod/m)\n",
    "#See Model Playground \"Compete\" tab for example model submission code.\n",
    "\n",
    "mycompetition= ai.Competition(myplayground.playground_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q6Rfl0VwDPz2"
   },
   "outputs": [],
   "source": [
    "# Add, remove, or completely update authorized participants for competition later\n",
    "emaillist=[\"emailaddress4@gmail.com\"]\n",
    "\n",
    "mycompetition.update_access_list(email_list=emaillist,update_type=\"Add\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mqyzWZPwgoEH"
   },
   "source": [
    "Submit Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sJgu9K92DS8O",
    "outputId": "dba324d3-3014-4159-c833-827acf628052"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI Modelshare Username:··········\n",
      "AI Modelshare Password:··········\n",
      "AI Model Share login credentials set successfully.\n"
     ]
    }
   ],
   "source": [
    "#Authorized users can submit new models after setting credentials using modelshare.org username/password\n",
    "\n",
    "apiurl=myplayground.playground_url # example url from deployed playground: apiurl= \"https://123456.execute-api.us-east-1.amazonaws.com/prod/m\n",
    "\n",
    "from aimodelshare.aws import set_credentials\n",
    "set_credentials(apiurl=apiurl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "f5bh0pYkCcvQ"
   },
   "outputs": [],
   "source": [
    "## Prepare X_test data for predictions: \n",
    "# Unzip video clips\n",
    "import zipfile\n",
    "with zipfile.ZipFile('sports_clips_competition_data/clips_test.zip', 'r') as zip_ref:\n",
    "    zip_ref.extractall('X_test_clips')\n",
    "\n",
    "# Preprocess clips\n",
    "import numpy as np\n",
    "file_names = [('/content/X_test_clips/clips_test/' + str(i) + '.avi') for i in range(1, 46)]\n",
    "preprocessed_video_data = [preprocessor(x) for x in file_names]\n",
    "\n",
    "#Create single X_test array from preprocessed videos\n",
    "X_test = np.vstack(preprocessed_video_data) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pJC2jl2PgfTf",
    "outputId": "a1101cb9-2d99-4b11-8de5-fd0d242cc8ef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Insert search tags to help users find your model (optional): lstm to dense, sports videos\n",
      "Provide any useful notes about your model (optional): lstm to dense layers\n",
      "\n",
      "Your model has been submitted as model version 1\n",
      "\n",
      "To submit code used to create this model or to view current leaderboard navigate to Model Playground: \n",
      "\n",
      " https://www.modelshare.org/detail/model:761\n"
     ]
    }
   ],
   "source": [
    "#Submit Model 1: \n",
    "\n",
    "#-- Generate predicted y values (Model 1)\n",
    "#Note: Keras predict returns the predicted column index location for classification models\n",
    "prediction_column_index = keras_model.predict(X_test).argmax(axis=1)\n",
    "\n",
    "# extract correct prediction labels \n",
    "predicted_labels = [y_train_labels.columns[i] for i in prediction_column_index]\n",
    "\n",
    "# Submit Model 1 to Competition Leaderboard\n",
    "mycompetition.submit_model(model_filepath = \"model.onnx\",\n",
    "                                 preprocessor_filepath=\"preprocessor.zip\",\n",
    "                                 prediction_submission=predicted_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hpzXNVPTop-O",
    "outputId": "de843225-66c3-449b-cc53-96ffaf7f3c9b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 60, 5)             983160    \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 5)                 220       \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 3)                 18        \n",
      "=================================================================\n",
      "Total params: 983,398\n",
      "Trainable params: 983,398\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Have a look at architecture for model two\n",
    "keras_model_2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "jraPDdsNX46e"
   },
   "outputs": [],
   "source": [
    "# Save Model 2 to .onnx file\n",
    "\n",
    "# Save tf.keras model to ONNX file\n",
    "onnx_cnn2 = model_to_onnx(keras_model_2, framework='keras',\n",
    "                          transfer_learning=False,\n",
    "                          deep_learning=True)\n",
    "\n",
    "# Save model to local .onnx file\n",
    "with open(\"model_2.onnx\", \"wb\") as f:\n",
    "    f.write(onnx_cnn2.SerializeToString()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Cme7T_gaYWlD",
    "outputId": "aef3b84b-7262-4126-8130-dd10f31ddc11"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Insert search tags to help users find your model (optional): stacked lstms to dense, sports videos\n",
      "Provide any useful notes about your model (optional): stacked lstms to dense\n",
      "\n",
      "Your model has been submitted as model version 2\n",
      "\n",
      "To submit code used to create this model or to view current leaderboard navigate to Model Playground: \n",
      "\n",
      " https://www.modelshare.org/detail/model:761\n"
     ]
    }
   ],
   "source": [
    "# Submit Model 2\n",
    "\n",
    "#-- Generate predicted y values (Model 2)\n",
    "#Note: Keras predict returns the predicted column index location for classification models\n",
    "prediction_column_index = keras_model_2.predict(X_test).argmax(axis=1)\n",
    "\n",
    "# extract correct prediction labels \n",
    "predicted_labels = [y_train_labels.columns[i] for i in prediction_column_index]\n",
    "\n",
    "# Submit Model 2 to Competition Leaderboard\n",
    "mycompetition.submit_model(model_filepath = \"model_2.onnx\",\n",
    "                                 prediction_submission=predicted_labels,\n",
    "                                 preprocessor_filepath=\"preprocessor.zip\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iLYlCkWchWC_"
   },
   "source": [
    "Get Leaderboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 201
    },
    "id": "J0-B1h0chYDL",
    "outputId": "08e117fa-d0cd-4fd5-b7f3-3df1d2a1a7c9"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "#T_126e4bec_4181_11ec_b831_0242ac1c0002row0_col0{\n",
       "            text-align:  center;\n",
       "            width:  10em;\n",
       "             height:  80%;\n",
       "            background:  linear-gradient(90deg,#f5f8d6 48.9%, transparent 48.9%);\n",
       "            color:  #251e1b;\n",
       "            font-size:  12px;\n",
       "        }#T_126e4bec_4181_11ec_b831_0242ac1c0002row0_col1{\n",
       "            text-align:  center;\n",
       "            width:  10em;\n",
       "             height:  80%;\n",
       "            background:  linear-gradient(90deg,#c778c8 45.9%, transparent 45.9%);\n",
       "            color:  #251e1b;\n",
       "            font-size:  12px;\n",
       "        }#T_126e4bec_4181_11ec_b831_0242ac1c0002row0_col2{\n",
       "            text-align:  center;\n",
       "            width:  10em;\n",
       "             height:  80%;\n",
       "            background:  linear-gradient(90deg,#ff4971 59.0%, transparent 59.0%);\n",
       "            color:  #251e1b;\n",
       "            font-size:  12px;\n",
       "        }#T_126e4bec_4181_11ec_b831_0242ac1c0002row0_col3{\n",
       "            text-align:  center;\n",
       "            width:  10em;\n",
       "             height:  80%;\n",
       "            background:  linear-gradient(90deg,#aadbaa 55.6%, transparent 55.6%);\n",
       "            color:  #251e1b;\n",
       "            font-size:  12px;\n",
       "        }#T_126e4bec_4181_11ec_b831_0242ac1c0002row0_col4,#T_126e4bec_4181_11ec_b831_0242ac1c0002row0_col5,#T_126e4bec_4181_11ec_b831_0242ac1c0002row0_col6,#T_126e4bec_4181_11ec_b831_0242ac1c0002row0_col7,#T_126e4bec_4181_11ec_b831_0242ac1c0002row0_col8,#T_126e4bec_4181_11ec_b831_0242ac1c0002row0_col9,#T_126e4bec_4181_11ec_b831_0242ac1c0002row0_col10,#T_126e4bec_4181_11ec_b831_0242ac1c0002row0_col11,#T_126e4bec_4181_11ec_b831_0242ac1c0002row0_col12,#T_126e4bec_4181_11ec_b831_0242ac1c0002row0_col13,#T_126e4bec_4181_11ec_b831_0242ac1c0002row0_col14,#T_126e4bec_4181_11ec_b831_0242ac1c0002row0_col15,#T_126e4bec_4181_11ec_b831_0242ac1c0002row0_col16,#T_126e4bec_4181_11ec_b831_0242ac1c0002row0_col17,#T_126e4bec_4181_11ec_b831_0242ac1c0002row0_col18,#T_126e4bec_4181_11ec_b831_0242ac1c0002row0_col19,#T_126e4bec_4181_11ec_b831_0242ac1c0002row0_col20,#T_126e4bec_4181_11ec_b831_0242ac1c0002row1_col4,#T_126e4bec_4181_11ec_b831_0242ac1c0002row1_col5,#T_126e4bec_4181_11ec_b831_0242ac1c0002row1_col6,#T_126e4bec_4181_11ec_b831_0242ac1c0002row1_col7,#T_126e4bec_4181_11ec_b831_0242ac1c0002row1_col8,#T_126e4bec_4181_11ec_b831_0242ac1c0002row1_col9,#T_126e4bec_4181_11ec_b831_0242ac1c0002row1_col10,#T_126e4bec_4181_11ec_b831_0242ac1c0002row1_col11,#T_126e4bec_4181_11ec_b831_0242ac1c0002row1_col12,#T_126e4bec_4181_11ec_b831_0242ac1c0002row1_col13,#T_126e4bec_4181_11ec_b831_0242ac1c0002row1_col14,#T_126e4bec_4181_11ec_b831_0242ac1c0002row1_col15,#T_126e4bec_4181_11ec_b831_0242ac1c0002row1_col16,#T_126e4bec_4181_11ec_b831_0242ac1c0002row1_col17,#T_126e4bec_4181_11ec_b831_0242ac1c0002row1_col18,#T_126e4bec_4181_11ec_b831_0242ac1c0002row1_col19,#T_126e4bec_4181_11ec_b831_0242ac1c0002row1_col20{\n",
       "            text-align:  center;\n",
       "        }#T_126e4bec_4181_11ec_b831_0242ac1c0002row1_col0{\n",
       "            text-align:  center;\n",
       "            width:  10em;\n",
       "             height:  80%;\n",
       "            background:  linear-gradient(90deg,#f5f8d6 57.8%, transparent 57.8%);\n",
       "            color:  #251e1b;\n",
       "            font-size:  12px;\n",
       "        }#T_126e4bec_4181_11ec_b831_0242ac1c0002row1_col1{\n",
       "            text-align:  center;\n",
       "            width:  10em;\n",
       "             height:  80%;\n",
       "            background:  linear-gradient(90deg,#c778c8 46.1%, transparent 46.1%);\n",
       "            color:  #251e1b;\n",
       "            font-size:  12px;\n",
       "        }#T_126e4bec_4181_11ec_b831_0242ac1c0002row1_col2{\n",
       "            text-align:  center;\n",
       "            width:  10em;\n",
       "             height:  80%;\n",
       "            background:  linear-gradient(90deg,#ff4971 46.3%, transparent 46.3%);\n",
       "            color:  #251e1b;\n",
       "            font-size:  12px;\n",
       "        }#T_126e4bec_4181_11ec_b831_0242ac1c0002row1_col3{\n",
       "            text-align:  center;\n",
       "            width:  10em;\n",
       "             height:  80%;\n",
       "            background:  linear-gradient(90deg,#aadbaa 52.1%, transparent 52.1%);\n",
       "            color:  #251e1b;\n",
       "            font-size:  12px;\n",
       "        }</style><table id=\"T_126e4bec_4181_11ec_b831_0242ac1c0002\" class=\"dataframe\"><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >accuracy</th>        <th class=\"col_heading level0 col1\" >f1_score</th>        <th class=\"col_heading level0 col2\" >precision</th>        <th class=\"col_heading level0 col3\" >recall</th>        <th class=\"col_heading level0 col4\" >ml_framework</th>        <th class=\"col_heading level0 col5\" >transfer_learning</th>        <th class=\"col_heading level0 col6\" >deep_learning</th>        <th class=\"col_heading level0 col7\" >model_type</th>        <th class=\"col_heading level0 col8\" >depth</th>        <th class=\"col_heading level0 col9\" >num_params</th>        <th class=\"col_heading level0 col10\" >dense_layers</th>        <th class=\"col_heading level0 col11\" >lstm_layers</th>        <th class=\"col_heading level0 col12\" >relu_act</th>        <th class=\"col_heading level0 col13\" >softmax_act</th>        <th class=\"col_heading level0 col14\" >tanh_act</th>        <th class=\"col_heading level0 col15\" >loss</th>        <th class=\"col_heading level0 col16\" >optimizer</th>        <th class=\"col_heading level0 col17\" >model_config</th>        <th class=\"col_heading level0 col18\" >memory_size</th>        <th class=\"col_heading level0 col19\" >username</th>        <th class=\"col_heading level0 col20\" >version</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_126e4bec_4181_11ec_b831_0242ac1c0002level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "                        <td id=\"T_126e4bec_4181_11ec_b831_0242ac1c0002row0_col0\" class=\"data row0 col0\" >48.89%</td>\n",
       "                        <td id=\"T_126e4bec_4181_11ec_b831_0242ac1c0002row0_col1\" class=\"data row0 col1\" >45.86%</td>\n",
       "                        <td id=\"T_126e4bec_4181_11ec_b831_0242ac1c0002row0_col2\" class=\"data row0 col2\" >59.04%</td>\n",
       "                        <td id=\"T_126e4bec_4181_11ec_b831_0242ac1c0002row0_col3\" class=\"data row0 col3\" >55.60%</td>\n",
       "                        <td id=\"T_126e4bec_4181_11ec_b831_0242ac1c0002row0_col4\" class=\"data row0 col4\" >keras</td>\n",
       "                        <td id=\"T_126e4bec_4181_11ec_b831_0242ac1c0002row0_col5\" class=\"data row0 col5\" >False</td>\n",
       "                        <td id=\"T_126e4bec_4181_11ec_b831_0242ac1c0002row0_col6\" class=\"data row0 col6\" >True</td>\n",
       "                        <td id=\"T_126e4bec_4181_11ec_b831_0242ac1c0002row0_col7\" class=\"data row0 col7\" >Sequential</td>\n",
       "                        <td id=\"T_126e4bec_4181_11ec_b831_0242ac1c0002row0_col8\" class=\"data row0 col8\" >3</td>\n",
       "                        <td id=\"T_126e4bec_4181_11ec_b831_0242ac1c0002row0_col9\" class=\"data row0 col9\" >9841683</td>\n",
       "                        <td id=\"T_126e4bec_4181_11ec_b831_0242ac1c0002row0_col10\" class=\"data row0 col10\" >2</td>\n",
       "                        <td id=\"T_126e4bec_4181_11ec_b831_0242ac1c0002row0_col11\" class=\"data row0 col11\" >1</td>\n",
       "                        <td id=\"T_126e4bec_4181_11ec_b831_0242ac1c0002row0_col12\" class=\"data row0 col12\" >1.000000</td>\n",
       "                        <td id=\"T_126e4bec_4181_11ec_b831_0242ac1c0002row0_col13\" class=\"data row0 col13\" >1</td>\n",
       "                        <td id=\"T_126e4bec_4181_11ec_b831_0242ac1c0002row0_col14\" class=\"data row0 col14\" >1</td>\n",
       "                        <td id=\"T_126e4bec_4181_11ec_b831_0242ac1c0002row0_col15\" class=\"data row0 col15\" >function</td>\n",
       "                        <td id=\"T_126e4bec_4181_11ec_b831_0242ac1c0002row0_col16\" class=\"data row0 col16\" >Adam</td>\n",
       "                        <td id=\"T_126e4bec_4181_11ec_b831_0242ac1c0002row0_col17\" class=\"data row0 col17\" >{'name': 'sequential', 'layers...</td>\n",
       "                        <td id=\"T_126e4bec_4181_11ec_b831_0242ac1c0002row0_col18\" class=\"data row0 col18\" >217096</td>\n",
       "                        <td id=\"T_126e4bec_4181_11ec_b831_0242ac1c0002row0_col19\" class=\"data row0 col19\" >mikedparrott</td>\n",
       "                        <td id=\"T_126e4bec_4181_11ec_b831_0242ac1c0002row0_col20\" class=\"data row0 col20\" >1</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_126e4bec_4181_11ec_b831_0242ac1c0002level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "                        <td id=\"T_126e4bec_4181_11ec_b831_0242ac1c0002row1_col0\" class=\"data row1 col0\" >57.78%</td>\n",
       "                        <td id=\"T_126e4bec_4181_11ec_b831_0242ac1c0002row1_col1\" class=\"data row1 col1\" >46.06%</td>\n",
       "                        <td id=\"T_126e4bec_4181_11ec_b831_0242ac1c0002row1_col2\" class=\"data row1 col2\" >46.30%</td>\n",
       "                        <td id=\"T_126e4bec_4181_11ec_b831_0242ac1c0002row1_col3\" class=\"data row1 col3\" >52.09%</td>\n",
       "                        <td id=\"T_126e4bec_4181_11ec_b831_0242ac1c0002row1_col4\" class=\"data row1 col4\" >keras</td>\n",
       "                        <td id=\"T_126e4bec_4181_11ec_b831_0242ac1c0002row1_col5\" class=\"data row1 col5\" >False</td>\n",
       "                        <td id=\"T_126e4bec_4181_11ec_b831_0242ac1c0002row1_col6\" class=\"data row1 col6\" >True</td>\n",
       "                        <td id=\"T_126e4bec_4181_11ec_b831_0242ac1c0002row1_col7\" class=\"data row1 col7\" >Sequential</td>\n",
       "                        <td id=\"T_126e4bec_4181_11ec_b831_0242ac1c0002row1_col8\" class=\"data row1 col8\" >3</td>\n",
       "                        <td id=\"T_126e4bec_4181_11ec_b831_0242ac1c0002row1_col9\" class=\"data row1 col9\" >983398</td>\n",
       "                        <td id=\"T_126e4bec_4181_11ec_b831_0242ac1c0002row1_col10\" class=\"data row1 col10\" >1</td>\n",
       "                        <td id=\"T_126e4bec_4181_11ec_b831_0242ac1c0002row1_col11\" class=\"data row1 col11\" >2</td>\n",
       "                        <td id=\"T_126e4bec_4181_11ec_b831_0242ac1c0002row1_col12\" class=\"data row1 col12\" >nan</td>\n",
       "                        <td id=\"T_126e4bec_4181_11ec_b831_0242ac1c0002row1_col13\" class=\"data row1 col13\" >1</td>\n",
       "                        <td id=\"T_126e4bec_4181_11ec_b831_0242ac1c0002row1_col14\" class=\"data row1 col14\" >2</td>\n",
       "                        <td id=\"T_126e4bec_4181_11ec_b831_0242ac1c0002row1_col15\" class=\"data row1 col15\" >function</td>\n",
       "                        <td id=\"T_126e4bec_4181_11ec_b831_0242ac1c0002row1_col16\" class=\"data row1 col16\" >Adam</td>\n",
       "                        <td id=\"T_126e4bec_4181_11ec_b831_0242ac1c0002row1_col17\" class=\"data row1 col17\" >{'name': 'sequential_1', 'laye...</td>\n",
       "                        <td id=\"T_126e4bec_4181_11ec_b831_0242ac1c0002row1_col18\" class=\"data row1 col18\" >2240552</td>\n",
       "                        <td id=\"T_126e4bec_4181_11ec_b831_0242ac1c0002row1_col19\" class=\"data row1 col19\" >mikedparrott</td>\n",
       "                        <td id=\"T_126e4bec_4181_11ec_b831_0242ac1c0002row1_col20\" class=\"data row1 col20\" >2</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f7a061f4610>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = mycompetition.get_leaderboard()\n",
    "mycompetition.stylize_leaderboard(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g_bklL3shOER"
   },
   "source": [
    "Compare Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 127
    },
    "id": "quo_V3A3hNS3",
    "outputId": "77cce8e7-91d7-4ef1-84bf-220b32f2ca7b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "    #T_14db2396_4181_11ec_b831_0242ac1c0002 caption {\n",
       "          color: black;\n",
       "          font-size: 18px;\n",
       "    }#T_14db2396_4181_11ec_b831_0242ac1c0002row0_col0,#T_14db2396_4181_11ec_b831_0242ac1c0002row0_col3,#T_14db2396_4181_11ec_b831_0242ac1c0002row1_col3{\n",
       "            background:  #cbd5e8;\n",
       "            color:  black;\n",
       "            color:  black;\n",
       "        }#T_14db2396_4181_11ec_b831_0242ac1c0002row0_col1,#T_14db2396_4181_11ec_b831_0242ac1c0002row0_col2,#T_14db2396_4181_11ec_b831_0242ac1c0002row0_col4,#T_14db2396_4181_11ec_b831_0242ac1c0002row0_col5,#T_14db2396_4181_11ec_b831_0242ac1c0002row1_col1,#T_14db2396_4181_11ec_b831_0242ac1c0002row1_col2,#T_14db2396_4181_11ec_b831_0242ac1c0002row1_col4,#T_14db2396_4181_11ec_b831_0242ac1c0002row1_col5,#T_14db2396_4181_11ec_b831_0242ac1c0002row2_col1,#T_14db2396_4181_11ec_b831_0242ac1c0002row2_col2,#T_14db2396_4181_11ec_b831_0242ac1c0002row2_col4,#T_14db2396_4181_11ec_b831_0242ac1c0002row2_col5{\n",
       "            background:  white;\n",
       "            color:  black;\n",
       "            color:  black;\n",
       "        }#T_14db2396_4181_11ec_b831_0242ac1c0002row1_col0,#T_14db2396_4181_11ec_b831_0242ac1c0002row2_col0,#T_14db2396_4181_11ec_b831_0242ac1c0002row2_col3{\n",
       "            background:  #fff2ae;\n",
       "            color:  black;\n",
       "            color:  black;\n",
       "        }</style><table id=\"T_14db2396_4181_11ec_b831_0242ac1c0002\" ><caption>Model type: Neural Network</caption><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >Model_1_Layer</th>        <th class=\"col_heading level0 col1\" >Model_1_Shape</th>        <th class=\"col_heading level0 col2\" >Model_1_Params</th>        <th class=\"col_heading level0 col3\" >Model_2_Layer</th>        <th class=\"col_heading level0 col4\" >Model_2_Shape</th>        <th class=\"col_heading level0 col5\" >Model_2_Params</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_14db2396_4181_11ec_b831_0242ac1c0002level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "                        <td id=\"T_14db2396_4181_11ec_b831_0242ac1c0002row0_col0\" class=\"data row0 col0\" >LSTM</td>\n",
       "                        <td id=\"T_14db2396_4181_11ec_b831_0242ac1c0002row0_col1\" class=\"data row0 col1\" >[None, 50]</td>\n",
       "                        <td id=\"T_14db2396_4181_11ec_b831_0242ac1c0002row0_col2\" class=\"data row0 col2\" >9840600</td>\n",
       "                        <td id=\"T_14db2396_4181_11ec_b831_0242ac1c0002row0_col3\" class=\"data row0 col3\" >LSTM</td>\n",
       "                        <td id=\"T_14db2396_4181_11ec_b831_0242ac1c0002row0_col4\" class=\"data row0 col4\" >[None, 60, 5]</td>\n",
       "                        <td id=\"T_14db2396_4181_11ec_b831_0242ac1c0002row0_col5\" class=\"data row0 col5\" >983160</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_14db2396_4181_11ec_b831_0242ac1c0002level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "                        <td id=\"T_14db2396_4181_11ec_b831_0242ac1c0002row1_col0\" class=\"data row1 col0\" >Dense</td>\n",
       "                        <td id=\"T_14db2396_4181_11ec_b831_0242ac1c0002row1_col1\" class=\"data row1 col1\" >[None, 20]</td>\n",
       "                        <td id=\"T_14db2396_4181_11ec_b831_0242ac1c0002row1_col2\" class=\"data row1 col2\" >1020</td>\n",
       "                        <td id=\"T_14db2396_4181_11ec_b831_0242ac1c0002row1_col3\" class=\"data row1 col3\" >LSTM</td>\n",
       "                        <td id=\"T_14db2396_4181_11ec_b831_0242ac1c0002row1_col4\" class=\"data row1 col4\" >[None, 5]</td>\n",
       "                        <td id=\"T_14db2396_4181_11ec_b831_0242ac1c0002row1_col5\" class=\"data row1 col5\" >220</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_14db2396_4181_11ec_b831_0242ac1c0002level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "                        <td id=\"T_14db2396_4181_11ec_b831_0242ac1c0002row2_col0\" class=\"data row2 col0\" >Dense</td>\n",
       "                        <td id=\"T_14db2396_4181_11ec_b831_0242ac1c0002row2_col1\" class=\"data row2 col1\" >[None, 3]</td>\n",
       "                        <td id=\"T_14db2396_4181_11ec_b831_0242ac1c0002row2_col2\" class=\"data row2 col2\" >63</td>\n",
       "                        <td id=\"T_14db2396_4181_11ec_b831_0242ac1c0002row2_col3\" class=\"data row2 col3\" >Dense</td>\n",
       "                        <td id=\"T_14db2396_4181_11ec_b831_0242ac1c0002row2_col4\" class=\"data row2 col4\" >[None, 3]</td>\n",
       "                        <td id=\"T_14db2396_4181_11ec_b831_0242ac1c0002row2_col5\" class=\"data row2 col5\" >18</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Compare two or more models (Experimental, Git-like Diffs for Model Architectures)\n",
    "data=mycompetition.compare_models([1,2],verbose=1)\n",
    "mycompetition.stylize_compare(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FKm9ugiBhQFn"
   },
   "source": [
    "#### Check structure of y test data \n",
    "(This helps users understand how to submit predicted values to leaderboard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dqY82D22hPZx",
    "outputId": "a013d6e2-835d-48d6-bde2-969c334f3144"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'class_balance': {'horserace': 19, 'kayaking': 13, 'pullups': 13},\n",
       " 'class_labels': ['kayaking', 'pullups', 'horserace'],\n",
       " 'label_dtypes': {\"<class 'str'>\": 45},\n",
       " 'y_length': 45,\n",
       " 'ytest_example': ['kayaking', 'horserace', 'pullups', 'kayaking', 'kayaking']}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mycompetition.inspect_y_test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iA-nYjr7WCIp"
   },
   "source": [
    "## **Part 3: Maintaining your Model Playground**\n",
    "\n",
    "-------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0UIWnHIXWM0F"
   },
   "source": [
    "Update Runtime model\n",
    "\n",
    "*Use this function to 1) update the prediction API behind your Model Playground with a new model, chosen from the leaderboard and 2) verify the modelperformance metrics in your Model Playground*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wAchpcGLWLxE",
    "outputId": "ccabcde3-b456-4584-bf9c-9012a31c68f0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Runtime model & preprocessor for api: https://fzix5hpw88.execute-api.us-east-1.amazonaws.com/prod/m updated to model version 2.\n",
      "\n",
      "Model metrics are now updated and verified for this model playground.\n"
     ]
    }
   ],
   "source": [
    "myplayground.update_runtime_model(model_version=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xhJRaiN-WaO1"
   },
   "source": [
    "Delete Deployment \n",
    "\n",
    "*Use this function to delete the entire Model Playground, including the REST API, web dashboard, competition, and all submitted models*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 129
    },
    "id": "mCkf-exLWyDK",
    "outputId": "b4bccc86-afa2-4728-e372-ab9c7feeb752"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running this function will permanently delete all resources tied to this deployment, \n",
      " including the eval lambda and all models submitted to the model competition.\n",
      "\n",
      "To confirm, type 'permanently delete':permanently delete\n"
     ]
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'API deleted successfully.'"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myplayground.delete_deployment()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "[SPORTS CLIPS]: Video Model Playground Deployment and Competition Creation.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
